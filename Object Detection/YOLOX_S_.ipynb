{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "YOLOX-S .ipynb",
      "provenance": [],
      "collapsed_sections": [
        "VfVlxlYYBR6z",
        "eiYvw_GGKaro",
        "2TabCpJOCRti",
        "8UjsuFDICVov",
        "CnFRJEa7CaPe",
        "N7nX2nwWCper",
        "XFbMKDkxPWoD"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfVlxlYYBR6z"
      },
      "source": [
        "# Install YOLOX Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igwruhYxE_a7",
        "outputId": "64f9a28e-a102-48b3-bddc-613c0500fddf"
      },
      "source": [
        "!git clone https://github.com/roboflow-ai/YOLOX.git\n",
        "%cd YOLOX\n",
        "!pip3 install -U pip && pip3 install -r requirements.txt\n",
        "!pip3 install -v -e .  \n",
        "!pip uninstall -y torch torchvision torchaudio\n",
        "!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'YOLOX'...\n",
            "remote: Enumerating objects: 786, done.\u001b[K\n",
            "remote: Total 786 (delta 0), reused 0 (delta 0), pack-reused 786\u001b[K\n",
            "Receiving objects: 100% (786/786), 5.78 MiB | 5.05 MiB/s, done.\n",
            "Resolving deltas: 100% (415/415), done.\n",
            "/content/YOLOX\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-21.3-py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 2.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "Successfully installed pip-21.3\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.9.0+cu111)\n",
            "Requirement already satisfied: opencv_python in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (4.1.2.30)\n",
            "Collecting loguru\n",
            "  Downloading loguru-0.5.3-py3-none-any.whl (57 kB)\n",
            "     |████████████████████████████████| 57 kB 2.4 MB/s             \n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (0.16.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (4.62.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (0.10.0+cu111)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (7.1.2)\n",
            "Collecting thop\n",
            "  Downloading thop-0.0.31.post2005241907-py3-none-any.whl (8.7 kB)\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.10.2.2-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "     |████████████████████████████████| 108 kB 8.6 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (0.8.9)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (2.6.0)\n",
            "Collecting onnx==1.8.1\n",
            "  Downloading onnx-1.8.1-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n",
            "     |████████████████████████████████| 14.5 MB 9.1 kB/s             \n",
            "\u001b[?25hCollecting onnxruntime==1.8.0\n",
            "  Downloading onnxruntime-1.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "     |████████████████████████████████| 4.5 MB 39.5 MB/s            \n",
            "\u001b[?25hCollecting onnx-simplifier==0.3.5\n",
            "  Downloading onnx-simplifier-0.3.5.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx==1.8.1->-r requirements.txt (line 16)) (1.15.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx==1.8.1->-r requirements.txt (line 16)) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx==1.8.1->-r requirements.txt (line 16)) (3.7.4.3)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime==1.8.0->-r requirements.txt (line 17)) (1.12)\n",
            "Collecting onnxoptimizer>=0.2.5\n",
            "  Downloading onnxoptimizer-0.2.6-cp37-cp37m-manylinux2014_x86_64.whl (466 kB)\n",
            "     |████████████████████████████████| 466 kB 49.7 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 6)) (2.4.1)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 6)) (1.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 6)) (2.6.3)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 6)) (1.1.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirements.txt (line 6)) (3.2.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 13)) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 13)) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 13)) (0.6.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 13)) (0.37.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 13)) (1.41.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 13)) (57.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 13)) (0.12.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 13)) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 13)) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 13)) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 13)) (3.3.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 13)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 13)) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 13)) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 13)) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->-r requirements.txt (line 13)) (4.8.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 6)) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 6)) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirements.txt (line 6)) (0.10.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 13)) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 13)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 13)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 13)) (3.0.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->-r requirements.txt (line 13)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 13)) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->-r requirements.txt (line 13)) (3.6.0)\n",
            "Building wheels for collected packages: onnx-simplifier\n",
            "  Building wheel for onnx-simplifier (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for onnx-simplifier: filename=onnx_simplifier-0.3.5-py3-none-any.whl size=12878 sha256=f1d8fdc053eac844855e8d56c44c2792bcd1344a005b3d273cfff09b9c330e7b\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/b4/1b/6acdd4eb854b215cd4aa1c18ca79399f9d34728edaff47ecce\n",
            "Successfully built onnx-simplifier\n",
            "Installing collected packages: onnx, onnxruntime, onnxoptimizer, thop, onnx-simplifier, ninja, loguru\n",
            "Successfully installed loguru-0.5.3 ninja-1.10.2.2 onnx-1.8.1 onnx-simplifier-0.3.5 onnxoptimizer-0.2.6 onnxruntime-1.8.0 thop-0.0.31.post2005241907\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Using pip 21.3 from /usr/local/lib/python3.7/dist-packages/pip (python 3.7)\n",
            "Obtaining file:///content/YOLOX\n",
            "  Running command python setup.py egg_info\n",
            "  running egg_info\n",
            "  creating /tmp/pip-pip-egg-info-iyjzb9p9/yolox.egg-info\n",
            "  writing /tmp/pip-pip-egg-info-iyjzb9p9/yolox.egg-info/PKG-INFO\n",
            "  writing dependency_links to /tmp/pip-pip-egg-info-iyjzb9p9/yolox.egg-info/dependency_links.txt\n",
            "  writing top-level names to /tmp/pip-pip-egg-info-iyjzb9p9/yolox.egg-info/top_level.txt\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-iyjzb9p9/yolox.egg-info/SOURCES.txt'\n",
            "  adding license file 'LICENSE'\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-iyjzb9p9/yolox.egg-info/SOURCES.txt'\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Installing collected packages: yolox\n",
            "  Running setup.py develop for yolox\n",
            "    Running command /usr/bin/python3 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/content/YOLOX/setup.py'\"'\"'; __file__='\"'\"'/content/YOLOX/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' develop --no-deps\n",
            "    running develop\n",
            "    running egg_info\n",
            "    creating yolox.egg-info\n",
            "    writing yolox.egg-info/PKG-INFO\n",
            "    writing dependency_links to yolox.egg-info/dependency_links.txt\n",
            "    writing top-level names to yolox.egg-info/top_level.txt\n",
            "    writing manifest file 'yolox.egg-info/SOURCES.txt'\n",
            "    adding license file 'LICENSE'\n",
            "    writing manifest file 'yolox.egg-info/SOURCES.txt'\n",
            "    running build_ext\n",
            "    building 'yolox._C' extension\n",
            "    creating /content/YOLOX/build\n",
            "    creating /content/YOLOX/build/temp.linux-x86_64-3.7\n",
            "    creating /content/YOLOX/build/temp.linux-x86_64-3.7/content\n",
            "    creating /content/YOLOX/build/temp.linux-x86_64-3.7/content/YOLOX\n",
            "    creating /content/YOLOX/build/temp.linux-x86_64-3.7/content/YOLOX/yolox\n",
            "    creating /content/YOLOX/build/temp.linux-x86_64-3.7/content/YOLOX/yolox/layers\n",
            "    creating /content/YOLOX/build/temp.linux-x86_64-3.7/content/YOLOX/yolox/layers/csrc\n",
            "    creating /content/YOLOX/build/temp.linux-x86_64-3.7/content/YOLOX/yolox/layers/csrc/cocoeval\n",
            "    Emitting ninja build file /content/YOLOX/build/temp.linux-x86_64-3.7/build.ninja...\n",
            "    Compiling objects...\n",
            "    Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "    [1/2] c++ -MMD -MF /content/YOLOX/build/temp.linux-x86_64-3.7/content/YOLOX/yolox/layers/csrc/cocoeval/cocoeval.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/YOLOX/yolox/layers/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/include/python3.7m -c -c /content/YOLOX/yolox/layers/csrc/cocoeval/cocoeval.cpp -o /content/YOLOX/build/temp.linux-x86_64-3.7/content/YOLOX/yolox/layers/csrc/cocoeval/cocoeval.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    [2/2] c++ -MMD -MF /content/YOLOX/build/temp.linux-x86_64-3.7/content/YOLOX/yolox/layers/csrc/vision.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/YOLOX/yolox/layers/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/include/python3.7m -c -c /content/YOLOX/yolox/layers/csrc/vision.cpp -o /content/YOLOX/build/temp.linux-x86_64-3.7/content/YOLOX/yolox/layers/csrc/vision.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    creating build/lib.linux-x86_64-3.7\n",
            "    creating build/lib.linux-x86_64-3.7/yolox\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 /content/YOLOX/build/temp.linux-x86_64-3.7/content/YOLOX/yolox/layers/csrc/vision.o /content/YOLOX/build/temp.linux-x86_64-3.7/content/YOLOX/yolox/layers/csrc/cocoeval/cocoeval.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.7/yolox/_C.cpython-37m-x86_64-linux-gnu.so\n",
            "    copying build/lib.linux-x86_64-3.7/yolox/_C.cpython-37m-x86_64-linux-gnu.so -> yolox\n",
            "    Creating /usr/local/lib/python3.7/dist-packages/yolox.egg-link (link to .)\n",
            "    Adding yolox 0.1.0 to easy-install.pth file\n",
            "\n",
            "    Installed /content/YOLOX\n",
            "Successfully installed yolox-0.1.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Found existing installation: torch 1.9.0+cu111\n",
            "Uninstalling torch-1.9.0+cu111:\n",
            "  Successfully uninstalled torch-1.9.0+cu111\n",
            "Found existing installation: torchvision 0.10.0+cu111\n",
            "Uninstalling torchvision-0.10.0+cu111:\n",
            "  Successfully uninstalled torchvision-0.10.0+cu111\n",
            "\u001b[33mWARNING: Skipping torchaudio as it is not installed.\u001b[0m\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.8.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (1982.2 MB)\n",
            "     |█████████████▌                  | 834.1 MB 1.8 MB/s eta 0:10:46 tcmalloc: large alloc 1147494400 bytes == 0x55ac551a2000 @  0x7f498a1d5615 0x55ac1ae4c4cc 0x55ac1af2c47a 0x55ac1ae4f2ed 0x55ac1af40e1d 0x55ac1aec2e99 0x55ac1aebd9ee 0x55ac1ae50bda 0x55ac1aec2d00 0x55ac1aebd9ee 0x55ac1ae50bda 0x55ac1aebf737 0x55ac1af41c66 0x55ac1aebedaf 0x55ac1af41c66 0x55ac1aebedaf 0x55ac1af41c66 0x55ac1aebedaf 0x55ac1ae51039 0x55ac1ae94409 0x55ac1ae4fc52 0x55ac1aec2c25 0x55ac1aebd9ee 0x55ac1ae50bda 0x55ac1aebf737 0x55ac1aebd9ee 0x55ac1ae50bda 0x55ac1aebe915 0x55ac1ae50afa 0x55ac1aebec0d 0x55ac1aebd9ee\n",
            "     |█████████████████               | 1055.7 MB 1.5 MB/s eta 0:10:34tcmalloc: large alloc 1434370048 bytes == 0x55ac997f8000 @  0x7f498a1d5615 0x55ac1ae4c4cc 0x55ac1af2c47a 0x55ac1ae4f2ed 0x55ac1af40e1d 0x55ac1aec2e99 0x55ac1aebd9ee 0x55ac1ae50bda 0x55ac1aec2d00 0x55ac1aebd9ee 0x55ac1ae50bda 0x55ac1aebf737 0x55ac1af41c66 0x55ac1aebedaf 0x55ac1af41c66 0x55ac1aebedaf 0x55ac1af41c66 0x55ac1aebedaf 0x55ac1ae51039 0x55ac1ae94409 0x55ac1ae4fc52 0x55ac1aec2c25 0x55ac1aebd9ee 0x55ac1ae50bda 0x55ac1aebf737 0x55ac1aebd9ee 0x55ac1ae50bda 0x55ac1aebe915 0x55ac1ae50afa 0x55ac1aebec0d 0x55ac1aebd9ee\n",
            "     |█████████████████████▋          | 1336.2 MB 1.5 MB/s eta 0:07:13tcmalloc: large alloc 1792966656 bytes == 0x55ac1e62a000 @  0x7f498a1d5615 0x55ac1ae4c4cc 0x55ac1af2c47a 0x55ac1ae4f2ed 0x55ac1af40e1d 0x55ac1aec2e99 0x55ac1aebd9ee 0x55ac1ae50bda 0x55ac1aec2d00 0x55ac1aebd9ee 0x55ac1ae50bda 0x55ac1aebf737 0x55ac1af41c66 0x55ac1aebedaf 0x55ac1af41c66 0x55ac1aebedaf 0x55ac1af41c66 0x55ac1aebedaf 0x55ac1ae51039 0x55ac1ae94409 0x55ac1ae4fc52 0x55ac1aec2c25 0x55ac1aebd9ee 0x55ac1ae50bda 0x55ac1aebf737 0x55ac1aebd9ee 0x55ac1ae50bda 0x55ac1aebe915 0x55ac1ae50afa 0x55ac1aebec0d 0x55ac1aebd9ee\n",
            "     |███████████████████████████▎    | 1691.1 MB 1.3 MB/s eta 0:03:38tcmalloc: large alloc 2241208320 bytes == 0x55ac89412000 @  0x7f498a1d5615 0x55ac1ae4c4cc 0x55ac1af2c47a 0x55ac1ae4f2ed 0x55ac1af40e1d 0x55ac1aec2e99 0x55ac1aebd9ee 0x55ac1ae50bda 0x55ac1aec2d00 0x55ac1aebd9ee 0x55ac1ae50bda 0x55ac1aebf737 0x55ac1af41c66 0x55ac1aebedaf 0x55ac1af41c66 0x55ac1aebedaf 0x55ac1af41c66 0x55ac1aebedaf 0x55ac1ae51039 0x55ac1ae94409 0x55ac1ae4fc52 0x55ac1aec2c25 0x55ac1aebd9ee 0x55ac1ae50bda 0x55ac1aebf737 0x55ac1aebd9ee 0x55ac1ae50bda 0x55ac1aebe915 0x55ac1ae50afa 0x55ac1aebec0d 0x55ac1aebd9ee\n",
            "     |████████████████████████████████| 1982.2 MB 1.4 MB/s eta 0:00:01tcmalloc: large alloc 1982251008 bytes == 0x55ad0ed74000 @  0x7f498a1d41e7 0x55ac1ae82067 0x55ac1ae4c4cc 0x55ac1af2c47a 0x55ac1ae4f2ed 0x55ac1af40e1d 0x55ac1aec2e99 0x55ac1aebd9ee 0x55ac1ae50bda 0x55ac1aebec0d 0x55ac1aebd9ee 0x55ac1ae50bda 0x55ac1aebec0d 0x55ac1aebd9ee 0x55ac1ae50bda 0x55ac1aebec0d 0x55ac1aebd9ee 0x55ac1ae50bda 0x55ac1aebec0d 0x55ac1aebd9ee 0x55ac1ae50bda 0x55ac1aebec0d 0x55ac1ae50afa 0x55ac1aebec0d 0x55ac1aebd9ee 0x55ac1ae50bda 0x55ac1aebf737 0x55ac1aebd9ee 0x55ac1ae50bda 0x55ac1aebf737 0x55ac1aebd9ee\n",
            "tcmalloc: large alloc 2477817856 bytes == 0x55ad84fe0000 @  0x7f498a1d5615 0x55ac1ae4c4cc 0x55ac1af2c47a 0x55ac1ae4f2ed 0x55ac1af40e1d 0x55ac1aec2e99 0x55ac1aebd9ee 0x55ac1ae50bda 0x55ac1aebec0d 0x55ac1aebd9ee 0x55ac1ae50bda 0x55ac1aebec0d 0x55ac1aebd9ee 0x55ac1ae50bda 0x55ac1aebec0d 0x55ac1aebd9ee 0x55ac1ae50bda 0x55ac1aebec0d 0x55ac1aebd9ee 0x55ac1ae50bda 0x55ac1aebec0d 0x55ac1ae50afa 0x55ac1aebec0d 0x55ac1aebd9ee 0x55ac1ae50bda 0x55ac1aebf737 0x55ac1aebd9ee 0x55ac1ae50bda 0x55ac1aebf737 0x55ac1aebd9ee 0x55ac1ae51271\n",
            "     |████████████████████████████████| 1982.2 MB 2.5 kB/s            \n",
            "\u001b[?25hCollecting torchvision==0.9.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (17.6 MB)\n",
            "     |████████████████████████████████| 17.6 MB 56.2 MB/s            \n",
            "\u001b[?25hCollecting torchaudio==0.8.0\n",
            "  Downloading torchaudio-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
            "     |████████████████████████████████| 1.9 MB 4.2 MB/s            \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0+cu111) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0+cu111) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.0+cu111) (7.1.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.8.0+cu111 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.8.0+cu111 torchaudio-0.8.0 torchvision-0.9.0+cu111\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llsu3xhVBZYC"
      },
      "source": [
        "## Install Nvidia Apex"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksHd57LFFMzK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "198888c1-5eea-408f-c566-3e04591528a3"
      },
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/NVIDIA/apex\n",
        "%cd apex\n",
        "!pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'apex'...\n",
            "remote: Enumerating objects: 8453, done.\u001b[K\n",
            "remote: Counting objects: 100% (540/540), done.\u001b[K\n",
            "remote: Compressing objects: 100% (336/336), done.\u001b[K\n",
            "remote: Total 8453 (delta 307), reused 355 (delta 192), pack-reused 7913\u001b[K\n",
            "Receiving objects: 100% (8453/8453), 14.38 MiB | 10.80 MiB/s, done.\n",
            "Resolving deltas: 100% (5706/5706), done.\n",
            "/content/apex\n",
            "/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/install.py:245: UserWarning: Disabling all use of wheels due to the use of --build-option / --global-option / --install-option.\n",
            "  cmdoptions.check_install_build_global(options)\n",
            "Using pip 21.3 from /usr/local/lib/python3.7/dist-packages/pip (python 3.7)\n",
            "Processing /content/apex\n",
            "  Running command python setup.py egg_info\n",
            "\n",
            "\n",
            "  torch.__version__  = 1.8.0+cu111\n",
            "\n",
            "\n",
            "  running egg_info\n",
            "  creating /tmp/pip-pip-egg-info-4jwsdx0m/apex.egg-info\n",
            "  writing /tmp/pip-pip-egg-info-4jwsdx0m/apex.egg-info/PKG-INFO\n",
            "  writing dependency_links to /tmp/pip-pip-egg-info-4jwsdx0m/apex.egg-info/dependency_links.txt\n",
            "  writing top-level names to /tmp/pip-pip-egg-info-4jwsdx0m/apex.egg-info/top_level.txt\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-4jwsdx0m/apex.egg-info/SOURCES.txt'\n",
            "  adding license file 'LICENSE'\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-4jwsdx0m/apex.egg-info/SOURCES.txt'\n",
            "  /content/apex/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "    warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Skipping wheel build for apex, due to binaries being disabled for it.\n",
            "Installing collected packages: apex\n",
            "    Running command /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/content/apex/setup.py'\"'\"'; __file__='\"'\"'/content/apex/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-zyevphjd/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.7/apex\n",
            "\n",
            "\n",
            "    torch.__version__  = 1.8.0+cu111\n",
            "\n",
            "\n",
            "    /content/apex/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "\n",
            "    Compiling cuda extensions with\n",
            "    nvcc: NVIDIA (R) Cuda compiler driver\n",
            "    Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "    Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "    Cuda compilation tools, release 11.1, V11.1.105\n",
            "    Build cuda_11.1.TC455_06.29190527_0\n",
            "    from /usr/local/cuda/bin\n",
            "\n",
            "    running install\n",
            "    running build\n",
            "    running build_py\n",
            "    creating build\n",
            "    creating build/lib.linux-x86_64-3.7\n",
            "    creating build/lib.linux-x86_64-3.7/apex\n",
            "    copying apex/_autocast_utils.py -> build/lib.linux-x86_64-3.7/apex\n",
            "    copying apex/__init__.py -> build/lib.linux-x86_64-3.7/apex\n",
            "    creating build/lib.linux-x86_64-3.7/apex/normalization\n",
            "    copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.7/apex/normalization\n",
            "    copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.7/apex/normalization\n",
            "    creating build/lib.linux-x86_64-3.7/apex/optimizers\n",
            "    copying apex/optimizers/fused_novograd.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
            "    copying apex/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
            "    copying apex/optimizers/fused_adagrad.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
            "    copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
            "    copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
            "    copying apex/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
            "    creating build/lib.linux-x86_64-3.7/apex/fp16_utils\n",
            "    copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.7/apex/fp16_utils\n",
            "    copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.7/apex/fp16_utils\n",
            "    copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.7/apex/fp16_utils\n",
            "    copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.7/apex/fp16_utils\n",
            "    creating build/lib.linux-x86_64-3.7/apex/fused_dense\n",
            "    copying apex/fused_dense/fused_dense.py -> build/lib.linux-x86_64-3.7/apex/fused_dense\n",
            "    copying apex/fused_dense/__init__.py -> build/lib.linux-x86_64-3.7/apex/fused_dense\n",
            "    creating build/lib.linux-x86_64-3.7/apex/transformer\n",
            "    copying apex/transformer/enums.py -> build/lib.linux-x86_64-3.7/apex/transformer\n",
            "    copying apex/transformer/parallel_state.py -> build/lib.linux-x86_64-3.7/apex/transformer\n",
            "    copying apex/transformer/__init__.py -> build/lib.linux-x86_64-3.7/apex/transformer\n",
            "    creating build/lib.linux-x86_64-3.7/apex/contrib\n",
            "    copying apex/contrib/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib\n",
            "    creating build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/amp.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/utils.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/opt.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/compat.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/handle.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    creating build/lib.linux-x86_64-3.7/apex/pyprof\n",
            "    copying apex/pyprof/__init__.py -> build/lib.linux-x86_64-3.7/apex/pyprof\n",
            "    creating build/lib.linux-x86_64-3.7/apex/parallel\n",
            "    copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "    copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "    copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "    copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "    copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "    copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "    copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "    copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "    creating build/lib.linux-x86_64-3.7/apex/RNN\n",
            "    copying apex/RNN/models.py -> build/lib.linux-x86_64-3.7/apex/RNN\n",
            "    copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.7/apex/RNN\n",
            "    copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.7/apex/RNN\n",
            "    copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.7/apex/RNN\n",
            "    creating build/lib.linux-x86_64-3.7/apex/multi_tensor_apply\n",
            "    copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.7/apex/multi_tensor_apply\n",
            "    copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.7/apex/multi_tensor_apply\n",
            "    creating build/lib.linux-x86_64-3.7/apex/mlp\n",
            "    copying apex/mlp/mlp.py -> build/lib.linux-x86_64-3.7/apex/mlp\n",
            "    copying apex/mlp/__init__.py -> build/lib.linux-x86_64-3.7/apex/mlp\n",
            "    creating build/lib.linux-x86_64-3.7/apex/reparameterization\n",
            "    copying apex/reparameterization/reparameterization.py -> build/lib.linux-x86_64-3.7/apex/reparameterization\n",
            "    copying apex/reparameterization/weight_norm.py -> build/lib.linux-x86_64-3.7/apex/reparameterization\n",
            "    copying apex/reparameterization/__init__.py -> build/lib.linux-x86_64-3.7/apex/reparameterization\n",
            "    creating build/lib.linux-x86_64-3.7/apex/transformer/functional\n",
            "    copying apex/transformer/functional/fused_softmax.py -> build/lib.linux-x86_64-3.7/apex/transformer/functional\n",
            "    copying apex/transformer/functional/__init__.py -> build/lib.linux-x86_64-3.7/apex/transformer/functional\n",
            "    creating build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel\n",
            "    copying apex/transformer/tensor_parallel/mappings.py -> build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel\n",
            "    copying apex/transformer/tensor_parallel/data.py -> build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel\n",
            "    copying apex/transformer/tensor_parallel/utils.py -> build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel\n",
            "    copying apex/transformer/tensor_parallel/random.py -> build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel\n",
            "    copying apex/transformer/tensor_parallel/cross_entropy.py -> build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel\n",
            "    copying apex/transformer/tensor_parallel/microbatches.py -> build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel\n",
            "    copying apex/transformer/tensor_parallel/__init__.py -> build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel\n",
            "    copying apex/transformer/tensor_parallel/layers.py -> build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel\n",
            "    copying apex/transformer/tensor_parallel/memory.py -> build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel\n",
            "    creating build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel/tests\n",
            "    copying apex/transformer/tensor_parallel/tests/commons.py -> build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel/tests\n",
            "    copying apex/transformer/tensor_parallel/tests/global_vars.py -> build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel/tests\n",
            "    copying apex/transformer/tensor_parallel/tests/arguments.py -> build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel/tests\n",
            "    copying apex/transformer/tensor_parallel/tests/__init__.py -> build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel/tests\n",
            "    creating build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "    creating build/lib.linux-x86_64-3.7/apex/contrib/transducer\n",
            "    copying apex/contrib/transducer/transducer.py -> build/lib.linux-x86_64-3.7/apex/contrib/transducer\n",
            "    copying apex/contrib/transducer/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/transducer\n",
            "    creating build/lib.linux-x86_64-3.7/apex/contrib/bottleneck\n",
            "    copying apex/contrib/bottleneck/bottleneck.py -> build/lib.linux-x86_64-3.7/apex/contrib/bottleneck\n",
            "    copying apex/contrib/bottleneck/bottleneck_module_test.py -> build/lib.linux-x86_64-3.7/apex/contrib/bottleneck\n",
            "    copying apex/contrib/bottleneck/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/bottleneck\n",
            "    copying apex/contrib/bottleneck/test.py -> build/lib.linux-x86_64-3.7/apex/contrib/bottleneck\n",
            "    creating build/lib.linux-x86_64-3.7/apex/contrib/xentropy\n",
            "    copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib.linux-x86_64-3.7/apex/contrib/xentropy\n",
            "    copying apex/contrib/xentropy/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/xentropy\n",
            "    creating build/lib.linux-x86_64-3.7/apex/contrib/layer_norm\n",
            "    copying apex/contrib/layer_norm/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/layer_norm\n",
            "    copying apex/contrib/layer_norm/layer_norm.py -> build/lib.linux-x86_64-3.7/apex/contrib/layer_norm\n",
            "    creating build/lib.linux-x86_64-3.7/apex/contrib/fmha\n",
            "    copying apex/contrib/fmha/fmha.py -> build/lib.linux-x86_64-3.7/apex/contrib/fmha\n",
            "    copying apex/contrib/fmha/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/fmha\n",
            "    creating build/lib.linux-x86_64-3.7/apex/contrib/groupbn\n",
            "    copying apex/contrib/groupbn/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/groupbn\n",
            "    copying apex/contrib/groupbn/batch_norm.py -> build/lib.linux-x86_64-3.7/apex/contrib/groupbn\n",
            "    creating build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "    creating build/lib.linux-x86_64-3.7/apex/contrib/sparsity\n",
            "    copying apex/contrib/sparsity/asp.py -> build/lib.linux-x86_64-3.7/apex/contrib/sparsity\n",
            "    copying apex/contrib/sparsity/sparse_masklib.py -> build/lib.linux-x86_64-3.7/apex/contrib/sparsity\n",
            "    copying apex/contrib/sparsity/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/sparsity\n",
            "    creating build/lib.linux-x86_64-3.7/apex/amp/lists\n",
            "    copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.7/apex/amp/lists\n",
            "    copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.7/apex/amp/lists\n",
            "    copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.7/apex/amp/lists\n",
            "    copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.7/apex/amp/lists\n",
            "    creating build/lib.linux-x86_64-3.7/apex/pyprof/nvtx\n",
            "    copying apex/pyprof/nvtx/__init__.py -> build/lib.linux-x86_64-3.7/apex/pyprof/nvtx\n",
            "    copying apex/pyprof/nvtx/nvmarker.py -> build/lib.linux-x86_64-3.7/apex/pyprof/nvtx\n",
            "    creating build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/__main__.py -> build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/db.py -> build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/kernel.py -> build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/__init__.py -> build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/nvvp.py -> build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/parse.py -> build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
            "    creating build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/randomSample.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/prof.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/convert.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/embedding.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/pooling.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/reduction.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/conv.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/data.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/pointwise.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/blas.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/softmax.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/utility.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/__main__.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/optim.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/usage.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/base.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/linear.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/misc.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/recurrentCell.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/activation.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/__init__.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/loss.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/normalization.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/dropout.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/output.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    running build_ext\n",
            "    building 'apex_C' extension\n",
            "    creating /content/apex/build/temp.linux-x86_64-3.7\n",
            "    creating /content/apex/build/temp.linux-x86_64-3.7/csrc\n",
            "    Emitting ninja build file /content/apex/build/temp.linux-x86_64-3.7/build.ninja...\n",
            "    Compiling objects...\n",
            "    Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "    [1/1] c++ -MMD -MF /content/apex/build/temp.linux-x86_64-3.7/csrc/flatten_unflatten.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/include/python3.7m -c -c /content/apex/csrc/flatten_unflatten.cpp -o /content/apex/build/temp.linux-x86_64-3.7/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:140:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:13,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/flatten_unflatten.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:83:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            "     #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            "\n",
            "    In file included from /content/apex/csrc/flatten_unflatten.cpp:2:0:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/utils/tensor_flatten.h: In member function ‘at::DeprecatedTypeProperties& torch::utils::TensorGroup::type()’:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/utils/tensor_flatten.h:44:28: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         return tensors[0].type();\n",
            "                                ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/flatten_unflatten.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 /content/apex/build/temp.linux-x86_64-3.7/csrc/flatten_unflatten.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.7/apex_C.cpython-37m-x86_64-linux-gnu.so\n",
            "    building 'amp_C' extension\n",
            "    Emitting ninja build file /content/apex/build/temp.linux-x86_64-3.7/build.ninja...\n",
            "    Compiling objects...\n",
            "    Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "    [1/12] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_adam.o.d -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/multi_tensor_adam.cu -o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_adam.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "    [2/12] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_sgd_kernel.o.d -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/multi_tensor_sgd_kernel.cu -o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_sgd_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "    [3/12] c++ -MMD -MF /content/apex/build/temp.linux-x86_64-3.7/csrc/amp_C_frontend.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/amp_C_frontend.cpp -o /content/apex/build/temp.linux-x86_64-3.7/csrc/amp_C_frontend.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:140:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:13,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/amp_C_frontend.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:83:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            "     #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            "\n",
            "    [4/12] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_scale_kernel.o.d -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/multi_tensor_scale_kernel.cu -o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "    [5/12] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_axpby_kernel.o.d -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/multi_tensor_axpby_kernel.cu -o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "    [6/12] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_l2norm_kernel.o.d -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/multi_tensor_l2norm_kernel.cu -o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "    [7/12] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_l2norm_scale_kernel.o.d -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/multi_tensor_l2norm_scale_kernel.cu -o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_l2norm_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "    [8/12] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_lamb_stage_1.o.d -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/multi_tensor_lamb_stage_1.cu -o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_lamb_stage_1.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "    [9/12] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_lamb_stage_2.o.d -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/multi_tensor_lamb_stage_2.cu -o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_lamb_stage_2.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "    [10/12] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_adagrad.o.d -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/multi_tensor_adagrad.cu -o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_adagrad.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "    [11/12] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_novograd.o.d -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/multi_tensor_novograd.cu -o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_novograd.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "    [12/12] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_lamb.o.d -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/multi_tensor_lamb.cu -o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_lamb.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 /content/apex/build/temp.linux-x86_64-3.7/csrc/amp_C_frontend.o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_sgd_kernel.o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_scale_kernel.o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_axpby_kernel.o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_l2norm_kernel.o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_l2norm_scale_kernel.o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_lamb_stage_1.o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_lamb_stage_2.o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_adam.o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_adagrad.o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_novograd.o /content/apex/build/temp.linux-x86_64-3.7/csrc/multi_tensor_lamb.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.7/amp_C.cpython-37m-x86_64-linux-gnu.so\n",
            "    building 'syncbn' extension\n",
            "    Emitting ninja build file /content/apex/build/temp.linux-x86_64-3.7/build.ninja...\n",
            "    Compiling objects...\n",
            "    Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "    [1/2] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/apex/build/temp.linux-x86_64-3.7/csrc/welford.o.d -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/welford.cu -o /content/apex/build/temp.linux-x86_64-3.7/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "    [2/2] c++ -MMD -MF /content/apex/build/temp.linux-x86_64-3.7/csrc/syncbn.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/syncbn.cpp -o /content/apex/build/temp.linux-x86_64-3.7/csrc/syncbn.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:140:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:13,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/syncbn.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:83:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            "     #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            "\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 /content/apex/build/temp.linux-x86_64-3.7/csrc/syncbn.o /content/apex/build/temp.linux-x86_64-3.7/csrc/welford.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.7/syncbn.cpython-37m-x86_64-linux-gnu.so\n",
            "    building 'fused_layer_norm_cuda' extension\n",
            "    Emitting ninja build file /content/apex/build/temp.linux-x86_64-3.7/build.ninja...\n",
            "    Compiling objects...\n",
            "    Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "    [1/2] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/apex/build/temp.linux-x86_64-3.7/csrc/layer_norm_cuda_kernel.o.d -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/layer_norm_cuda_kernel.cu -o /content/apex/build/temp.linux-x86_64-3.7/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -maxrregcount=50 -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "    [2/2] c++ -MMD -MF /content/apex/build/temp.linux-x86_64-3.7/csrc/layer_norm_cuda.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/layer_norm_cuda.cpp -o /content/apex/build/temp.linux-x86_64-3.7/csrc/layer_norm_cuda.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:140:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:13,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:83:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            "     #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            "\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm(at::Tensor, c10::IntArrayRef, double)’:\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:129:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(input);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm_affine(at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double)’:\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:150:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(input);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:151:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(gamma);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:152:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(beta);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm_affine_mixed_dtypes(at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double)’:\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:174:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(input);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp: In function ‘at::Tensor layer_norm_gradient(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, double)’:\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:216:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(dout);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:217:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(mean);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:218:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(invvar);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:219:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(input);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp: In function ‘std::vector<at::Tensor> layer_norm_gradient_affine(at::Tensor, at::Tensor, at::Tensor, at::Tensor, c10::IntArrayRef, at::Tensor, at::Tensor, double)’:\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:242:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(dout);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:243:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(mean);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:244:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(invvar);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:245:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(input);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:246:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(gamma);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/DeviceType.h:8:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Device.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/c10/core/Allocator.h:6,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:7,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:117:42: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                                              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/macros/Macros.h:173:65: note: in definition of macro ‘C10_UNLIKELY’\n",
            "     #define C10_UNLIKELY(expr)  (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "                                                                     ^~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/c10/util/Exception.h:362:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "       if (C10_UNLIKELY_OR_CONST(!(cond))) {                                 \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:117:23: note: in expansion of macro ‘TORCH_CHECK’\n",
            "     #define CHECK_CUDA(x) TORCH_CHECK(x.type().is_cuda(), #x \" must be a CUDA tensor\")\n",
            "                           ^~~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:119:24: note: in expansion of macro ‘CHECK_CUDA’\n",
            "     #define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
            "                            ^~~~~~~~~~\n",
            "    /content/apex/csrc/layer_norm_cuda.cpp:247:3: note: in expansion of macro ‘CHECK_INPUT’\n",
            "       CHECK_INPUT(beta);\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/layer_norm_cuda.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 /content/apex/build/temp.linux-x86_64-3.7/csrc/layer_norm_cuda.o /content/apex/build/temp.linux-x86_64-3.7/csrc/layer_norm_cuda_kernel.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.7/fused_layer_norm_cuda.cpython-37m-x86_64-linux-gnu.so\n",
            "    building 'mlp_cuda' extension\n",
            "    Emitting ninja build file /content/apex/build/temp.linux-x86_64-3.7/build.ninja...\n",
            "    Compiling objects...\n",
            "    Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "    [1/2] c++ -MMD -MF /content/apex/build/temp.linux-x86_64-3.7/csrc/mlp.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/mlp.cpp -o /content/apex/build/temp.linux-x86_64-3.7/csrc/mlp.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:140:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:13,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:83:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            "     #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            "\n",
            "    /content/apex/csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_forward(int, int, std::vector<at::Tensor>)’:\n",
            "    /content/apex/csrc/mlp.cpp:57:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "       for (int i = 0; i < num_layers; i++) {\n",
            "                       ~~^~~~~~~~~~~~\n",
            "    /content/apex/csrc/mlp.cpp:64:77: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       auto out = at::empty({batch_size, output_features.back()}, inputs[0].type());\n",
            "                                                                                 ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    /content/apex/csrc/mlp.cpp:65:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n",
            "                                                                       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    /content/apex/csrc/mlp.cpp:65:68: warning: narrowing conversion of ‘reserved_size’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "       auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n",
            "                                                                        ^\n",
            "    /content/apex/csrc/mlp.cpp:65:68: warning: narrowing conversion of ‘reserved_size’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "    /content/apex/csrc/mlp.cpp:67:59: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       auto lt_workspace = at::empty({1 << 22}, inputs[0].type());\n",
            "                                                               ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/mlp.cpp:1:\n",
            "    /content/apex/csrc/mlp.cpp: In lambda function:\n",
            "    /content/apex/csrc/mlp.cpp:69:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "                                                          ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:209:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "         const auto& the_type = TYPE;                                               \\\n",
            "                                ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:211:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "         at::ScalarType _st = ::detail::scalar_type(the_type);                      \\\n",
            "                                                            ^\n",
            "    /content/apex/csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:109:23: note: declared here\n",
            "     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "                           ^~~~~~~~~~~\n",
            "    /content/apex/csrc/mlp.cpp: In lambda function:\n",
            "    /content/apex/csrc/mlp.cpp:72:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    /content/apex/csrc/mlp.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_fp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    /content/apex/csrc/mlp.cpp: In lambda function:\n",
            "    /content/apex/csrc/mlp.cpp:72:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    /content/apex/csrc/mlp.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_fp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    /content/apex/csrc/mlp.cpp: In lambda function:\n",
            "    /content/apex/csrc/mlp.cpp:72:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    /content/apex/csrc/mlp.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_fp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/mlp.cpp:69:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    /content/apex/csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_backward(int, int, at::Tensor, std::vector<at::Tensor>, std::vector<at::Tensor>)’:\n",
            "    /content/apex/csrc/mlp.cpp:115:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "       for (int i = 0; i < num_layers; i++) {\n",
            "                       ~~^~~~~~~~~~~~\n",
            "    /content/apex/csrc/mlp.cpp:120:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "       for (int i = 0; i < inputs.size(); i++) {\n",
            "                       ~~^~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/mlp.cpp:121:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         outputs.push_back(at::empty(inputs[i].sizes(), inputs[i].type()));  // clone for testing now\n",
            "                                                                       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/mlp.cpp:1:\n",
            "    /content/apex/csrc/mlp.cpp: In lambda function:\n",
            "    /content/apex/csrc/mlp.cpp:124:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "                                                          ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:209:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "         const auto& the_type = TYPE;                                               \\\n",
            "                                ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:211:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "         at::ScalarType _st = ::detail::scalar_type(the_type);                      \\\n",
            "                                                            ^\n",
            "    /content/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:109:23: note: declared here\n",
            "     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "                           ^~~~~~~~~~~\n",
            "    /content/apex/csrc/mlp.cpp: In lambda function:\n",
            "    /content/apex/csrc/mlp.cpp:126:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    /content/apex/csrc/mlp.cpp:130:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < inputs.size(); i++) {\n",
            "                         ~~^~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    /content/apex/csrc/mlp.cpp:138:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                                                                    ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/mlp.cpp:1:\n",
            "    /content/apex/csrc/mlp.cpp:138:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    /content/apex/csrc/mlp.cpp:138:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    /content/apex/csrc/mlp.cpp:140:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_bp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    /content/apex/csrc/mlp.cpp: In lambda function:\n",
            "    /content/apex/csrc/mlp.cpp:126:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    /content/apex/csrc/mlp.cpp:130:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < inputs.size(); i++) {\n",
            "                         ~~^~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    /content/apex/csrc/mlp.cpp:138:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                                                                    ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/mlp.cpp:1:\n",
            "    /content/apex/csrc/mlp.cpp:138:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    /content/apex/csrc/mlp.cpp:138:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    /content/apex/csrc/mlp.cpp:140:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_bp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    /content/apex/csrc/mlp.cpp: In lambda function:\n",
            "    /content/apex/csrc/mlp.cpp:126:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    /content/apex/csrc/mlp.cpp:130:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < inputs.size(); i++) {\n",
            "                         ~~^~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    /content/apex/csrc/mlp.cpp:138:80: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                                                                    ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/mlp.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/mlp.cpp:1:\n",
            "    /content/apex/csrc/mlp.cpp:138:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    /content/apex/csrc/mlp.cpp:138:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    /content/apex/csrc/mlp.cpp:140:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_bp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/mlp.cpp:124:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    [2/2] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/apex/build/temp.linux-x86_64-3.7/csrc/mlp_cuda.o.d -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/mlp_cuda.cu -o /content/apex/build/temp.linux-x86_64-3.7/csrc/mlp_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 /content/apex/build/temp.linux-x86_64-3.7/csrc/mlp.o /content/apex/build/temp.linux-x86_64-3.7/csrc/mlp_cuda.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.7/mlp_cuda.cpython-37m-x86_64-linux-gnu.so\n",
            "    building 'fused_dense_cuda' extension\n",
            "    Emitting ninja build file /content/apex/build/temp.linux-x86_64-3.7/build.ninja...\n",
            "    Compiling objects...\n",
            "    Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "    [1/2] c++ -MMD -MF /content/apex/build/temp.linux-x86_64-3.7/csrc/fused_dense.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/fused_dense.cpp -o /content/apex/build/temp.linux-x86_64-3.7/csrc/fused_dense.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_dense_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:140:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:13,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/fused_dense.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:83:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            "     #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            "\n",
            "    /content/apex/csrc/fused_dense.cpp: In function ‘at::Tensor linear_bias_forward(at::Tensor, at::Tensor, at::Tensor)’:\n",
            "    /content/apex/csrc/fused_dense.cpp:30:63: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       auto out = at::empty({batch_size, out_features}, input.type());\n",
            "                                                                   ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/fused_dense.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    /content/apex/csrc/fused_dense.cpp:33:55: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       auto lt_workspace = at::empty({1 << 22}, input.type());\n",
            "                                                           ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/fused_dense.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/fused_dense.cpp:1:\n",
            "    /content/apex/csrc/fused_dense.cpp: In lambda function:\n",
            "    /content/apex/csrc/fused_dense.cpp:35:50: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_forward\", [&] {\n",
            "                                                      ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:209:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "         const auto& the_type = TYPE;                                               \\\n",
            "                                ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/fused_dense.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/fused_dense.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:211:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "         at::ScalarType _st = ::detail::scalar_type(the_type);                      \\\n",
            "                                                            ^\n",
            "    /content/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_forward\", [&] {\n",
            "       ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:109:23: note: declared here\n",
            "     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "                           ^~~~~~~~~~~\n",
            "    /content/apex/csrc/fused_dense.cpp: In lambda function:\n",
            "    /content/apex/csrc/fused_dense.cpp:37:15: warning: unused variable ‘b_ptr’ [-Wunused-variable]\n",
            "         scalar_t* b_ptr = bias.data_ptr<scalar_t>();\n",
            "                   ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_forward\", [&] {\n",
            "       ^\n",
            "    /content/apex/csrc/fused_dense.cpp:38:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = linear_bias_forward_cuda<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_forward\", [&] {\n",
            "       ^\n",
            "    /content/apex/csrc/fused_dense.cpp: In lambda function:\n",
            "    /content/apex/csrc/fused_dense.cpp:37:15: warning: unused variable ‘b_ptr’ [-Wunused-variable]\n",
            "         scalar_t* b_ptr = bias.data_ptr<scalar_t>();\n",
            "                   ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_forward\", [&] {\n",
            "       ^\n",
            "    /content/apex/csrc/fused_dense.cpp:38:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = linear_bias_forward_cuda<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_forward\", [&] {\n",
            "       ^\n",
            "    /content/apex/csrc/fused_dense.cpp: In lambda function:\n",
            "    /content/apex/csrc/fused_dense.cpp:37:15: warning: unused variable ‘b_ptr’ [-Wunused-variable]\n",
            "         scalar_t* b_ptr = bias.data_ptr<scalar_t>();\n",
            "                   ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_forward\", [&] {\n",
            "       ^\n",
            "    /content/apex/csrc/fused_dense.cpp:38:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = linear_bias_forward_cuda<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/fused_dense.cpp:35:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_forward\", [&] {\n",
            "       ^\n",
            "    /content/apex/csrc/fused_dense.cpp: In function ‘std::vector<at::Tensor> linear_bias_backward(at::Tensor, at::Tensor, at::Tensor)’:\n",
            "    /content/apex/csrc/fused_dense.cpp:64:69: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       auto d_weight = at::empty({out_features, in_features}, input.type());\n",
            "                                                                         ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/fused_dense.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    /content/apex/csrc/fused_dense.cpp:68:54: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       auto d_bias = at::empty({out_features}, input.type());\n",
            "                                                          ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/fused_dense.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    /content/apex/csrc/fused_dense.cpp:70:66: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       auto d_input = at::empty({batch_size, in_features}, input.type());\n",
            "                                                                      ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/fused_dense.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    /content/apex/csrc/fused_dense.cpp:73:55: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       auto lt_workspace = at::empty({1 << 22}, input.type());\n",
            "                                                           ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/fused_dense.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/fused_dense.cpp:1:\n",
            "    /content/apex/csrc/fused_dense.cpp: In lambda function:\n",
            "    /content/apex/csrc/fused_dense.cpp:75:50: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "                                                      ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:209:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "         const auto& the_type = TYPE;                                               \\\n",
            "                                ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/fused_dense.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/fused_dense.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:211:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "         at::ScalarType _st = ::detail::scalar_type(the_type);                      \\\n",
            "                                                            ^\n",
            "    /content/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "       ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:109:23: note: declared here\n",
            "     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "                           ^~~~~~~~~~~\n",
            "    /content/apex/csrc/fused_dense.cpp: In lambda function:\n",
            "    /content/apex/csrc/fused_dense.cpp:77:15: warning: unused variable ‘d_b_ptr’ [-Wunused-variable]\n",
            "         scalar_t* d_b_ptr = d_bias.data_ptr<scalar_t>();\n",
            "                   ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "       ^\n",
            "    /content/apex/csrc/fused_dense.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = linear_bias_backward_cuda<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "       ^\n",
            "    /content/apex/csrc/fused_dense.cpp: In lambda function:\n",
            "    /content/apex/csrc/fused_dense.cpp:77:15: warning: unused variable ‘d_b_ptr’ [-Wunused-variable]\n",
            "         scalar_t* d_b_ptr = d_bias.data_ptr<scalar_t>();\n",
            "                   ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "       ^\n",
            "    /content/apex/csrc/fused_dense.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = linear_bias_backward_cuda<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "       ^\n",
            "    /content/apex/csrc/fused_dense.cpp: In lambda function:\n",
            "    /content/apex/csrc/fused_dense.cpp:77:15: warning: unused variable ‘d_b_ptr’ [-Wunused-variable]\n",
            "         scalar_t* d_b_ptr = d_bias.data_ptr<scalar_t>();\n",
            "                   ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "       ^\n",
            "    /content/apex/csrc/fused_dense.cpp:78:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = linear_bias_backward_cuda<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/fused_dense.cpp:75:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "       ^\n",
            "    /content/apex/csrc/fused_dense.cpp: In function ‘std::vector<at::Tensor> linear_gelu_linear_forward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor)’:\n",
            "    /content/apex/csrc/fused_dense.cpp:106:70: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       auto output1 = at::empty({batch_size, hidden_features}, input.type());\n",
            "                                                                          ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/fused_dense.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    /content/apex/csrc/fused_dense.cpp:107:70: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       auto gelu_in = at::empty({batch_size, hidden_features}, input.type());\n",
            "                                                                          ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/fused_dense.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    /content/apex/csrc/fused_dense.cpp:108:67: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       auto output2 = at::empty({batch_size, out_features}, input.type());\n",
            "                                                                       ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/fused_dense.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    /content/apex/csrc/fused_dense.cpp:111:55: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       auto lt_workspace = at::empty({1 << 22}, input.type());\n",
            "                                                           ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/fused_dense.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/fused_dense.cpp:1:\n",
            "    /content/apex/csrc/fused_dense.cpp: In lambda function:\n",
            "    /content/apex/csrc/fused_dense.cpp:113:50: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_gelu_linear_forward\", [&] {\n",
            "                                                      ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:209:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "         const auto& the_type = TYPE;                                               \\\n",
            "                                ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/fused_dense.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/fused_dense.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:211:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "         at::ScalarType _st = ::detail::scalar_type(the_type);                      \\\n",
            "                                                            ^\n",
            "    /content/apex/csrc/fused_dense.cpp:113:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_gelu_linear_forward\", [&] {\n",
            "       ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:109:23: note: declared here\n",
            "     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "                           ^~~~~~~~~~~\n",
            "    /content/apex/csrc/fused_dense.cpp: In lambda function:\n",
            "    /content/apex/csrc/fused_dense.cpp:118:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = linear_gelu_linear_forward_cuda<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/fused_dense.cpp:113:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_gelu_linear_forward\", [&] {\n",
            "       ^\n",
            "    /content/apex/csrc/fused_dense.cpp: In lambda function:\n",
            "    /content/apex/csrc/fused_dense.cpp:118:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = linear_gelu_linear_forward_cuda<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/fused_dense.cpp:113:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_gelu_linear_forward\", [&] {\n",
            "       ^\n",
            "    /content/apex/csrc/fused_dense.cpp: In lambda function:\n",
            "    /content/apex/csrc/fused_dense.cpp:118:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = linear_gelu_linear_forward_cuda<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/fused_dense.cpp:113:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_gelu_linear_forward\", [&] {\n",
            "       ^\n",
            "    /content/apex/csrc/fused_dense.cpp: In function ‘std::vector<at::Tensor> linear_gelu_linear_backward(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor)’:\n",
            "    /content/apex/csrc/fused_dense.cpp:149:73: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       auto d_weight1 = at::empty({hidden_features, in_features}, input.type());\n",
            "                                                                             ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/fused_dense.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    /content/apex/csrc/fused_dense.cpp:150:74: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       auto d_weight2 = at::empty({out_features, hidden_features}, input.type());\n",
            "                                                                              ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/fused_dense.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    /content/apex/csrc/fused_dense.cpp:151:58: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       auto d_bias1 = at::empty({hidden_features}, input.type());\n",
            "                                                              ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/fused_dense.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    /content/apex/csrc/fused_dense.cpp:152:55: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       auto d_bias2 = at::empty({out_features}, input.type());\n",
            "                                                           ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/fused_dense.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    /content/apex/csrc/fused_dense.cpp:153:66: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       auto d_input = at::empty({batch_size, in_features}, input.type());\n",
            "                                                                      ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/fused_dense.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    /content/apex/csrc/fused_dense.cpp:154:72: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       auto d_output1 = at::empty({batch_size, hidden_features}, input.type());\n",
            "                                                                            ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/fused_dense.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    /content/apex/csrc/fused_dense.cpp:157:55: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       auto lt_workspace = at::empty({1 << 22}, input.type());\n",
            "                                                           ^\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/fused_dense.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/fused_dense.cpp:1:\n",
            "    /content/apex/csrc/fused_dense.cpp: In lambda function:\n",
            "    /content/apex/csrc/fused_dense.cpp:159:50: warning: ‘at::DeprecatedTypeProperties& at::Tensor::type() const’ is deprecated: Tensor.type() is deprecated. Instead use Tensor.options(), which in many cases (e.g. in a constructor) is a drop-in replacement. If you were using data from type(), that is now available from Tensor itself, so instead of tensor.type().scalar_type(), use tensor.scalar_type() instead and instead of tensor.type().backend() use tensor.device(). [-Wdeprecated-declarations]\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "                                                      ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:209:28: note: in definition of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "         const auto& the_type = TYPE;                                               \\\n",
            "                                ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Tensor.h:3:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Context.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:9,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/fused_dense.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/TensorBody.h:303:30: note: declared here\n",
            "       DeprecatedTypeProperties & type() const {\n",
            "                                  ^~~~\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ATen.h:13:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:8,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/fused_dense.cpp:1:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:211:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated: passing at::DeprecatedTypeProperties to an AT_DISPATCH macro is deprecated, pass an at::ScalarType instead [-Wdeprecated-declarations]\n",
            "         at::ScalarType _st = ::detail::scalar_type(the_type);                      \\\n",
            "                                                            ^\n",
            "    /content/apex/csrc/fused_dense.cpp:159:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "       ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:109:23: note: declared here\n",
            "     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties& t) {\n",
            "                           ^~~~~~~~~~~\n",
            "    /content/apex/csrc/fused_dense.cpp: In lambda function:\n",
            "    /content/apex/csrc/fused_dense.cpp:162:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = linear_gelu_linear_backward_cuda<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:214:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Double, double, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/fused_dense.cpp:159:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "       ^\n",
            "    /content/apex/csrc/fused_dense.cpp: In lambda function:\n",
            "    /content/apex/csrc/fused_dense.cpp:162:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = linear_gelu_linear_backward_cuda<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:215:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Float, float, __VA_ARGS__)    \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/fused_dense.cpp:159:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "       ^\n",
            "    /content/apex/csrc/fused_dense.cpp: In lambda function:\n",
            "    /content/apex/csrc/fused_dense.cpp:162:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = linear_gelu_linear_backward_cuda<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:56:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE_USING_HINT’\n",
            "         return __VA_ARGS__();                                                        \\\n",
            "                ^~~~~~~~~~~\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Dispatch.h:216:7: note: in expansion of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "           AT_PRIVATE_CASE_TYPE(NAME, at::ScalarType::Half, at::Half, __VA_ARGS__)  \\\n",
            "           ^~~~~~~~~~~~~~~~~~~~\n",
            "    /content/apex/csrc/fused_dense.cpp:159:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(input.type(), \"linear_bias_backward\", [&] {\n",
            "       ^\n",
            "    [2/2] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/apex/build/temp.linux-x86_64-3.7/csrc/fused_dense_cuda.o.d -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/fused_dense_cuda.cu -o /content/apex/build/temp.linux-x86_64-3.7/csrc/fused_dense_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=fused_dense_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "    /content/apex/csrc/fused_dense_cuda.cu(1148): warning: variable \"beta_zero\" was declared but never referenced\n",
            "\n",
            "    /content/apex/csrc/fused_dense_cuda.cu(1272): warning: variable \"alpha\" was declared but never referenced\n",
            "\n",
            "    /content/apex/csrc/fused_dense_cuda.cu(1273): warning: variable \"beta_zero\" was declared but never referenced\n",
            "\n",
            "    /content/apex/csrc/fused_dense_cuda.cu(1274): warning: variable \"status\" was declared but never referenced\n",
            "\n",
            "    /content/apex/csrc/fused_dense_cuda.cu(1329): warning: variable \"alpha\" was declared but never referenced\n",
            "\n",
            "    /content/apex/csrc/fused_dense_cuda.cu(1330): warning: variable \"beta_zero\" was declared but never referenced\n",
            "\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 /content/apex/build/temp.linux-x86_64-3.7/csrc/fused_dense.o /content/apex/build/temp.linux-x86_64-3.7/csrc/fused_dense_cuda.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.7/fused_dense_cuda.cpython-37m-x86_64-linux-gnu.so\n",
            "    building 'scaled_upper_triang_masked_softmax_cuda' extension\n",
            "    creating /content/apex/build/temp.linux-x86_64-3.7/csrc/megatron\n",
            "    Emitting ninja build file /content/apex/build/temp.linux-x86_64-3.7/build.ninja...\n",
            "    Compiling objects...\n",
            "    Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "    [1/2] c++ -MMD -MF /content/apex/build/temp.linux-x86_64-3.7/csrc/megatron/scaled_upper_triang_masked_softmax.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/apex/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/megatron/scaled_upper_triang_masked_softmax.cpp -o /content/apex/build/temp.linux-x86_64-3.7/csrc/megatron/scaled_upper_triang_masked_softmax.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=scaled_upper_triang_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:140:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:13,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/megatron/scaled_upper_triang_masked_softmax.cpp:18:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:83:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            "     #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            "\n",
            "    [2/2] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/apex/build/temp.linux-x86_64-3.7/csrc/megatron/scaled_upper_triang_masked_softmax_cuda.o.d -I/content/apex/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/megatron/scaled_upper_triang_masked_softmax_cuda.cu -o /content/apex/build/temp.linux-x86_64-3.7/csrc/megatron/scaled_upper_triang_masked_softmax_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=scaled_upper_triang_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 /content/apex/build/temp.linux-x86_64-3.7/csrc/megatron/scaled_upper_triang_masked_softmax.o /content/apex/build/temp.linux-x86_64-3.7/csrc/megatron/scaled_upper_triang_masked_softmax_cuda.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.7/scaled_upper_triang_masked_softmax_cuda.cpython-37m-x86_64-linux-gnu.so\n",
            "    building 'scaled_masked_softmax_cuda' extension\n",
            "    Emitting ninja build file /content/apex/build/temp.linux-x86_64-3.7/build.ninja...\n",
            "    Compiling objects...\n",
            "    Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "    [1/2] c++ -MMD -MF /content/apex/build/temp.linux-x86_64-3.7/csrc/megatron/scaled_masked_softmax.o.d -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/content/apex/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/megatron/scaled_masked_softmax.cpp -o /content/apex/build/temp.linux-x86_64-3.7/csrc/megatron/scaled_masked_softmax.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=scaled_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "    In file included from /usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:140:0,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:13,\n",
            "                     from /usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from /content/apex/csrc/megatron/scaled_masked_softmax.cpp:18:\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:83:0: warning: ignoring #pragma omp parallel [-Wunknown-pragmas]\n",
            "     #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            "\n",
            "    [2/2] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/apex/build/temp.linux-x86_64-3.7/csrc/megatron/scaled_masked_softmax_cuda.o.d -I/content/apex/csrc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c -c /content/apex/csrc/megatron/scaled_masked_softmax_cuda.cu -o /content/apex/build/temp.linux-x86_64-3.7/csrc/megatron/scaled_masked_softmax_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -O3 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ --expt-relaxed-constexpr --expt-extended-lambda -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=scaled_masked_softmax_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=compute_37 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "    nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 /content/apex/build/temp.linux-x86_64-3.7/csrc/megatron/scaled_masked_softmax.o /content/apex/build/temp.linux-x86_64-3.7/csrc/megatron/scaled_masked_softmax_cuda.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda_cu -ltorch_cuda_cpp -o build/lib.linux-x86_64-3.7/scaled_masked_softmax_cuda.cpython-37m-x86_64-linux-gnu.so\n",
            "    running install_lib\n",
            "    copying build/lib.linux-x86_64-3.7/scaled_upper_triang_masked_softmax_cuda.cpython-37m-x86_64-linux-gnu.so -> /usr/local/lib/python3.7/dist-packages\n",
            "    copying build/lib.linux-x86_64-3.7/fused_layer_norm_cuda.cpython-37m-x86_64-linux-gnu.so -> /usr/local/lib/python3.7/dist-packages\n",
            "    copying build/lib.linux-x86_64-3.7/scaled_masked_softmax_cuda.cpython-37m-x86_64-linux-gnu.so -> /usr/local/lib/python3.7/dist-packages\n",
            "    copying build/lib.linux-x86_64-3.7/apex_C.cpython-37m-x86_64-linux-gnu.so -> /usr/local/lib/python3.7/dist-packages\n",
            "    copying build/lib.linux-x86_64-3.7/fused_dense_cuda.cpython-37m-x86_64-linux-gnu.so -> /usr/local/lib/python3.7/dist-packages\n",
            "    copying build/lib.linux-x86_64-3.7/mlp_cuda.cpython-37m-x86_64-linux-gnu.so -> /usr/local/lib/python3.7/dist-packages\n",
            "    copying build/lib.linux-x86_64-3.7/amp_C.cpython-37m-x86_64-linux-gnu.so -> /usr/local/lib/python3.7/dist-packages\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/normalization\n",
            "    copying build/lib.linux-x86_64-3.7/apex/normalization/fused_layer_norm.py -> /usr/local/lib/python3.7/dist-packages/apex/normalization\n",
            "    copying build/lib.linux-x86_64-3.7/apex/normalization/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/normalization\n",
            "    copying build/lib.linux-x86_64-3.7/apex/_autocast_utils.py -> /usr/local/lib/python3.7/dist-packages/apex\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.7/apex/optimizers/fused_novograd.py -> /usr/local/lib/python3.7/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.7/apex/optimizers/fused_lamb.py -> /usr/local/lib/python3.7/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.7/apex/optimizers/fused_adagrad.py -> /usr/local/lib/python3.7/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.7/apex/optimizers/fused_adam.py -> /usr/local/lib/python3.7/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.7/apex/optimizers/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.7/apex/optimizers/fused_sgd.py -> /usr/local/lib/python3.7/dist-packages/apex/optimizers\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.7/apex/fp16_utils/fp16util.py -> /usr/local/lib/python3.7/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.7/apex/fp16_utils/fp16_optimizer.py -> /usr/local/lib/python3.7/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.7/apex/fp16_utils/loss_scaler.py -> /usr/local/lib/python3.7/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.7/apex/fp16_utils/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/fp16_utils\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/fused_dense\n",
            "    copying build/lib.linux-x86_64-3.7/apex/fused_dense/fused_dense.py -> /usr/local/lib/python3.7/dist-packages/apex/fused_dense\n",
            "    copying build/lib.linux-x86_64-3.7/apex/fused_dense/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/fused_dense\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/transformer\n",
            "    copying build/lib.linux-x86_64-3.7/apex/transformer/enums.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer\n",
            "    copying build/lib.linux-x86_64-3.7/apex/transformer/parallel_state.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/transformer/functional\n",
            "    copying build/lib.linux-x86_64-3.7/apex/transformer/functional/fused_softmax.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/functional\n",
            "    copying build/lib.linux-x86_64-3.7/apex/transformer/functional/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/functional\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel/tests\n",
            "    copying build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel/tests/commons.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel/tests\n",
            "    copying build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel/tests/global_vars.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel/tests\n",
            "    copying build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel/tests/arguments.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel/tests\n",
            "    copying build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel/tests/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel/tests\n",
            "    copying build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel/mappings.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel\n",
            "    copying build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel/data.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel\n",
            "    copying build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel/utils.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel\n",
            "    copying build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel/random.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel\n",
            "    copying build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel/cross_entropy.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel\n",
            "    copying build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel/microbatches.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel\n",
            "    copying build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel\n",
            "    copying build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel/layers.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel\n",
            "    copying build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel/memory.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel\n",
            "    copying build/lib.linux-x86_64-3.7/apex/transformer/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/transformer\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/contrib\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/optimizers/distributed_fused_adam.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/optimizers/fp16_optimizer.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/optimizers/fused_lamb.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/optimizers/fused_adam.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/optimizers/distributed_fused_lamb.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/optimizers/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/optimizers/distributed_fused_adam_v3.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/optimizers/fused_sgd.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/optimizers/distributed_fused_adam_v2.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/contrib/transducer\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/transducer/transducer.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/transducer\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/transducer/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/transducer\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/contrib/bottleneck\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/bottleneck/bottleneck.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/bottleneck\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/bottleneck/bottleneck_module_test.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/bottleneck\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/bottleneck/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/bottleneck\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/bottleneck/test.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/bottleneck\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/contrib/xentropy\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/xentropy/softmax_xentropy.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/xentropy\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/xentropy/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/xentropy\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/contrib/layer_norm\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/layer_norm/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/layer_norm\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/layer_norm/layer_norm.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/layer_norm\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/contrib/fmha\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/fmha/fmha.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/fmha\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/fmha/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/fmha\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/contrib/groupbn\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/groupbn/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/groupbn\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/groupbn/batch_norm.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/groupbn\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/self_multihead_attn.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/self_multihead_attn_func.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn/encdec_multihead_attn.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/contrib/sparsity\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/sparsity/asp.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/sparsity\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/sparsity/sparse_masklib.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/sparsity\n",
            "    copying build/lib.linux-x86_64-3.7/apex/contrib/sparsity/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/contrib/sparsity\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.7/apex/amp/scaler.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.7/apex/amp/_initialize.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.7/apex/amp/amp.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.7/apex/amp/frontend.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.7/apex/amp/_amp_state.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.7/apex/amp/utils.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.7/apex/amp/__version__.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.7/apex/amp/wrap.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.7/apex/amp/opt.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.7/apex/amp/compat.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.7/apex/amp/lists/torch_overrides.py -> /usr/local/lib/python3.7/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.7/apex/amp/lists/functional_overrides.py -> /usr/local/lib/python3.7/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.7/apex/amp/lists/tensor_overrides.py -> /usr/local/lib/python3.7/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.7/apex/amp/lists/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.7/apex/amp/_process_optimizer.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.7/apex/amp/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.7/apex/amp/rnn_compat.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.7/apex/amp/handle.py -> /usr/local/lib/python3.7/dist-packages/apex/amp\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/pyprof\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/pyprof/nvtx\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/nvtx/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/nvtx\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/nvtx/nvmarker.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/nvtx\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/parse/__main__.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/parse/db.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/parse/kernel.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/parse/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/parse/nvvp.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/parse/parse.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/randomSample.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/prof.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/convert.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/embedding.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/pooling.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/reduction.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/conv.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/data.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/pointwise.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/blas.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/softmax.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/utility.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/__main__.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/optim.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/index_slice_join_mutate.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/usage.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/base.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/linear.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/misc.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/recurrentCell.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/activation.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/loss.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/normalization.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/dropout.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.7/apex/pyprof/prof/output.py -> /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.7/apex/parallel/multiproc.py -> /usr/local/lib/python3.7/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.7/apex/parallel/sync_batchnorm.py -> /usr/local/lib/python3.7/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.7/apex/parallel/sync_batchnorm_kernel.py -> /usr/local/lib/python3.7/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.7/apex/parallel/optimized_sync_batchnorm_kernel.py -> /usr/local/lib/python3.7/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.7/apex/parallel/optimized_sync_batchnorm.py -> /usr/local/lib/python3.7/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.7/apex/parallel/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.7/apex/parallel/distributed.py -> /usr/local/lib/python3.7/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.7/apex/parallel/LARC.py -> /usr/local/lib/python3.7/dist-packages/apex/parallel\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.7/apex/RNN/models.py -> /usr/local/lib/python3.7/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.7/apex/RNN/cells.py -> /usr/local/lib/python3.7/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.7/apex/RNN/RNNBackend.py -> /usr/local/lib/python3.7/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.7/apex/RNN/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/RNN\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/multi_tensor_apply\n",
            "    copying build/lib.linux-x86_64-3.7/apex/multi_tensor_apply/multi_tensor_apply.py -> /usr/local/lib/python3.7/dist-packages/apex/multi_tensor_apply\n",
            "    copying build/lib.linux-x86_64-3.7/apex/multi_tensor_apply/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/multi_tensor_apply\n",
            "    copying build/lib.linux-x86_64-3.7/apex/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/mlp\n",
            "    copying build/lib.linux-x86_64-3.7/apex/mlp/mlp.py -> /usr/local/lib/python3.7/dist-packages/apex/mlp\n",
            "    copying build/lib.linux-x86_64-3.7/apex/mlp/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/mlp\n",
            "    creating /usr/local/lib/python3.7/dist-packages/apex/reparameterization\n",
            "    copying build/lib.linux-x86_64-3.7/apex/reparameterization/reparameterization.py -> /usr/local/lib/python3.7/dist-packages/apex/reparameterization\n",
            "    copying build/lib.linux-x86_64-3.7/apex/reparameterization/weight_norm.py -> /usr/local/lib/python3.7/dist-packages/apex/reparameterization\n",
            "    copying build/lib.linux-x86_64-3.7/apex/reparameterization/__init__.py -> /usr/local/lib/python3.7/dist-packages/apex/reparameterization\n",
            "    copying build/lib.linux-x86_64-3.7/syncbn.cpython-37m-x86_64-linux-gnu.so -> /usr/local/lib/python3.7/dist-packages\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/normalization/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/_autocast_utils.py to _autocast_utils.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/optimizers/fused_novograd.py to fused_novograd.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/optimizers/fused_lamb.py to fused_lamb.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/optimizers/fused_adagrad.py to fused_adagrad.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/optimizers/fused_adam.py to fused_adam.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/optimizers/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/optimizers/fused_sgd.py to fused_sgd.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/fp16_utils/fp16util.py to fp16util.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/fp16_utils/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/fused_dense/fused_dense.py to fused_dense.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/fused_dense/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/enums.py to enums.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/parallel_state.py to parallel_state.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/functional/fused_softmax.py to fused_softmax.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/functional/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel/tests/commons.py to commons.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel/tests/global_vars.py to global_vars.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel/tests/arguments.py to arguments.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel/tests/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel/mappings.py to mappings.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel/data.py to data.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel/utils.py to utils.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel/random.py to random.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel/cross_entropy.py to cross_entropy.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel/microbatches.py to microbatches.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel/layers.py to layers.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/tensor_parallel/memory.py to memory.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/transformer/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers/distributed_fused_adam.py to distributed_fused_adam.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers/fused_lamb.py to fused_lamb.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers/fused_adam.py to fused_adam.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py to distributed_fused_lamb.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers/distributed_fused_adam_v3.py to distributed_fused_adam_v3.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers/fused_sgd.py to fused_sgd.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/optimizers/distributed_fused_adam_v2.py to distributed_fused_adam_v2.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/transducer/transducer.py to transducer.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/transducer/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/bottleneck/bottleneck.py to bottleneck.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/bottleneck/bottleneck_module_test.py to bottleneck_module_test.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/bottleneck/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/bottleneck/test.py to test.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/xentropy/softmax_xentropy.py to softmax_xentropy.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/xentropy/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/layer_norm/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/layer_norm/layer_norm.py to layer_norm.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/fmha/fmha.py to fmha.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/fmha/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/groupbn/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/groupbn/batch_norm.py to batch_norm.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py to fast_encdec_multihead_attn_func.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py to fast_self_multihead_attn_norm_add_func.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn/mask_softmax_dropout_func.py to mask_softmax_dropout_func.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn_func.py to encdec_multihead_attn_func.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn/self_multihead_attn.py to self_multihead_attn.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn/self_multihead_attn_func.py to self_multihead_attn_func.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py to fast_encdec_multihead_attn_norm_add_func.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py to fast_self_multihead_attn_func.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn.py to encdec_multihead_attn.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/sparsity/asp.py to asp.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/sparsity/sparse_masklib.py to sparse_masklib.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/contrib/sparsity/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/scaler.py to scaler.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/_initialize.py to _initialize.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/amp.py to amp.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/frontend.py to frontend.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/_amp_state.py to _amp_state.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/utils.py to utils.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/__version__.py to __version__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/wrap.py to wrap.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/opt.py to opt.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/compat.py to compat.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/lists/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/_process_optimizer.py to _process_optimizer.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/rnn_compat.py to rnn_compat.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/amp/handle.py to handle.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/nvtx/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/nvtx/nvmarker.py to nvmarker.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/parse/__main__.py to __main__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/parse/db.py to db.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/parse/kernel.py to kernel.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/parse/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/parse/nvvp.py to nvvp.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/parse/parse.py to parse.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/randomSample.py to randomSample.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/prof.py to prof.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/convert.py to convert.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/embedding.py to embedding.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/pooling.py to pooling.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/reduction.py to reduction.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/conv.py to conv.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/data.py to data.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/pointwise.py to pointwise.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/blas.py to blas.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/softmax.py to softmax.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/utility.py to utility.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/__main__.py to __main__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/optim.py to optim.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/index_slice_join_mutate.py to index_slice_join_mutate.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/usage.py to usage.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/base.py to base.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/linear.py to linear.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/misc.py to misc.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/recurrentCell.py to recurrentCell.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/activation.py to activation.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/loss.py to loss.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/normalization.py to normalization.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/dropout.py to dropout.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/pyprof/prof/output.py to output.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/parallel/multiproc.py to multiproc.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/parallel/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/parallel/distributed.py to distributed.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/parallel/LARC.py to LARC.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/RNN/models.py to models.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/RNN/cells.py to cells.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/RNN/RNNBackend.py to RNNBackend.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/RNN/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/multi_tensor_apply/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/mlp/mlp.py to mlp.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/mlp/__init__.py to __init__.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/reparameterization/reparameterization.py to reparameterization.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/reparameterization/weight_norm.py to weight_norm.cpython-37.pyc\n",
            "    byte-compiling /usr/local/lib/python3.7/dist-packages/apex/reparameterization/__init__.py to __init__.cpython-37.pyc\n",
            "    running install_egg_info\n",
            "    running egg_info\n",
            "    creating apex.egg-info\n",
            "    writing apex.egg-info/PKG-INFO\n",
            "    writing dependency_links to apex.egg-info/dependency_links.txt\n",
            "    writing top-level names to apex.egg-info/top_level.txt\n",
            "    writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "    adding license file 'LICENSE'\n",
            "    writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "    Copying apex.egg-info to /usr/local/lib/python3.7/dist-packages/apex-0.1-py3.7.egg-info\n",
            "    running install_scripts\n",
            "    writing list of installed files to '/tmp/pip-record-zyevphjd/install-record.txt'\n",
            "    Running setup.py install for apex ... \u001b[?25l\u001b[?25hdone\n",
            "Successfully installed apex-0.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oc-EidleBfeB"
      },
      "source": [
        "## Install PyCocoTools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwuWoBOxFV6v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8600b6ff-1b3c-4ec4-e1ec-711a1a2320f3"
      },
      "source": [
        "!pip3 install cython; pip3 install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (0.29.24)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-j2xvimia\n",
            "  Running command git clone --filter=blob:none -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-j2xvimia\n",
            "  Resolved https://github.com/cocodataset/cocoapi.git to commit 8c9bcc3cf640524c4c20a9c40e89cb6a2f2fa0e9\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (57.4.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (0.29.24)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.19.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools==2.0) (1.15.0)\n",
            "Building wheels for collected packages: pycocotools\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0-cp37-cp37m-linux_x86_64.whl size=263929 sha256=30b5e16f11442834625f12a222712b22bda9cd6c43a79645d5185d522cbc0331\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-q4rj4l6n/wheels/e2/6b/1d/344ac773c7495ea0b85eb228bc66daec7400a143a92d36b7b1\n",
            "Successfully built pycocotools\n",
            "Installing collected packages: pycocotools\n",
            "  Attempting uninstall: pycocotools\n",
            "    Found existing installation: pycocotools 2.0.2\n",
            "    Uninstalling pycocotools-2.0.2:\n",
            "      Successfully uninstalled pycocotools-2.0.2\n",
            "Successfully installed pycocotools-2.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEdiT0rJBmRA"
      },
      "source": [
        "We'll download our dataset from Roboflow API . Use the \"**Pascal VOC**\"\n",
        "\n",
        "**YOLOX Only accept two formats till now \"Pascal VOC\" and \"COCO\"**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJkU0eH-VgCn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17787c3f-520c-45d8-e1f1-c2dcfc46cbcb"
      },
      "source": [
        "#to get your roboflow code below please follow the link output by this cell\n",
        "!pip -q install roboflow\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(model_format=\"voc\", notebook=\"yolox\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "     |████████████████████████████████| 178 kB 1.5 MB/s            \n",
            "     |████████████████████████████████| 1.1 MB 5.6 MB/s            \n",
            "     |████████████████████████████████| 138 kB 44.9 MB/s            \n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "     |████████████████████████████████| 596 kB 36.9 MB/s            \n",
            "     |████████████████████████████████| 62 kB 665 kB/s             \n",
            "\u001b[?25h  Building wheel for roboflow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.8.0+cu111 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "upload and label your dataset, and get an API KEY here: https://app.roboflow.com/?model=voc&ref=yolox\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp1L8zdwGo_j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c81fd27-3961-45fe-ee9c-bfcb14908e11"
      },
      "source": [
        "%cd /content/\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"U52l26I1vE0xSQh5Obr5\")\n",
        "project = rf.workspace().project(\"yolox-yi6ft\")\n",
        "dataset = project.version(4).download(\"voc\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in yolox-4 to voc: 100% [122324960 / 122324960] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to yolox-4 in voc:: 100%|██████████| 9871/9871 [00:09<00:00, 1001.33it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr4cOxxbVuHB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38efd3ba-e0a8-4cba-af58-17e6b6ac5f3e"
      },
      "source": [
        "%cd YOLOX/\n",
        "!ln -s {dataset.location}/train/ ./datasets/VOCdevkit"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/YOLOX\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agZSFjXLByrv"
      },
      "source": [
        "## Format Your Data Appropriately"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xTRtDWrIw_D",
        "outputId": "e3ea0eeb-cd1a-4dda-c52a-5b4a7df08156"
      },
      "source": [
        "%mkdir \"/content/YOLOX/datasets/VOCdevkit/VOC2007\"\n",
        "!python3 voc_txt.py \"/content/YOLOX/datasets/VOCdevkit/\"\n",
        "%mkdir \"/content/YOLOX/datasets/VOCdevkit/VOC2012\"\n",
        "!cp -r \"/content/YOLOX/datasets/VOCdevkit/VOC2007/.\" \"/content/YOLOX/datasets/VOCdevkit/VOC2012\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train and val size: 3107\n",
            "train size: 2485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW8iyuMyB3bc"
      },
      "source": [
        "## Change the Classes\n",
        "Make sure you change the classes based on what your dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rohuAE541Nug"
      },
      "source": [
        "from IPython.core.magic import register_line_cell_magic\n",
        "\n",
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h5PM8Ft1OjG"
      },
      "source": [
        "##REPLACE this cell with your classnames stripped of whitespace and lowercase\n",
        "%%writetemplate /content/YOLOX/yolox/data/datasets/voc_classes.py\n",
        "\n",
        "VOC_CLASSES = (\n",
        "  \"beans\",\n",
        "  \"cake\",\n",
        "  \"candy\",\n",
        "  \"cereal\",\n",
        "  \"chips\",\n",
        "  \"chocolate\",\n",
        "  \"coffee\",\n",
        "  \"corn\",\n",
        "  \"fish\",\n",
        "  \"flour\",\n",
        "  \"honey\",\n",
        "  \"jam\",\n",
        "  \"juice\",\n",
        "  \"milk\",\n",
        "  \"nuts\",\n",
        "  \"oil\",\n",
        "  \"pasta\",\n",
        "  \"rice\",\n",
        "  \"soda\",\n",
        "  \"spices\",\n",
        "  \"sugar\",\n",
        "  \"tea\",\n",
        "  \"tomato_sauce\",\n",
        "  \"vinegar\",\n",
        "  \"water\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu6_LzErQRSU"
      },
      "source": [
        "##REPLACE this cell with your classnames stripped of whitespace and lowercase\n",
        "%%writetemplate /content/YOLOX/yolox/data/datasets/coco_classes.py\n",
        "\n",
        "COCO_CLASSES = (\n",
        "  \"beans\",\n",
        "  \"cake\",\n",
        "  \"candy\",\n",
        "  \"cereal\",\n",
        "  \"chips\",\n",
        "  \"chocolate\",\n",
        "  \"coffee\",\n",
        "  \"corn\",\n",
        "  \"fish\",\n",
        "  \"flour\",\n",
        "  \"honey\",\n",
        "  \"jam\",\n",
        "  \"juice\",\n",
        "  \"milk\",\n",
        "  \"nuts\",\n",
        "  \"oil\",\n",
        "  \"pasta\",\n",
        "  \"rice\",\n",
        "  \"soda\",\n",
        "  \"spices\",\n",
        "  \"sugar\",\n",
        "  \"tea\",\n",
        "  \"tomato_sauce\",\n",
        "  \"vinegar\",\n",
        "  \"water\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uAaf5AKSE_E"
      },
      "source": [
        "Set the number of classes you have in your dataset in te `NUM_CLASSES` variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxA0JmWqwU_M"
      },
      "source": [
        "NUM_CLASSES = 25\n",
        "!sed -i -e 's/self.num_classes = 20/self.num_classes = {NUM_CLASSES}/g' \"/content/YOLOX/exps/example/yolox_voc/yolox_voc_s.py\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiYvw_GGKaro"
      },
      "source": [
        "# Download Pretrained Model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsOCh9hRKbIw",
        "outputId": "10ac5207-5736-4679-ba67-b6040a823464"
      },
      "source": [
        "%cd /content/\n",
        "!wget https://github.com/amrmahmoud9/YOLOX/raw/main/best_pth.tar\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "--2021-10-22 12:39:45--  https://github.com/amrmahmoud9/YOLOX/raw/main/best_pth.tar\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/amrmahmoud9/YOLOX/main/best_pth.tar [following]\n",
            "--2021-10-22 12:39:45--  https://raw.githubusercontent.com/amrmahmoud9/YOLOX/main/best_pth.tar\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 71924253 (69M) [application/octet-stream]\n",
            "Saving to: ‘best_pth.tar’\n",
            "\n",
            "best_pth.tar        100%[===================>]  68.59M   181MB/s    in 0.4s    \n",
            "\n",
            "2021-10-22 12:39:46 (181 MB/s) - ‘best_pth.tar’ saved [71924253/71924253]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TabCpJOCRti"
      },
      "source": [
        "# Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5h536amH32Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8dc18ae-07c3-4a8a-e100-6bbf08fc4770"
      },
      "source": [
        "%cd /content/YOLOX/\n",
        "!python tools/train.py -f exps/example/yolox_voc/yolox_voc_s.py -d 1 -b 8 --fp16 -o -c /content/gdrive/MyDrive/Sprints/yolox_voc_s/yolox_voc_s/latest_ckpt.pth.tar  --resume"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/YOLOX\n",
            "\u001b[32m2021-10-22 02:25:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m125\u001b[0m - \u001b[1margs: Namespace(batch_size=8, ckpt='/content/gdrive/MyDrive/Sprints/yolox_voc_s/yolox_voc_s/latest_ckpt.pth.tar', devices=1, dist_backend='nccl', dist_url=None, exp_file='exps/example/yolox_voc/yolox_voc_s.py', experiment_name='yolox_voc_s', fp16=True, local_rank=0, machine_rank=0, name=None, num_machines=1, occupy=True, opts=[], resume=True, start_epoch=None)\u001b[0m\n",
            "\u001b[32m2021-10-22 02:25:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m126\u001b[0m - \u001b[1mexp value:\n",
            "╒══════════════════╤═══════════════════════════════════════════════════════════╕\n",
            "│ keys             │ values                                                    │\n",
            "╞══════════════════╪═══════════════════════════════════════════════════════════╡\n",
            "│ seed             │ None                                                      │\n",
            "├──────────────────┼───────────────────────────────────────────────────────────┤\n",
            "│ output_dir       │ '/content/gdrive/MyDrive/Sprints/yolox_voc_s/yolox_voc_s' │\n",
            "├──────────────────┼───────────────────────────────────────────────────────────┤\n",
            "│ print_interval   │ 10                                                        │\n",
            "├──────────────────┼───────────────────────────────────────────────────────────┤\n",
            "│ eval_interval    │ 10                                                        │\n",
            "├──────────────────┼───────────────────────────────────────────────────────────┤\n",
            "│ num_classes      │ 25                                                        │\n",
            "├──────────────────┼───────────────────────────────────────────────────────────┤\n",
            "│ depth            │ 0.33                                                      │\n",
            "├──────────────────┼───────────────────────────────────────────────────────────┤\n",
            "│ width            │ 0.5                                                       │\n",
            "├──────────────────┼───────────────────────────────────────────────────────────┤\n",
            "│ data_num_workers │ 4                                                         │\n",
            "├──────────────────┼───────────────────────────────────────────────────────────┤\n",
            "│ input_size       │ (640, 640)                                                │\n",
            "├──────────────────┼───────────────────────────────────────────────────────────┤\n",
            "│ random_size      │ (14, 26)                                                  │\n",
            "├──────────────────┼───────────────────────────────────────────────────────────┤\n",
            "│ train_ann        │ 'instances_train2017.json'                                │\n",
            "├──────────────────┼───────────────────────────────────────────────────────────┤\n",
            "│ val_ann          │ 'instances_val2017.json'                                  │\n",
            "├──────────────────┼───────────────────────────────────────────────────────────┤\n",
            "│ degrees          │ 10.0                                                      │\n",
            "├──────────────────┼───────────────────────────────────────────────────────────┤\n",
            "│ translate        │ 0.1                                                       │\n",
            "├──────────────────┼───────────────────────────────────────────────────────────┤\n",
            "│ scale            │ (0.1, 2)                                                  │\n",
            "├──────────────────┼───────────────────────────────────────────────────────────┤\n",
            "│ mscale           │ (0.8, 1.6)                                                │\n",
            "├──────────────────┼───────────────────────────────────────────────────────────┤\n",
            "│ shear            │ 2.0                                                       │\n",
            "├──────────────────┼───────────────────────────────────────────────────────────┤\n",
            "│ perspective      │ 0.0                                                       │\n",
            "├──────────────────┼───────────────────────────────────────────────────────────┤\n",
            "│ enable_mixup     │ True                                                      │\n",
            "├──────────────────┼───────────────────────────────────────────────────────────┤\n",
            "│ warmup_epochs    │ 5                                                         │\n",
            "├──────────────────┼───────────────────────────────────────────────────────────┤\n",
            "│ max_epoch        │ 300                                                       │\n",
            "├──────────────────┼───────────────────────────────────────────────────────────┤\n",
            "│ warmup_lr        │ 0                                                         │\n",
            "├──────────────────┼───────────────────────────────────────────────────────────┤\n",
            "│ basic_lr_per_img │ 0.00015625                                                │\n",
            "├──────────────────┼───────────────────────────────────────────────────────────┤\n",
            "│ scheduler        │ 'yoloxwarmcos'                                            │\n",
            "├──────────────────┼───────────────────────────────────────────────────────────┤\n",
            "│ no_aug_epochs    │ 15                                                        │\n",
            "├──────────────────┼───────────────────────────────────────────────────────────┤\n",
            "│ min_lr_ratio     │ 0.05                                                      │\n",
            "├──────────────────┼───────────────────────────────────────────────────────────┤\n",
            "│ ema              │ True                                                      │\n",
            "├──────────────────┼───────────────────────────────────────────────────────────┤\n",
            "│ weight_decay     │ 0.0005                                                    │\n",
            "├──────────────────┼───────────────────────────────────────────────────────────┤\n",
            "│ momentum         │ 0.9                                                       │\n",
            "├──────────────────┼───────────────────────────────────────────────────────────┤\n",
            "│ exp_name         │ 'yolox_voc_s'                                             │\n",
            "├──────────────────┼───────────────────────────────────────────────────────────┤\n",
            "│ test_size        │ (640, 640)                                                │\n",
            "├──────────────────┼───────────────────────────────────────────────────────────┤\n",
            "│ test_conf        │ 0.01                                                      │\n",
            "├──────────────────┼───────────────────────────────────────────────────────────┤\n",
            "│ nmsthre          │ 0.65                                                      │\n",
            "╘══════════════════╧═══════════════════════════════════════════════════════════╛\u001b[0m\n",
            "\u001b[32m2021-10-22 02:25:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m132\u001b[0m - \u001b[1mModel Summary: Params: 8.95M, Gflops: 26.69\u001b[0m\n",
            "\u001b[32m2021-10-22 02:25:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m328\u001b[0m - \u001b[1mSelected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\u001b[0m\n",
            "\u001b[32m2021-10-22 02:25:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m329\u001b[0m - \u001b[1mDefaults for this optimization level are:\u001b[0m\n",
            "\u001b[32m2021-10-22 02:25:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m331\u001b[0m - \u001b[1menabled                : True\u001b[0m\n",
            "\u001b[32m2021-10-22 02:25:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m331\u001b[0m - \u001b[1mopt_level              : O1\u001b[0m\n",
            "\u001b[32m2021-10-22 02:25:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m331\u001b[0m - \u001b[1mcast_model_type        : None\u001b[0m\n",
            "\u001b[32m2021-10-22 02:25:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m331\u001b[0m - \u001b[1mpatch_torch_functions  : True\u001b[0m\n",
            "\u001b[32m2021-10-22 02:25:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m331\u001b[0m - \u001b[1mkeep_batchnorm_fp32    : None\u001b[0m\n",
            "\u001b[32m2021-10-22 02:25:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m331\u001b[0m - \u001b[1mmaster_weights         : None\u001b[0m\n",
            "\u001b[32m2021-10-22 02:25:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m331\u001b[0m - \u001b[1mloss_scale             : dynamic\u001b[0m\n",
            "\u001b[32m2021-10-22 02:25:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m336\u001b[0m - \u001b[1mProcessing user overrides (additional kwargs that are not None)...\u001b[0m\n",
            "\u001b[32m2021-10-22 02:25:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m354\u001b[0m - \u001b[1mAfter processing overrides, optimization options are:\u001b[0m\n",
            "\u001b[32m2021-10-22 02:25:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m356\u001b[0m - \u001b[1menabled                : True\u001b[0m\n",
            "\u001b[32m2021-10-22 02:25:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m356\u001b[0m - \u001b[1mopt_level              : O1\u001b[0m\n",
            "\u001b[32m2021-10-22 02:25:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m356\u001b[0m - \u001b[1mcast_model_type        : None\u001b[0m\n",
            "\u001b[32m2021-10-22 02:25:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m356\u001b[0m - \u001b[1mpatch_torch_functions  : True\u001b[0m\n",
            "\u001b[32m2021-10-22 02:25:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m356\u001b[0m - \u001b[1mkeep_batchnorm_fp32    : None\u001b[0m\n",
            "\u001b[32m2021-10-22 02:25:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m356\u001b[0m - \u001b[1mmaster_weights         : None\u001b[0m\n",
            "\u001b[32m2021-10-22 02:25:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.frontend\u001b[0m:\u001b[36m356\u001b[0m - \u001b[1mloss_scale             : dynamic\u001b[0m\n",
            "\u001b[32m2021-10-22 02:25:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m271\u001b[0m - \u001b[1mresume training\u001b[0m\n",
            "\u001b[32m2021-10-22 02:25:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m292\u001b[0m - \u001b[1mloaded checkpoint 'True' (epoch 39)\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\u001b[32m2021-10-22 02:25:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1minit prefetcher, this might take one minute or less...\u001b[0m\n",
            "\u001b[32m2021-10-22 02:25:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m182\u001b[0m - \u001b[1mTraining start...\u001b[0m\n",
            "\u001b[32m2021-10-22 02:25:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m183\u001b[0m - \u001b[1m\n",
            "YOLOX(\n",
            "  (backbone): YOLOPAFPN(\n",
            "    (backbone): CSPDarknet(\n",
            "      (stem): Focus(\n",
            "        (conv): BaseConv(\n",
            "          (conv): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (dark2): Sequential(\n",
            "        (0): BaseConv(\n",
            "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): CSPLayer(\n",
            "          (conv1): BaseConv(\n",
            "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv2): BaseConv(\n",
            "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv3): BaseConv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (m): Sequential(\n",
            "            (0): Bottleneck(\n",
            "              (conv1): BaseConv(\n",
            "                (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (conv2): BaseConv(\n",
            "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (dark3): Sequential(\n",
            "        (0): BaseConv(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): CSPLayer(\n",
            "          (conv1): BaseConv(\n",
            "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv2): BaseConv(\n",
            "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv3): BaseConv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (m): Sequential(\n",
            "            (0): Bottleneck(\n",
            "              (conv1): BaseConv(\n",
            "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (conv2): BaseConv(\n",
            "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "            (1): Bottleneck(\n",
            "              (conv1): BaseConv(\n",
            "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (conv2): BaseConv(\n",
            "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "            (2): Bottleneck(\n",
            "              (conv1): BaseConv(\n",
            "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (conv2): BaseConv(\n",
            "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (dark4): Sequential(\n",
            "        (0): BaseConv(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): CSPLayer(\n",
            "          (conv1): BaseConv(\n",
            "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv2): BaseConv(\n",
            "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv3): BaseConv(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (m): Sequential(\n",
            "            (0): Bottleneck(\n",
            "              (conv1): BaseConv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (conv2): BaseConv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "            (1): Bottleneck(\n",
            "              (conv1): BaseConv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (conv2): BaseConv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "            (2): Bottleneck(\n",
            "              (conv1): BaseConv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (conv2): BaseConv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (dark5): Sequential(\n",
            "        (0): BaseConv(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): SPPBottleneck(\n",
            "          (conv1): BaseConv(\n",
            "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (m): ModuleList(\n",
            "            (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
            "            (1): MaxPool2d(kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False)\n",
            "            (2): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)\n",
            "          )\n",
            "          (conv2): BaseConv(\n",
            "            (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (2): CSPLayer(\n",
            "          (conv1): BaseConv(\n",
            "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv2): BaseConv(\n",
            "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv3): BaseConv(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (m): Sequential(\n",
            "            (0): Bottleneck(\n",
            "              (conv1): BaseConv(\n",
            "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (conv2): BaseConv(\n",
            "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    (lateral_conv0): BaseConv(\n",
            "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (C3_p4): CSPLayer(\n",
            "      (conv1): BaseConv(\n",
            "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (conv2): BaseConv(\n",
            "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (conv3): BaseConv(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): BaseConv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv2): BaseConv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (reduce_conv1): BaseConv(\n",
            "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (C3_p3): CSPLayer(\n",
            "      (conv1): BaseConv(\n",
            "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (conv2): BaseConv(\n",
            "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (conv3): BaseConv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): BaseConv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv2): BaseConv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (bu_conv2): BaseConv(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (C3_n3): CSPLayer(\n",
            "      (conv1): BaseConv(\n",
            "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (conv2): BaseConv(\n",
            "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (conv3): BaseConv(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): BaseConv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv2): BaseConv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (bu_conv1): BaseConv(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (C3_n4): CSPLayer(\n",
            "      (conv1): BaseConv(\n",
            "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (conv2): BaseConv(\n",
            "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (conv3): BaseConv(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): BaseConv(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv2): BaseConv(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (head): YOLOXHead(\n",
            "    (cls_convs): ModuleList(\n",
            "      (0): Sequential(\n",
            "        (0): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (reg_convs): ModuleList(\n",
            "      (0): Sequential(\n",
            "        (0): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (cls_preds): ModuleList(\n",
            "      (0): Conv2d(128, 25, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): Conv2d(128, 25, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Conv2d(128, 25, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (reg_preds): ModuleList(\n",
            "      (0): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (obj_preds): ModuleList(\n",
            "      (0): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (stems): ModuleList(\n",
            "      (0): BaseConv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (1): BaseConv(\n",
            "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (2): BaseConv(\n",
            "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (l1_loss): L1Loss()\n",
            "    (bcewithlog_loss): BCEWithLogitsLoss()\n",
            "    (iou_loss): IOUloss()\n",
            "  )\n",
            ")\u001b[0m\n",
            "\u001b[32m2021-10-22 02:25:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m193\u001b[0m - \u001b[1m---> start train epoch40\u001b[0m\n",
            "\u001b[32m2021-10-22 02:25:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 10/777, mem: 9741Mb, iter_time: 1.889s, data_time: 0.500s, total_loss: 4.4, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 0.9, lr: 1.207e-03, size: 448, ETA: 4 days, 10:24:07\u001b[0m\n",
            "\u001b[32m2021-10-22 02:25:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 20/777, mem: 9741Mb, iter_time: 0.949s, data_time: 0.007s, total_loss: 4.4, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 1.7, cls_loss: 1.2, lr: 1.207e-03, size: 704, ETA: 3 days, 7:56:10\u001b[0m\n",
            "\u001b[32m2021-10-22 02:26:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 30/777, mem: 9741Mb, iter_time: 1.443s, data_time: 0.010s, total_loss: 4.9, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.2, lr: 1.207e-03, size: 832, ETA: 3 days, 8:22:36\u001b[0m\n",
            "\u001b[32m2021-10-22 02:26:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 40/777, mem: 9741Mb, iter_time: 1.787s, data_time: 0.005s, total_loss: 5.4, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.2, lr: 1.207e-03, size: 608, ETA: 3 days, 13:26:26\u001b[0m\n",
            "\u001b[32m2021-10-22 02:26:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 50/777, mem: 9741Mb, iter_time: 1.470s, data_time: 0.004s, total_loss: 5.0, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.1, lr: 1.207e-03, size: 640, ETA: 3 days, 12:54:16\u001b[0m\n",
            "\u001b[32m2021-10-22 02:26:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 60/777, mem: 9741Mb, iter_time: 0.912s, data_time: 0.007s, total_loss: 3.9, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 1.6, cls_loss: 0.8, lr: 1.207e-03, size: 448, ETA: 3 days, 7:18:47\u001b[0m\n",
            "\u001b[32m2021-10-22 02:27:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 70/777, mem: 9741Mb, iter_time: 0.796s, data_time: 0.007s, total_loss: 4.7, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.1, lr: 1.207e-03, size: 672, ETA: 3 days, 2:23:02\u001b[0m\n",
            "\u001b[32m2021-10-22 02:27:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 80/777, mem: 9741Mb, iter_time: 1.390s, data_time: 0.007s, total_loss: 5.5, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.5, cls_loss: 1.4, lr: 1.207e-03, size: 480, ETA: 3 days, 2:51:53\u001b[0m\n",
            "\u001b[32m2021-10-22 02:27:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 90/777, mem: 9741Mb, iter_time: 0.986s, data_time: 0.007s, total_loss: 4.5, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.0, lr: 1.207e-03, size: 448, ETA: 3 days, 0:42:36\u001b[0m\n",
            "\u001b[32m2021-10-22 02:27:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 100/777, mem: 9741Mb, iter_time: 0.729s, data_time: 0.009s, total_loss: 4.7, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.1, lr: 1.207e-03, size: 640, ETA: 2 days, 21:32:23\u001b[0m\n",
            "\u001b[32m2021-10-22 02:27:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 110/777, mem: 9741Mb, iter_time: 0.898s, data_time: 0.009s, total_loss: 5.7, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.6, lr: 1.207e-03, size: 704, ETA: 2 days, 19:48:40\u001b[0m\n",
            "\u001b[32m2021-10-22 02:27:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 120/777, mem: 9741Mb, iter_time: 1.016s, data_time: 0.008s, total_loss: 4.6, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.1, lr: 1.207e-03, size: 704, ETA: 2 days, 18:55:23\u001b[0m\n",
            "\u001b[32m2021-10-22 02:28:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 130/777, mem: 9741Mb, iter_time: 1.071s, data_time: 0.006s, total_loss: 4.7, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.1, lr: 1.207e-03, size: 576, ETA: 2 days, 18:24:41\u001b[0m\n",
            "\u001b[32m2021-10-22 02:28:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 140/777, mem: 9741Mb, iter_time: 1.293s, data_time: 0.008s, total_loss: 5.0, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.4, lr: 1.207e-03, size: 576, ETA: 2 days, 18:51:54\u001b[0m\n",
            "\u001b[32m2021-10-22 02:28:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 150/777, mem: 9741Mb, iter_time: 0.866s, data_time: 0.005s, total_loss: 5.2, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.1, lr: 1.207e-03, size: 480, ETA: 2 days, 17:39:17\u001b[0m\n",
            "\u001b[32m2021-10-22 02:28:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 160/777, mem: 9741Mb, iter_time: 0.771s, data_time: 0.007s, total_loss: 4.9, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.3, lr: 1.207e-03, size: 672, ETA: 2 days, 16:15:35\u001b[0m\n",
            "\u001b[32m2021-10-22 02:28:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 170/777, mem: 9741Mb, iter_time: 0.974s, data_time: 0.010s, total_loss: 5.9, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.6, cls_loss: 1.5, lr: 1.207e-03, size: 608, ETA: 2 days, 15:42:07\u001b[0m\n",
            "\u001b[32m2021-10-22 02:28:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 180/777, mem: 9741Mb, iter_time: 0.963s, data_time: 0.007s, total_loss: 6.0, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.7, cls_loss: 1.5, lr: 1.207e-03, size: 832, ETA: 2 days, 15:10:19\u001b[0m\n",
            "\u001b[32m2021-10-22 02:29:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 190/777, mem: 9741Mb, iter_time: 1.212s, data_time: 0.007s, total_loss: 5.3, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.6, cls_loss: 1.1, lr: 1.207e-03, size: 544, ETA: 2 days, 15:26:07\u001b[0m\n",
            "\u001b[32m2021-10-22 02:29:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 200/777, mem: 9741Mb, iter_time: 1.416s, data_time: 0.004s, total_loss: 4.4, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.0, lr: 1.207e-03, size: 704, ETA: 2 days, 16:14:37\u001b[0m\n",
            "\u001b[32m2021-10-22 02:29:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 210/777, mem: 9741Mb, iter_time: 0.993s, data_time: 0.008s, total_loss: 5.7, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.7, cls_loss: 1.4, lr: 1.207e-03, size: 480, ETA: 2 days, 15:50:30\u001b[0m\n",
            "\u001b[32m2021-10-22 02:29:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 220/777, mem: 9741Mb, iter_time: 0.861s, data_time: 0.007s, total_loss: 5.0, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.3, lr: 1.207e-03, size: 672, ETA: 2 days, 15:08:16\u001b[0m\n",
            "\u001b[32m2021-10-22 02:29:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 230/777, mem: 9741Mb, iter_time: 0.976s, data_time: 0.009s, total_loss: 6.0, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.6, cls_loss: 1.6, lr: 1.207e-03, size: 480, ETA: 2 days, 14:46:40\u001b[0m\n",
            "\u001b[32m2021-10-22 02:29:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 240/777, mem: 9741Mb, iter_time: 0.858s, data_time: 0.005s, total_loss: 4.7, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.1, lr: 1.207e-03, size: 672, ETA: 2 days, 14:10:15\u001b[0m\n",
            "\u001b[32m2021-10-22 02:30:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 250/777, mem: 9741Mb, iter_time: 0.934s, data_time: 0.009s, total_loss: 5.4, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.4, lr: 1.207e-03, size: 480, ETA: 2 days, 13:47:03\u001b[0m\n",
            "\u001b[32m2021-10-22 02:30:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 260/777, mem: 9741Mb, iter_time: 0.837s, data_time: 0.009s, total_loss: 5.1, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.2, lr: 1.206e-03, size: 512, ETA: 2 days, 13:12:54\u001b[0m\n",
            "\u001b[32m2021-10-22 02:30:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 270/777, mem: 9741Mb, iter_time: 0.965s, data_time: 0.005s, total_loss: 5.3, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.2, lr: 1.206e-03, size: 512, ETA: 2 days, 12:57:16\u001b[0m\n",
            "\u001b[32m2021-10-22 02:30:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.handle\u001b[0m:\u001b[36m140\u001b[0m - \u001b[1mGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\u001b[0m\n",
            "\u001b[32m2021-10-22 02:30:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 280/777, mem: 9741Mb, iter_time: 0.750s, data_time: 0.009s, total_loss: 5.1, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.2, lr: 1.206e-03, size: 576, ETA: 2 days, 12:16:56\u001b[0m\n",
            "\u001b[32m2021-10-22 02:30:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 290/777, mem: 9741Mb, iter_time: 0.859s, data_time: 0.009s, total_loss: 5.0, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.2, lr: 1.206e-03, size: 704, ETA: 2 days, 11:52:01\u001b[0m\n",
            "\u001b[32m2021-10-22 02:30:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 300/777, mem: 9741Mb, iter_time: 1.039s, data_time: 0.007s, total_loss: 5.3, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.2, lr: 1.206e-03, size: 832, ETA: 2 days, 11:48:58\u001b[0m\n",
            "\u001b[32m2021-10-22 02:31:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 310/777, mem: 9741Mb, iter_time: 1.240s, data_time: 0.009s, total_loss: 5.4, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.4, lr: 1.206e-03, size: 672, ETA: 2 days, 12:07:59\u001b[0m\n",
            "\u001b[32m2021-10-22 02:31:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 320/777, mem: 9741Mb, iter_time: 1.128s, data_time: 0.003s, total_loss: 4.6, iou_loss: 1.3, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.0, lr: 1.206e-03, size: 544, ETA: 2 days, 12:13:58\u001b[0m\n",
            "\u001b[32m2021-10-22 02:31:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 330/777, mem: 9741Mb, iter_time: 0.852s, data_time: 0.007s, total_loss: 5.0, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.1, lr: 1.206e-03, size: 448, ETA: 2 days, 11:51:22\u001b[0m\n",
            "\u001b[32m2021-10-22 02:31:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 340/777, mem: 9741Mb, iter_time: 0.751s, data_time: 0.008s, total_loss: 5.0, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.2, lr: 1.206e-03, size: 608, ETA: 2 days, 11:20:04\u001b[0m\n",
            "\u001b[32m2021-10-22 02:31:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 350/777, mem: 9741Mb, iter_time: 0.884s, data_time: 0.012s, total_loss: 5.9, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.6, lr: 1.206e-03, size: 672, ETA: 2 days, 11:03:26\u001b[0m\n",
            "\u001b[32m2021-10-22 02:31:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 360/777, mem: 9741Mb, iter_time: 0.979s, data_time: 0.010s, total_loss: 5.7, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.6, lr: 1.206e-03, size: 832, ETA: 2 days, 10:56:37\u001b[0m\n",
            "\u001b[32m2021-10-22 02:31:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 370/777, mem: 9741Mb, iter_time: 1.214s, data_time: 0.008s, total_loss: 5.5, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.5, cls_loss: 1.4, lr: 1.206e-03, size: 704, ETA: 2 days, 11:11:34\u001b[0m\n",
            "\u001b[32m2021-10-22 02:32:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 380/777, mem: 9741Mb, iter_time: 1.132s, data_time: 0.008s, total_loss: 6.0, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.7, cls_loss: 1.4, lr: 1.206e-03, size: 480, ETA: 2 days, 11:18:28\u001b[0m\n",
            "\u001b[32m2021-10-22 02:32:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 390/777, mem: 9741Mb, iter_time: 0.882s, data_time: 0.005s, total_loss: 4.8, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.1, lr: 1.206e-03, size: 736, ETA: 2 days, 11:03:22\u001b[0m\n",
            "\u001b[32m2021-10-22 02:32:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 400/777, mem: 9741Mb, iter_time: 1.501s, data_time: 0.009s, total_loss: 5.0, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.3, lr: 1.206e-03, size: 704, ETA: 2 days, 11:41:12\u001b[0m\n",
            "\u001b[32m2021-10-22 02:32:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 410/777, mem: 9741Mb, iter_time: 1.085s, data_time: 0.009s, total_loss: 5.4, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.5, cls_loss: 1.3, lr: 1.206e-03, size: 480, ETA: 2 days, 11:42:55\u001b[0m\n",
            "\u001b[32m2021-10-22 02:32:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 420/777, mem: 9741Mb, iter_time: 0.879s, data_time: 0.006s, total_loss: 4.8, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.7, cls_loss: 1.5, lr: 1.206e-03, size: 768, ETA: 2 days, 11:28:01\u001b[0m\n",
            "\u001b[32m2021-10-22 02:33:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 430/777, mem: 9741Mb, iter_time: 1.529s, data_time: 0.010s, total_loss: 5.3, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.2, lr: 1.206e-03, size: 800, ETA: 2 days, 12:04:47\u001b[0m\n",
            "\u001b[32m2021-10-22 02:33:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 440/777, mem: 9741Mb, iter_time: 1.693s, data_time: 0.011s, total_loss: 6.3, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.8, cls_loss: 1.7, lr: 1.206e-03, size: 608, ETA: 2 days, 12:52:27\u001b[0m\n",
            "\u001b[32m2021-10-22 02:33:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 450/777, mem: 9741Mb, iter_time: 1.035s, data_time: 0.005s, total_loss: 5.7, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.5, cls_loss: 1.4, lr: 1.206e-03, size: 576, ETA: 2 days, 12:48:43\u001b[0m\n",
            "\u001b[32m2021-10-22 02:33:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 460/777, mem: 9741Mb, iter_time: 0.879s, data_time: 0.007s, total_loss: 6.1, iou_loss: 2.0, l1_loss: 0.0, conf_loss: 2.9, cls_loss: 1.3, lr: 1.206e-03, size: 768, ETA: 2 days, 12:33:39\u001b[0m\n",
            "\u001b[32m2021-10-22 02:33:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 470/777, mem: 9741Mb, iter_time: 1.125s, data_time: 0.009s, total_loss: 6.0, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.8, lr: 1.206e-03, size: 544, ETA: 2 days, 12:36:52\u001b[0m\n",
            "\u001b[32m2021-10-22 02:34:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 480/777, mem: 9741Mb, iter_time: 0.950s, data_time: 0.005s, total_loss: 4.1, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.5, cls_loss: 1.0, lr: 1.206e-03, size: 832, ETA: 2 days, 12:27:38\u001b[0m\n",
            "\u001b[32m2021-10-22 02:34:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 490/777, mem: 9741Mb, iter_time: 1.234s, data_time: 0.012s, total_loss: 5.7, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.7, cls_loss: 1.3, lr: 1.206e-03, size: 704, ETA: 2 days, 12:38:19\u001b[0m\n",
            "\u001b[32m2021-10-22 02:34:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 500/777, mem: 9741Mb, iter_time: 1.144s, data_time: 0.008s, total_loss: 5.3, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.2, lr: 1.206e-03, size: 512, ETA: 2 days, 12:42:33\u001b[0m\n",
            "\u001b[32m2021-10-22 02:34:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 510/777, mem: 9741Mb, iter_time: 0.877s, data_time: 0.009s, total_loss: 5.7, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.6, lr: 1.206e-03, size: 512, ETA: 2 days, 12:28:55\u001b[0m\n",
            "\u001b[32m2021-10-22 02:34:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 520/777, mem: 9741Mb, iter_time: 0.776s, data_time: 0.007s, total_loss: 4.3, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 1.7, cls_loss: 0.9, lr: 1.206e-03, size: 672, ETA: 2 days, 12:09:17\u001b[0m\n",
            "\u001b[32m2021-10-22 02:34:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 530/777, mem: 9741Mb, iter_time: 0.959s, data_time: 0.009s, total_loss: 5.5, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.2, lr: 1.206e-03, size: 480, ETA: 2 days, 12:02:02\u001b[0m\n",
            "\u001b[32m2021-10-22 02:35:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 540/777, mem: 9741Mb, iter_time: 0.857s, data_time: 0.006s, total_loss: 4.1, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.6, cls_loss: 0.9, lr: 1.206e-03, size: 800, ETA: 2 days, 11:48:39\u001b[0m\n",
            "\u001b[32m2021-10-22 02:35:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 550/777, mem: 9741Mb, iter_time: 1.203s, data_time: 0.007s, total_loss: 6.7, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.9, cls_loss: 2.0, lr: 1.206e-03, size: 448, ETA: 2 days, 11:56:56\u001b[0m\n",
            "\u001b[32m2021-10-22 02:35:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 560/777, mem: 9741Mb, iter_time: 0.947s, data_time: 0.004s, total_loss: 4.7, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.4, lr: 1.206e-03, size: 576, ETA: 2 days, 11:49:30\u001b[0m\n",
            "\u001b[32m2021-10-22 02:35:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 570/777, mem: 9741Mb, iter_time: 0.831s, data_time: 0.008s, total_loss: 4.9, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.0, lr: 1.205e-03, size: 704, ETA: 2 days, 11:35:28\u001b[0m\n",
            "\u001b[32m2021-10-22 02:35:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 580/777, mem: 9741Mb, iter_time: 1.035s, data_time: 0.009s, total_loss: 4.4, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 1.7, cls_loss: 1.0, lr: 1.205e-03, size: 832, ETA: 2 days, 11:33:47\u001b[0m\n",
            "\u001b[32m2021-10-22 02:35:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 590/777, mem: 9741Mb, iter_time: 1.229s, data_time: 0.010s, total_loss: 4.8, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.0, lr: 1.205e-03, size: 608, ETA: 2 days, 11:43:14\u001b[0m\n",
            "\u001b[32m2021-10-22 02:36:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 600/777, mem: 9741Mb, iter_time: 1.061s, data_time: 0.004s, total_loss: 3.9, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.5, cls_loss: 0.8, lr: 1.205e-03, size: 448, ETA: 2 days, 11:42:56\u001b[0m\n",
            "\u001b[32m2021-10-22 02:36:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 610/777, mem: 9741Mb, iter_time: 0.812s, data_time: 0.005s, total_loss: 4.6, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.3, lr: 1.205e-03, size: 832, ETA: 2 days, 11:28:52\u001b[0m\n",
            "\u001b[32m2021-10-22 02:36:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 620/777, mem: 9741Mb, iter_time: 1.221s, data_time: 0.009s, total_loss: 5.8, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.5, cls_loss: 1.6, lr: 1.205e-03, size: 736, ETA: 2 days, 11:37:28\u001b[0m\n",
            "\u001b[32m2021-10-22 02:36:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 630/777, mem: 9741Mb, iter_time: 1.182s, data_time: 0.005s, total_loss: 4.5, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.1, lr: 1.205e-03, size: 544, ETA: 2 days, 11:43:43\u001b[0m\n",
            "\u001b[32m2021-10-22 02:36:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 640/777, mem: 9741Mb, iter_time: 0.918s, data_time: 0.008s, total_loss: 4.4, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 1.7, cls_loss: 1.0, lr: 1.205e-03, size: 608, ETA: 2 days, 11:35:53\u001b[0m\n",
            "\u001b[32m2021-10-22 02:36:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 650/777, mem: 9741Mb, iter_time: 0.881s, data_time: 0.009s, total_loss: 5.2, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.2, lr: 1.205e-03, size: 608, ETA: 2 days, 11:26:23\u001b[0m\n",
            "\u001b[32m2021-10-22 02:37:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 660/777, mem: 9741Mb, iter_time: 0.924s, data_time: 0.006s, total_loss: 5.5, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.5, lr: 1.205e-03, size: 704, ETA: 2 days, 11:19:19\u001b[0m\n",
            "\u001b[32m2021-10-22 02:37:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 670/777, mem: 9741Mb, iter_time: 1.030s, data_time: 0.011s, total_loss: 3.9, iou_loss: 1.4, l1_loss: 0.0, conf_loss: 1.7, cls_loss: 0.8, lr: 1.205e-03, size: 672, ETA: 2 days, 11:17:47\u001b[0m\n",
            "\u001b[32m2021-10-22 02:37:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 680/777, mem: 9741Mb, iter_time: 1.025s, data_time: 0.005s, total_loss: 5.0, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.3, lr: 1.205e-03, size: 640, ETA: 2 days, 11:16:04\u001b[0m\n",
            "\u001b[32m2021-10-22 02:37:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 690/777, mem: 9741Mb, iter_time: 0.967s, data_time: 0.006s, total_loss: 4.5, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.2, lr: 1.205e-03, size: 640, ETA: 2 days, 11:11:34\u001b[0m\n",
            "\u001b[32m2021-10-22 02:37:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 700/777, mem: 9741Mb, iter_time: 0.945s, data_time: 0.010s, total_loss: 4.4, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 1.6, cls_loss: 1.1, lr: 1.205e-03, size: 672, ETA: 2 days, 11:06:09\u001b[0m\n",
            "\u001b[32m2021-10-22 02:37:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 710/777, mem: 9741Mb, iter_time: 0.979s, data_time: 0.005s, total_loss: 5.1, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.1, lr: 1.205e-03, size: 608, ETA: 2 days, 11:02:27\u001b[0m\n",
            "\u001b[32m2021-10-22 02:38:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 720/777, mem: 9741Mb, iter_time: 0.984s, data_time: 0.007s, total_loss: 5.7, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.5, lr: 1.205e-03, size: 736, ETA: 2 days, 10:59:05\u001b[0m\n",
            "\u001b[32m2021-10-22 02:38:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 730/777, mem: 9741Mb, iter_time: 1.065s, data_time: 0.007s, total_loss: 5.4, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.4, lr: 1.205e-03, size: 512, ETA: 2 days, 10:59:35\u001b[0m\n",
            "\u001b[32m2021-10-22 02:38:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 740/777, mem: 9741Mb, iter_time: 0.885s, data_time: 0.004s, total_loss: 5.0, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.2, lr: 1.205e-03, size: 736, ETA: 2 days, 10:51:51\u001b[0m\n",
            "\u001b[32m2021-10-22 02:38:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 750/777, mem: 9741Mb, iter_time: 1.079s, data_time: 0.011s, total_loss: 5.1, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.3, lr: 1.205e-03, size: 640, ETA: 2 days, 10:53:02\u001b[0m\n",
            "\u001b[32m2021-10-22 02:38:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 760/777, mem: 9741Mb, iter_time: 1.009s, data_time: 0.006s, total_loss: 4.3, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 0.8, lr: 1.205e-03, size: 800, ETA: 2 days, 10:51:05\u001b[0m\n",
            "\u001b[32m2021-10-22 02:38:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 40/300, iter: 770/777, mem: 9741Mb, iter_time: 1.151s, data_time: 0.009s, total_loss: 5.3, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.4, lr: 1.205e-03, size: 512, ETA: 2 days, 10:55:24\u001b[0m\n",
            "\u001b[32m2021-10-22 02:39:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mSave weights to /content/gdrive/MyDrive/Sprints/yolox_voc_s/yolox_voc_s/yolox_voc_s\u001b[0m\n",
            "  0%|          | 0/44 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|##########| 44/44 [00:15<00:00,  2.87it/s]\n",
            "\u001b[32m2021-10-22 02:39:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.evaluators.voc_evaluator\u001b[0m:\u001b[36m161\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
            "Writing beans VOC results file\n",
            "Writing cake VOC results file\n",
            "Writing candy VOC results file\n",
            "Writing cereal VOC results file\n",
            "Writing chips VOC results file\n",
            "Writing chocolate VOC results file\n",
            "Writing coffee VOC results file\n",
            "Writing corn VOC results file\n",
            "Writing fish VOC results file\n",
            "Writing flour VOC results file\n",
            "Writing honey VOC results file\n",
            "Writing jam VOC results file\n",
            "Writing juice VOC results file\n",
            "Writing milk VOC results file\n",
            "Writing nuts VOC results file\n",
            "Writing oil VOC results file\n",
            "Writing pasta VOC results file\n",
            "Writing rice VOC results file\n",
            "Writing soda VOC results file\n",
            "Writing spices VOC results file\n",
            "Writing sugar VOC results file\n",
            "Writing tea VOC results file\n",
            "Writing tomato_sauce VOC results file\n",
            "Writing vinegar VOC results file\n",
            "Writing water VOC results file\n",
            "Eval IoU : 0.50\n",
            "Reading annotation for 1/346\n",
            "Reading annotation for 101/346\n",
            "Reading annotation for 201/346\n",
            "Reading annotation for 301/346\n",
            "Saving cached annotations to /content/YOLOX/datasets/VOCdevkit/annotations_cache/VOC2007/test/annots.pkl\n",
            "AP for beans = 0.9346\n",
            "AP for cake = 0.9335\n",
            "AP for candy = 0.7929\n",
            "AP for cereal = 0.9497\n",
            "AP for chips = 0.9278\n",
            "AP for chocolate = 0.9071\n",
            "AP for coffee = 0.9344\n",
            "AP for corn = 0.9394\n",
            "AP for fish = 0.8896\n",
            "AP for flour = 0.9040\n",
            "AP for honey = 0.9563\n",
            "AP for jam = 0.8976\n",
            "AP for juice = 0.8981\n",
            "AP for milk = 0.7227\n",
            "AP for nuts = 0.8852\n",
            "AP for oil = 0.8166\n",
            "AP for pasta = 0.8479\n",
            "AP for rice = 0.9084\n",
            "AP for soda = 0.8862\n",
            "AP for spices = 0.9063\n",
            "AP for sugar = 0.9147\n",
            "AP for tea = 0.8094\n",
            "AP for tomato_sauce = 0.8853\n",
            "AP for vinegar = 0.9656\n",
            "AP for water = 0.9350\n",
            "Mean AP = 0.8939\n",
            "~~~~~~~~\n",
            "Results:\n",
            "0.935\n",
            "0.934\n",
            "0.793\n",
            "0.950\n",
            "0.928\n",
            "0.907\n",
            "0.934\n",
            "0.939\n",
            "0.890\n",
            "0.904\n",
            "0.956\n",
            "0.898\n",
            "0.898\n",
            "0.723\n",
            "0.885\n",
            "0.817\n",
            "0.848\n",
            "0.908\n",
            "0.886\n",
            "0.906\n",
            "0.915\n",
            "0.809\n",
            "0.885\n",
            "0.966\n",
            "0.935\n",
            "0.894\n",
            "~~~~~~~~\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Results computed with the **unofficial** Python eval code.\n",
            "Results should be very close to the official MATLAB eval code.\n",
            "Recompute with `./tools/reval.py --matlab ...` for your paper.\n",
            "-- Thanks, The Management\n",
            "--------------------------------------------------------------\n",
            "Eval IoU : 0.55\n",
            "Eval IoU : 0.60\n",
            "Eval IoU : 0.65\n",
            "Eval IoU : 0.70\n",
            "Eval IoU : 0.75\n",
            "Eval IoU : 0.80\n",
            "Eval IoU : 0.85\n",
            "Eval IoU : 0.90\n",
            "Eval IoU : 0.95\n",
            "--------------------------------------------------------------\n",
            "map_5095: 0.6958235022238853\n",
            "map_50: 0.8939254029849042\n",
            "--------------------------------------------------------------\n",
            "\u001b[32m2021-10-22 02:39:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m314\u001b[0m - \u001b[1m\n",
            "Average forward time: 22.14 ms, Average NMS time: 5.11 ms, Average inference time: 27.25 ms\n",
            "\u001b[0m\n",
            "\u001b[32m2021-10-22 02:39:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mSave weights to /content/gdrive/MyDrive/Sprints/yolox_voc_s/yolox_voc_s/yolox_voc_s\u001b[0m\n",
            "\u001b[32m2021-10-22 02:39:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m193\u001b[0m - \u001b[1m---> start train epoch41\u001b[0m\n",
            "\u001b[32m2021-10-22 02:39:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 10/777, mem: 9741Mb, iter_time: 1.021s, data_time: 0.007s, total_loss: 7.4, iou_loss: 2.0, l1_loss: 0.0, conf_loss: 3.4, cls_loss: 2.0, lr: 1.205e-03, size: 768, ETA: 2 days, 10:54:09\u001b[0m\n",
            "\u001b[32m2021-10-22 02:39:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 20/777, mem: 9741Mb, iter_time: 1.153s, data_time: 0.006s, total_loss: 5.1, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.5, lr: 1.205e-03, size: 704, ETA: 2 days, 10:58:21\u001b[0m\n",
            "\u001b[32m2021-10-22 02:40:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 30/777, mem: 9741Mb, iter_time: 1.166s, data_time: 0.009s, total_loss: 5.5, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.6, cls_loss: 1.3, lr: 1.205e-03, size: 832, ETA: 2 days, 11:02:57\u001b[0m\n",
            "\u001b[32m2021-10-22 02:40:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 40/777, mem: 9741Mb, iter_time: 1.337s, data_time: 0.008s, total_loss: 4.7, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.1, lr: 1.205e-03, size: 832, ETA: 2 days, 11:14:31\u001b[0m\n",
            "\u001b[32m2021-10-22 02:40:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 50/777, mem: 9741Mb, iter_time: 1.153s, data_time: 0.002s, total_loss: 5.3, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.3, lr: 1.205e-03, size: 576, ETA: 2 days, 11:18:17\u001b[0m\n",
            "\u001b[32m2021-10-22 02:40:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 60/777, mem: 9741Mb, iter_time: 0.817s, data_time: 0.009s, total_loss: 5.0, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.2, lr: 1.205e-03, size: 544, ETA: 2 days, 11:08:26\u001b[0m\n",
            "\u001b[32m2021-10-22 02:40:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 70/777, mem: 9741Mb, iter_time: 0.942s, data_time: 0.006s, total_loss: 4.7, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.0, lr: 1.205e-03, size: 704, ETA: 2 days, 11:03:49\u001b[0m\n",
            "\u001b[32m2021-10-22 02:40:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 80/777, mem: 9741Mb, iter_time: 1.194s, data_time: 0.009s, total_loss: 5.1, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.3, lr: 1.205e-03, size: 832, ETA: 2 days, 11:09:12\u001b[0m\n",
            "\u001b[32m2021-10-22 02:41:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 90/777, mem: 9741Mb, iter_time: 1.269s, data_time: 0.005s, total_loss: 5.8, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.6, cls_loss: 1.5, lr: 1.205e-03, size: 736, ETA: 2 days, 11:17:20\u001b[0m\n",
            "\u001b[32m2021-10-22 02:41:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 100/777, mem: 9741Mb, iter_time: 1.215s, data_time: 0.006s, total_loss: 5.0, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.3, lr: 1.204e-03, size: 832, ETA: 2 days, 11:23:14\u001b[0m\n",
            "\u001b[32m2021-10-22 02:41:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 110/777, mem: 9741Mb, iter_time: 1.141s, data_time: 0.003s, total_loss: 4.8, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.3, lr: 1.204e-03, size: 512, ETA: 2 days, 11:26:11\u001b[0m\n",
            "\u001b[32m2021-10-22 02:41:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 120/777, mem: 9741Mb, iter_time: 0.732s, data_time: 0.008s, total_loss: 5.6, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.7, lr: 1.204e-03, size: 448, ETA: 2 days, 11:13:42\u001b[0m\n",
            "\u001b[32m2021-10-22 02:41:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 130/777, mem: 9741Mb, iter_time: 0.719s, data_time: 0.004s, total_loss: 5.4, iou_loss: 2.1, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.4, lr: 1.204e-03, size: 448, ETA: 2 days, 11:01:01\u001b[0m\n",
            "\u001b[32m2021-10-22 02:41:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 140/777, mem: 9741Mb, iter_time: 0.782s, data_time: 0.009s, total_loss: 4.8, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.2, lr: 1.204e-03, size: 544, ETA: 2 days, 10:50:56\u001b[0m\n",
            "\u001b[32m2021-10-22 02:42:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 150/777, mem: 9741Mb, iter_time: 1.013s, data_time: 0.008s, total_loss: 4.8, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.2, lr: 1.204e-03, size: 768, ETA: 2 days, 10:49:26\u001b[0m\n",
            "\u001b[32m2021-10-22 02:42:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 160/777, mem: 9741Mb, iter_time: 1.161s, data_time: 0.008s, total_loss: 5.2, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.2, lr: 1.204e-03, size: 736, ETA: 2 days, 10:53:17\u001b[0m\n",
            "\u001b[32m2021-10-22 02:42:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 170/777, mem: 9741Mb, iter_time: 1.046s, data_time: 0.007s, total_loss: 6.0, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.6, cls_loss: 1.5, lr: 1.204e-03, size: 640, ETA: 2 days, 10:52:56\u001b[0m\n",
            "\u001b[32m2021-10-22 02:42:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 180/777, mem: 9741Mb, iter_time: 0.848s, data_time: 0.009s, total_loss: 5.2, iou_loss: 2.1, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.0, lr: 1.204e-03, size: 480, ETA: 2 days, 10:45:40\u001b[0m\n",
            "\u001b[32m2021-10-22 02:42:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 190/777, mem: 9741Mb, iter_time: 0.769s, data_time: 0.006s, total_loss: 4.9, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.2, lr: 1.204e-03, size: 512, ETA: 2 days, 10:35:47\u001b[0m\n",
            "\u001b[32m2021-10-22 02:42:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 200/777, mem: 9741Mb, iter_time: 0.821s, data_time: 0.010s, total_loss: 5.4, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.5, cls_loss: 1.2, lr: 1.204e-03, size: 640, ETA: 2 days, 10:27:52\u001b[0m\n",
            "\u001b[32m2021-10-22 02:43:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 210/777, mem: 9741Mb, iter_time: 1.081s, data_time: 0.007s, total_loss: 6.4, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 3.1, cls_loss: 1.5, lr: 1.204e-03, size: 736, ETA: 2 days, 10:28:59\u001b[0m\n",
            "\u001b[32m2021-10-22 02:43:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 220/777, mem: 9741Mb, iter_time: 1.202s, data_time: 0.006s, total_loss: 4.8, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.2, lr: 1.204e-03, size: 800, ETA: 2 days, 10:34:10\u001b[0m\n",
            "\u001b[32m2021-10-22 02:43:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 230/777, mem: 9741Mb, iter_time: 1.133s, data_time: 0.003s, total_loss: 5.5, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.3, lr: 1.204e-03, size: 576, ETA: 2 days, 10:36:58\u001b[0m\n",
            "\u001b[32m2021-10-22 02:43:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 240/777, mem: 9741Mb, iter_time: 0.980s, data_time: 0.007s, total_loss: 5.2, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.2, lr: 1.204e-03, size: 736, ETA: 2 days, 10:34:37\u001b[0m\n",
            "\u001b[32m2021-10-22 02:43:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 250/777, mem: 9741Mb, iter_time: 1.059s, data_time: 0.008s, total_loss: 4.8, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 0.9, lr: 1.204e-03, size: 640, ETA: 2 days, 10:34:53\u001b[0m\n",
            "\u001b[32m2021-10-22 02:43:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 260/777, mem: 9741Mb, iter_time: 1.107s, data_time: 0.009s, total_loss: 6.1, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.8, cls_loss: 1.4, lr: 1.204e-03, size: 832, ETA: 2 days, 10:36:42\u001b[0m\n",
            "\u001b[32m2021-10-22 02:44:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 270/777, mem: 9741Mb, iter_time: 1.235s, data_time: 0.007s, total_loss: 5.0, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.2, lr: 1.204e-03, size: 704, ETA: 2 days, 10:42:37\u001b[0m\n",
            "\u001b[32m2021-10-22 02:44:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 280/777, mem: 9741Mb, iter_time: 1.130s, data_time: 0.009s, total_loss: 6.3, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.9, cls_loss: 1.4, lr: 1.204e-03, size: 768, ETA: 2 days, 10:45:04\u001b[0m\n",
            "\u001b[32m2021-10-22 02:44:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 290/777, mem: 9741Mb, iter_time: 1.014s, data_time: 0.006s, total_loss: 5.8, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.5, cls_loss: 1.4, lr: 1.204e-03, size: 544, ETA: 2 days, 10:43:48\u001b[0m\n",
            "\u001b[32m2021-10-22 02:44:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 300/777, mem: 9741Mb, iter_time: 0.861s, data_time: 0.009s, total_loss: 5.1, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.3, lr: 1.204e-03, size: 608, ETA: 2 days, 10:37:48\u001b[0m\n",
            "\u001b[32m2021-10-22 02:44:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 310/777, mem: 9741Mb, iter_time: 1.009s, data_time: 0.009s, total_loss: 4.8, iou_loss: 1.3, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.3, lr: 1.204e-03, size: 736, ETA: 2 days, 10:36:28\u001b[0m\n",
            "\u001b[32m2021-10-22 02:44:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 320/777, mem: 9741Mb, iter_time: 0.974s, data_time: 0.002s, total_loss: 5.8, iou_loss: 2.0, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.5, lr: 1.204e-03, size: 448, ETA: 2 days, 10:34:06\u001b[0m\n",
            "\u001b[32m2021-10-22 02:45:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 330/777, mem: 9741Mb, iter_time: 0.816s, data_time: 0.008s, total_loss: 5.2, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.2, lr: 1.204e-03, size: 608, ETA: 2 days, 10:26:57\u001b[0m\n",
            "\u001b[32m2021-10-22 02:45:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 340/777, mem: 9741Mb, iter_time: 0.858s, data_time: 0.011s, total_loss: 5.5, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.6, lr: 1.204e-03, size: 448, ETA: 2 days, 10:21:13\u001b[0m\n",
            "\u001b[32m2021-10-22 02:45:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 350/777, mem: 9741Mb, iter_time: 1.018s, data_time: 0.009s, total_loss: 5.2, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.2, lr: 1.204e-03, size: 800, ETA: 2 days, 10:20:20\u001b[0m\n",
            "\u001b[32m2021-10-22 02:45:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 360/777, mem: 9741Mb, iter_time: 1.112s, data_time: 0.004s, total_loss: 5.0, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.2, lr: 1.204e-03, size: 512, ETA: 2 days, 10:22:14\u001b[0m\n",
            "\u001b[32m2021-10-22 02:45:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 370/777, mem: 9741Mb, iter_time: 0.739s, data_time: 0.008s, total_loss: 5.2, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.5, lr: 1.204e-03, size: 480, ETA: 2 days, 10:13:11\u001b[0m\n",
            "\u001b[32m2021-10-22 02:45:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 380/777, mem: 9741Mb, iter_time: 0.734s, data_time: 0.008s, total_loss: 5.5, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.6, lr: 1.204e-03, size: 448, ETA: 2 days, 10:04:08\u001b[0m\n",
            "\u001b[32m2021-10-22 02:45:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 390/777, mem: 9741Mb, iter_time: 0.726s, data_time: 0.008s, total_loss: 5.4, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.3, lr: 1.204e-03, size: 480, ETA: 2 days, 9:55:01\u001b[0m\n",
            "\u001b[32m2021-10-22 02:46:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 400/777, mem: 9741Mb, iter_time: 0.783s, data_time: 0.007s, total_loss: 5.2, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.3, lr: 1.203e-03, size: 544, ETA: 2 days, 9:47:40\u001b[0m\n",
            "\u001b[32m2021-10-22 02:46:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 410/777, mem: 9741Mb, iter_time: 0.813s, data_time: 0.009s, total_loss: 4.4, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 0.9, lr: 1.203e-03, size: 512, ETA: 2 days, 9:41:18\u001b[0m\n",
            "\u001b[32m2021-10-22 02:46:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 420/777, mem: 9741Mb, iter_time: 0.816s, data_time: 0.009s, total_loss: 4.6, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.0, lr: 1.203e-03, size: 576, ETA: 2 days, 9:35:08\u001b[0m\n",
            "\u001b[32m2021-10-22 02:46:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 430/777, mem: 9741Mb, iter_time: 1.002s, data_time: 0.010s, total_loss: 4.9, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.0, lr: 1.203e-03, size: 768, ETA: 2 days, 9:34:14\u001b[0m\n",
            "\u001b[32m2021-10-22 02:46:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 440/777, mem: 9741Mb, iter_time: 1.229s, data_time: 0.009s, total_loss: 6.1, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.8, cls_loss: 1.6, lr: 1.203e-03, size: 800, ETA: 2 days, 9:39:36\u001b[0m\n",
            "\u001b[32m2021-10-22 02:46:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 450/777, mem: 9741Mb, iter_time: 1.152s, data_time: 0.005s, total_loss: 4.5, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.0, lr: 1.203e-03, size: 640, ETA: 2 days, 9:42:47\u001b[0m\n",
            "\u001b[32m2021-10-22 02:47:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 460/777, mem: 9741Mb, iter_time: 0.922s, data_time: 0.007s, total_loss: 5.1, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.3, lr: 1.203e-03, size: 640, ETA: 2 days, 9:39:39\u001b[0m\n",
            "\u001b[32m2021-10-22 02:47:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 470/777, mem: 9741Mb, iter_time: 0.878s, data_time: 0.008s, total_loss: 4.9, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.2, lr: 1.203e-03, size: 512, ETA: 2 days, 9:35:23\u001b[0m\n",
            "\u001b[32m2021-10-22 02:47:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 480/777, mem: 9741Mb, iter_time: 0.859s, data_time: 0.010s, total_loss: 5.5, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.3, lr: 1.203e-03, size: 640, ETA: 2 days, 9:30:41\u001b[0m\n",
            "\u001b[32m2021-10-22 02:47:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 490/777, mem: 9741Mb, iter_time: 0.896s, data_time: 0.007s, total_loss: 5.2, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.2, lr: 1.203e-03, size: 512, ETA: 2 days, 9:27:02\u001b[0m\n",
            "\u001b[32m2021-10-22 02:47:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 500/777, mem: 9741Mb, iter_time: 0.847s, data_time: 0.008s, total_loss: 6.2, iou_loss: 2.0, l1_loss: 0.0, conf_loss: 2.8, cls_loss: 1.4, lr: 1.203e-03, size: 640, ETA: 2 days, 9:22:09\u001b[0m\n",
            "\u001b[32m2021-10-22 02:47:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 510/777, mem: 9741Mb, iter_time: 0.938s, data_time: 0.009s, total_loss: 5.2, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.2, lr: 1.203e-03, size: 608, ETA: 2 days, 9:19:43\u001b[0m\n",
            "\u001b[32m2021-10-22 02:47:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 520/777, mem: 9741Mb, iter_time: 0.906s, data_time: 0.007s, total_loss: 5.3, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.4, lr: 1.203e-03, size: 512, ETA: 2 days, 9:16:30\u001b[0m\n",
            "\u001b[32m2021-10-22 02:48:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 530/777, mem: 9741Mb, iter_time: 0.873s, data_time: 0.007s, total_loss: 5.6, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.5, cls_loss: 1.5, lr: 1.203e-03, size: 608, ETA: 2 days, 9:12:27\u001b[0m\n",
            "\u001b[32m2021-10-22 02:48:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 540/777, mem: 9741Mb, iter_time: 0.895s, data_time: 0.007s, total_loss: 5.2, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.2, lr: 1.203e-03, size: 512, ETA: 2 days, 9:09:03\u001b[0m\n",
            "\u001b[32m2021-10-22 02:48:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 550/777, mem: 9741Mb, iter_time: 0.796s, data_time: 0.006s, total_loss: 4.3, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 1.7, cls_loss: 1.1, lr: 1.203e-03, size: 544, ETA: 2 days, 9:03:11\u001b[0m\n",
            "\u001b[32m2021-10-22 02:48:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 560/777, mem: 9741Mb, iter_time: 1.044s, data_time: 0.010s, total_loss: 7.0, iou_loss: 2.0, l1_loss: 0.0, conf_loss: 3.4, cls_loss: 1.6, lr: 1.203e-03, size: 800, ETA: 2 days, 9:03:38\u001b[0m\n",
            "\u001b[32m2021-10-22 02:48:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 570/777, mem: 9741Mb, iter_time: 1.144s, data_time: 0.002s, total_loss: 4.6, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.1, lr: 1.203e-03, size: 480, ETA: 2 days, 9:06:33\u001b[0m\n",
            "\u001b[32m2021-10-22 02:48:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 580/777, mem: 9741Mb, iter_time: 0.965s, data_time: 0.013s, total_loss: 5.7, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.5, lr: 1.203e-03, size: 736, ETA: 2 days, 9:05:01\u001b[0m\n",
            "\u001b[32m2021-10-22 02:49:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 590/777, mem: 9741Mb, iter_time: 1.047s, data_time: 0.005s, total_loss: 5.1, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.1, lr: 1.203e-03, size: 608, ETA: 2 days, 9:05:30\u001b[0m\n",
            "\u001b[32m2021-10-22 02:49:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 600/777, mem: 9741Mb, iter_time: 0.862s, data_time: 0.006s, total_loss: 4.5, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.0, lr: 1.203e-03, size: 512, ETA: 2 days, 9:01:28\u001b[0m\n",
            "\u001b[32m2021-10-22 02:49:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 610/777, mem: 9741Mb, iter_time: 0.830s, data_time: 0.005s, total_loss: 5.7, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.5, lr: 1.203e-03, size: 576, ETA: 2 days, 8:56:42\u001b[0m\n",
            "\u001b[32m2021-10-22 02:49:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 620/777, mem: 9741Mb, iter_time: 1.108s, data_time: 0.009s, total_loss: 5.8, iou_loss: 2.0, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.5, lr: 1.203e-03, size: 832, ETA: 2 days, 8:58:41\u001b[0m\n",
            "\u001b[32m2021-10-22 02:49:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 630/777, mem: 9741Mb, iter_time: 1.194s, data_time: 0.003s, total_loss: 4.3, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 0.8, lr: 1.203e-03, size: 608, ETA: 2 days, 9:02:42\u001b[0m\n",
            "\u001b[32m2021-10-22 02:49:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 640/777, mem: 9741Mb, iter_time: 0.910s, data_time: 0.007s, total_loss: 4.8, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.3, lr: 1.203e-03, size: 608, ETA: 2 days, 8:59:56\u001b[0m\n",
            "\u001b[32m2021-10-22 02:50:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 650/777, mem: 9741Mb, iter_time: 0.995s, data_time: 0.008s, total_loss: 5.6, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.6, lr: 1.203e-03, size: 704, ETA: 2 days, 8:59:12\u001b[0m\n",
            "\u001b[32m2021-10-22 02:50:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 660/777, mem: 9741Mb, iter_time: 1.064s, data_time: 0.008s, total_loss: 5.9, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.8, cls_loss: 1.4, lr: 1.203e-03, size: 672, ETA: 2 days, 9:00:05\u001b[0m\n",
            "\u001b[32m2021-10-22 02:50:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 670/777, mem: 9741Mb, iter_time: 1.165s, data_time: 0.008s, total_loss: 6.6, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.9, cls_loss: 1.7, lr: 1.203e-03, size: 832, ETA: 2 days, 9:03:18\u001b[0m\n",
            "\u001b[32m2021-10-22 02:50:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 680/777, mem: 9741Mb, iter_time: 1.152s, data_time: 0.002s, total_loss: 4.6, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.1, lr: 1.203e-03, size: 544, ETA: 2 days, 9:06:10\u001b[0m\n",
            "\u001b[32m2021-10-22 02:50:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 690/777, mem: 9741Mb, iter_time: 0.754s, data_time: 0.008s, total_loss: 4.6, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.2, lr: 1.203e-03, size: 448, ETA: 2 days, 8:59:54\u001b[0m\n",
            "\u001b[32m2021-10-22 02:50:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 700/777, mem: 9741Mb, iter_time: 0.963s, data_time: 0.011s, total_loss: 5.6, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.3, lr: 1.202e-03, size: 768, ETA: 2 days, 8:58:27\u001b[0m\n",
            "\u001b[32m2021-10-22 02:51:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 710/777, mem: 9741Mb, iter_time: 1.253s, data_time: 0.007s, total_loss: 6.2, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.7, cls_loss: 1.5, lr: 1.202e-03, size: 800, ETA: 2 days, 9:03:35\u001b[0m\n",
            "\u001b[32m2021-10-22 02:51:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 720/777, mem: 9741Mb, iter_time: 1.105s, data_time: 0.002s, total_loss: 5.8, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.4, lr: 1.202e-03, size: 480, ETA: 2 days, 9:05:18\u001b[0m\n",
            "\u001b[32m2021-10-22 02:51:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 730/777, mem: 9741Mb, iter_time: 0.886s, data_time: 0.008s, total_loss: 4.7, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.0, lr: 1.202e-03, size: 672, ETA: 2 days, 9:02:07\u001b[0m\n",
            "\u001b[32m2021-10-22 02:51:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 740/777, mem: 9741Mb, iter_time: 1.165s, data_time: 0.010s, total_loss: 6.2, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.7, cls_loss: 1.7, lr: 1.202e-03, size: 832, ETA: 2 days, 9:05:10\u001b[0m\n",
            "\u001b[32m2021-10-22 02:51:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 750/777, mem: 9741Mb, iter_time: 1.231s, data_time: 0.005s, total_loss: 5.7, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.5, lr: 1.202e-03, size: 608, ETA: 2 days, 9:09:37\u001b[0m\n",
            "\u001b[32m2021-10-22 02:52:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 760/777, mem: 9741Mb, iter_time: 0.852s, data_time: 0.008s, total_loss: 5.3, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.2, lr: 1.202e-03, size: 480, ETA: 2 days, 9:05:43\u001b[0m\n",
            "\u001b[32m2021-10-22 02:52:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 41/300, iter: 770/777, mem: 9741Mb, iter_time: 0.804s, data_time: 0.012s, total_loss: 4.8, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.1, lr: 1.202e-03, size: 576, ETA: 2 days, 9:00:51\u001b[0m\n",
            "\u001b[32m2021-10-22 02:52:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mSave weights to /content/gdrive/MyDrive/Sprints/yolox_voc_s/yolox_voc_s/yolox_voc_s\u001b[0m\n",
            "100%|##########| 44/44 [00:13<00:00,  3.14it/s]\n",
            "\u001b[32m2021-10-22 02:52:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.evaluators.voc_evaluator\u001b[0m:\u001b[36m161\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
            "Writing beans VOC results file\n",
            "Writing cake VOC results file\n",
            "Writing candy VOC results file\n",
            "Writing cereal VOC results file\n",
            "Writing chips VOC results file\n",
            "Writing chocolate VOC results file\n",
            "Writing coffee VOC results file\n",
            "Writing corn VOC results file\n",
            "Writing fish VOC results file\n",
            "Writing flour VOC results file\n",
            "Writing honey VOC results file\n",
            "Writing jam VOC results file\n",
            "Writing juice VOC results file\n",
            "Writing milk VOC results file\n",
            "Writing nuts VOC results file\n",
            "Writing oil VOC results file\n",
            "Writing pasta VOC results file\n",
            "Writing rice VOC results file\n",
            "Writing soda VOC results file\n",
            "Writing spices VOC results file\n",
            "Writing sugar VOC results file\n",
            "Writing tea VOC results file\n",
            "Writing tomato_sauce VOC results file\n",
            "Writing vinegar VOC results file\n",
            "Writing water VOC results file\n",
            "Eval IoU : 0.50\n",
            "AP for beans = 0.9346\n",
            "AP for cake = 0.9339\n",
            "AP for candy = 0.7744\n",
            "AP for cereal = 0.9497\n",
            "AP for chips = 0.9278\n",
            "AP for chocolate = 0.9079\n",
            "AP for coffee = 0.9316\n",
            "AP for corn = 0.9504\n",
            "AP for fish = 0.8835\n",
            "AP for flour = 0.9135\n",
            "AP for honey = 0.9550\n",
            "AP for jam = 0.8987\n",
            "AP for juice = 0.8979\n",
            "AP for milk = 0.7227\n",
            "AP for nuts = 0.8809\n",
            "AP for oil = 0.8291\n",
            "AP for pasta = 0.8537\n",
            "AP for rice = 0.9159\n",
            "AP for soda = 0.8834\n",
            "AP for spices = 0.9063\n",
            "AP for sugar = 0.9101\n",
            "AP for tea = 0.8103\n",
            "AP for tomato_sauce = 0.8859\n",
            "AP for vinegar = 0.9623\n",
            "AP for water = 0.9350\n",
            "Mean AP = 0.8942\n",
            "~~~~~~~~\n",
            "Results:\n",
            "0.935\n",
            "0.934\n",
            "0.774\n",
            "0.950\n",
            "0.928\n",
            "0.908\n",
            "0.932\n",
            "0.950\n",
            "0.884\n",
            "0.914\n",
            "0.955\n",
            "0.899\n",
            "0.898\n",
            "0.723\n",
            "0.881\n",
            "0.829\n",
            "0.854\n",
            "0.916\n",
            "0.883\n",
            "0.906\n",
            "0.910\n",
            "0.810\n",
            "0.886\n",
            "0.962\n",
            "0.935\n",
            "0.894\n",
            "~~~~~~~~\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Results computed with the **unofficial** Python eval code.\n",
            "Results should be very close to the official MATLAB eval code.\n",
            "Recompute with `./tools/reval.py --matlab ...` for your paper.\n",
            "-- Thanks, The Management\n",
            "--------------------------------------------------------------\n",
            "Eval IoU : 0.55\n",
            "Eval IoU : 0.60\n",
            "Eval IoU : 0.65\n",
            "Eval IoU : 0.70\n",
            "Eval IoU : 0.75\n",
            "Eval IoU : 0.80\n",
            "Eval IoU : 0.85\n",
            "Eval IoU : 0.90\n",
            "Eval IoU : 0.95\n",
            "--------------------------------------------------------------\n",
            "map_5095: 0.6974100516020927\n",
            "map_50: 0.8941923361064424\n",
            "--------------------------------------------------------------\n",
            "\u001b[32m2021-10-22 02:52:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m314\u001b[0m - \u001b[1m\n",
            "Average forward time: 22.00 ms, Average NMS time: 5.49 ms, Average inference time: 27.48 ms\n",
            "\u001b[0m\n",
            "\u001b[32m2021-10-22 02:52:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mSave weights to /content/gdrive/MyDrive/Sprints/yolox_voc_s/yolox_voc_s/yolox_voc_s\u001b[0m\n",
            "\u001b[32m2021-10-22 02:52:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m193\u001b[0m - \u001b[1m---> start train epoch42\u001b[0m\n",
            "\u001b[32m2021-10-22 02:52:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 10/777, mem: 9741Mb, iter_time: 0.872s, data_time: 0.012s, total_loss: 4.5, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.0, lr: 1.202e-03, size: 640, ETA: 2 days, 8:54:08\u001b[0m\n",
            "\u001b[32m2021-10-22 02:52:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 20/777, mem: 9741Mb, iter_time: 0.990s, data_time: 0.008s, total_loss: 4.6, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.3, lr: 1.202e-03, size: 704, ETA: 2 days, 8:53:22\u001b[0m\n",
            "\u001b[32m2021-10-22 02:53:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 30/777, mem: 9741Mb, iter_time: 1.077s, data_time: 0.007s, total_loss: 5.1, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.2, lr: 1.202e-03, size: 704, ETA: 2 days, 8:54:26\u001b[0m\n",
            "\u001b[32m2021-10-22 02:53:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 40/777, mem: 9741Mb, iter_time: 1.079s, data_time: 0.007s, total_loss: 5.4, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.4, lr: 1.202e-03, size: 736, ETA: 2 days, 8:55:33\u001b[0m\n",
            "\u001b[32m2021-10-22 02:53:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 50/777, mem: 9741Mb, iter_time: 1.162s, data_time: 0.009s, total_loss: 5.9, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.7, cls_loss: 1.6, lr: 1.202e-03, size: 800, ETA: 2 days, 8:58:22\u001b[0m\n",
            "\u001b[32m2021-10-22 02:53:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 60/777, mem: 9741Mb, iter_time: 1.160s, data_time: 0.006s, total_loss: 6.1, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.9, cls_loss: 1.6, lr: 1.202e-03, size: 480, ETA: 2 days, 9:01:07\u001b[0m\n",
            "\u001b[32m2021-10-22 02:53:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 70/777, mem: 9741Mb, iter_time: 0.891s, data_time: 0.009s, total_loss: 5.7, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.6, lr: 1.202e-03, size: 672, ETA: 2 days, 8:58:17\u001b[0m\n",
            "\u001b[32m2021-10-22 02:53:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 80/777, mem: 9741Mb, iter_time: 0.992s, data_time: 0.008s, total_loss: 5.2, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.3, lr: 1.202e-03, size: 608, ETA: 2 days, 8:57:33\u001b[0m\n",
            "\u001b[32m2021-10-22 02:54:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 90/777, mem: 9741Mb, iter_time: 0.903s, data_time: 0.008s, total_loss: 4.7, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.0, lr: 1.202e-03, size: 576, ETA: 2 days, 8:55:00\u001b[0m\n",
            "\u001b[32m2021-10-22 02:54:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 100/777, mem: 9741Mb, iter_time: 0.823s, data_time: 0.006s, total_loss: 5.3, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.2, lr: 1.202e-03, size: 448, ETA: 2 days, 8:50:53\u001b[0m\n",
            "\u001b[32m2021-10-22 02:54:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 110/777, mem: 9741Mb, iter_time: 0.760s, data_time: 0.008s, total_loss: 5.2, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.3, lr: 1.202e-03, size: 544, ETA: 2 days, 8:45:32\u001b[0m\n",
            "\u001b[32m2021-10-22 02:54:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 120/777, mem: 9741Mb, iter_time: 0.853s, data_time: 0.009s, total_loss: 4.6, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.2, lr: 1.202e-03, size: 608, ETA: 2 days, 8:42:06\u001b[0m\n",
            "\u001b[32m2021-10-22 02:54:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 130/777, mem: 9741Mb, iter_time: 0.956s, data_time: 0.009s, total_loss: 5.7, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.5, cls_loss: 1.4, lr: 1.202e-03, size: 736, ETA: 2 days, 8:40:45\u001b[0m\n",
            "\u001b[32m2021-10-22 02:54:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 140/777, mem: 9741Mb, iter_time: 1.130s, data_time: 0.007s, total_loss: 6.1, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.7, cls_loss: 1.6, lr: 1.202e-03, size: 736, ETA: 2 days, 8:42:52\u001b[0m\n",
            "\u001b[32m2021-10-22 02:55:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 150/777, mem: 9741Mb, iter_time: 1.033s, data_time: 0.005s, total_loss: 5.6, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.5, cls_loss: 1.4, lr: 1.202e-03, size: 448, ETA: 2 days, 8:43:02\u001b[0m\n",
            "\u001b[32m2021-10-22 02:55:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 160/777, mem: 9741Mb, iter_time: 0.763s, data_time: 0.005s, total_loss: 5.2, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.5, lr: 1.202e-03, size: 544, ETA: 2 days, 8:37:56\u001b[0m\n",
            "\u001b[32m2021-10-22 02:55:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 170/777, mem: 9741Mb, iter_time: 0.892s, data_time: 0.011s, total_loss: 4.7, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.1, lr: 1.202e-03, size: 672, ETA: 2 days, 8:35:23\u001b[0m\n",
            "\u001b[32m2021-10-22 02:55:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 180/777, mem: 9741Mb, iter_time: 1.019s, data_time: 0.006s, total_loss: 5.3, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.3, lr: 1.202e-03, size: 672, ETA: 2 days, 8:35:20\u001b[0m\n",
            "\u001b[32m2021-10-22 02:55:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 190/777, mem: 9741Mb, iter_time: 0.965s, data_time: 0.004s, total_loss: 4.8, iou_loss: 1.4, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.3, lr: 1.202e-03, size: 480, ETA: 2 days, 8:34:13\u001b[0m\n",
            "\u001b[32m2021-10-22 02:55:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 200/777, mem: 9741Mb, iter_time: 0.766s, data_time: 0.005s, total_loss: 5.0, iou_loss: 2.0, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.1, lr: 1.202e-03, size: 512, ETA: 2 days, 8:29:21\u001b[0m\n",
            "\u001b[32m2021-10-22 02:55:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 210/777, mem: 9741Mb, iter_time: 0.838s, data_time: 0.009s, total_loss: 4.9, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.2, lr: 1.202e-03, size: 672, ETA: 2 days, 8:25:52\u001b[0m\n",
            "\u001b[32m2021-10-22 02:56:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 220/777, mem: 9741Mb, iter_time: 1.054s, data_time: 0.007s, total_loss: 5.4, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.3, lr: 1.201e-03, size: 704, ETA: 2 days, 8:26:31\u001b[0m\n",
            "\u001b[32m2021-10-22 02:56:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 230/777, mem: 9741Mb, iter_time: 1.024s, data_time: 0.005s, total_loss: 6.1, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.8, cls_loss: 1.4, lr: 1.201e-03, size: 448, ETA: 2 days, 8:26:36\u001b[0m\n",
            "\u001b[32m2021-10-22 02:56:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 240/777, mem: 9741Mb, iter_time: 0.736s, data_time: 0.008s, total_loss: 4.8, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.2, lr: 1.201e-03, size: 448, ETA: 2 days, 8:21:18\u001b[0m\n",
            "\u001b[32m2021-10-22 02:56:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 250/777, mem: 9741Mb, iter_time: 0.841s, data_time: 0.007s, total_loss: 4.9, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.2, lr: 1.201e-03, size: 736, ETA: 2 days, 8:18:00\u001b[0m\n",
            "\u001b[32m2021-10-22 02:56:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 260/777, mem: 9741Mb, iter_time: 1.185s, data_time: 0.009s, total_loss: 6.3, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.9, cls_loss: 1.6, lr: 1.201e-03, size: 832, ETA: 2 days, 8:21:06\u001b[0m\n",
            "\u001b[32m2021-10-22 02:56:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 270/777, mem: 9741Mb, iter_time: 1.327s, data_time: 0.006s, total_loss: 5.4, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.5, cls_loss: 1.2, lr: 1.201e-03, size: 832, ETA: 2 days, 8:26:45\u001b[0m\n",
            "\u001b[32m2021-10-22 02:57:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 280/777, mem: 9741Mb, iter_time: 1.340s, data_time: 0.008s, total_loss: 4.7, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.1, lr: 1.201e-03, size: 832, ETA: 2 days, 8:32:35\u001b[0m\n",
            "\u001b[32m2021-10-22 02:57:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 290/777, mem: 9741Mb, iter_time: 1.276s, data_time: 0.007s, total_loss: 5.1, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.3, lr: 1.201e-03, size: 704, ETA: 2 days, 8:37:11\u001b[0m\n",
            "\u001b[32m2021-10-22 02:57:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 300/777, mem: 9741Mb, iter_time: 1.052s, data_time: 0.008s, total_loss: 4.6, iou_loss: 1.4, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.2, lr: 1.201e-03, size: 512, ETA: 2 days, 8:37:42\u001b[0m\n",
            "\u001b[32m2021-10-22 02:57:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 310/777, mem: 9741Mb, iter_time: 0.840s, data_time: 0.009s, total_loss: 4.2, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 1.7, cls_loss: 0.9, lr: 1.201e-03, size: 576, ETA: 2 days, 8:34:24\u001b[0m\n",
            "\u001b[32m2021-10-22 02:57:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 320/777, mem: 9741Mb, iter_time: 0.992s, data_time: 0.007s, total_loss: 5.4, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.3, lr: 1.201e-03, size: 800, ETA: 2 days, 8:33:51\u001b[0m\n",
            "\u001b[32m2021-10-22 02:58:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 330/777, mem: 9741Mb, iter_time: 1.186s, data_time: 0.007s, total_loss: 5.3, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.5, cls_loss: 1.2, lr: 1.201e-03, size: 544, ETA: 2 days, 8:36:45\u001b[0m\n",
            "\u001b[32m2021-10-22 02:58:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 340/777, mem: 9741Mb, iter_time: 0.947s, data_time: 0.006s, total_loss: 4.9, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.3, lr: 1.201e-03, size: 704, ETA: 2 days, 8:35:23\u001b[0m\n",
            "\u001b[32m2021-10-22 02:58:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 350/777, mem: 9741Mb, iter_time: 1.026s, data_time: 0.012s, total_loss: 4.3, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.7, cls_loss: 1.0, lr: 1.201e-03, size: 480, ETA: 2 days, 8:35:26\u001b[0m\n",
            "\u001b[32m2021-10-22 02:58:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 360/777, mem: 9741Mb, iter_time: 0.831s, data_time: 0.008s, total_loss: 5.2, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.5, lr: 1.201e-03, size: 640, ETA: 2 days, 8:32:04\u001b[0m\n",
            "\u001b[32m2021-10-22 02:58:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 370/777, mem: 9741Mb, iter_time: 0.981s, data_time: 0.009s, total_loss: 5.3, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.2, lr: 1.201e-03, size: 608, ETA: 2 days, 8:31:20\u001b[0m\n",
            "\u001b[32m2021-10-22 02:58:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 380/777, mem: 9741Mb, iter_time: 0.926s, data_time: 0.004s, total_loss: 5.7, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.5, cls_loss: 1.4, lr: 1.201e-03, size: 640, ETA: 2 days, 8:29:39\u001b[0m\n",
            "\u001b[32m2021-10-22 02:59:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 390/777, mem: 9741Mb, iter_time: 0.993s, data_time: 0.010s, total_loss: 4.7, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.1, lr: 1.201e-03, size: 768, ETA: 2 days, 8:29:09\u001b[0m\n",
            "\u001b[32m2021-10-22 02:59:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 400/777, mem: 9741Mb, iter_time: 1.065s, data_time: 0.004s, total_loss: 6.4, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.9, cls_loss: 1.8, lr: 1.201e-03, size: 448, ETA: 2 days, 8:29:53\u001b[0m\n",
            "\u001b[32m2021-10-22 02:59:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 410/777, mem: 9741Mb, iter_time: 0.885s, data_time: 0.006s, total_loss: 5.2, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.2, lr: 1.201e-03, size: 768, ETA: 2 days, 8:27:32\u001b[0m\n",
            "\u001b[32m2021-10-22 02:59:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 420/777, mem: 9741Mb, iter_time: 1.213s, data_time: 0.007s, total_loss: 5.8, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.5, cls_loss: 1.5, lr: 1.201e-03, size: 800, ETA: 2 days, 8:30:46\u001b[0m\n",
            "\u001b[32m2021-10-22 02:59:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 430/777, mem: 9741Mb, iter_time: 1.203s, data_time: 0.004s, total_loss: 5.0, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.2, lr: 1.201e-03, size: 576, ETA: 2 days, 8:33:48\u001b[0m\n",
            "\u001b[32m2021-10-22 02:59:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 440/777, mem: 9741Mb, iter_time: 0.975s, data_time: 0.005s, total_loss: 5.0, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.2, lr: 1.201e-03, size: 768, ETA: 2 days, 8:32:59\u001b[0m\n",
            "\u001b[32m2021-10-22 03:00:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 450/777, mem: 9741Mb, iter_time: 1.174s, data_time: 0.007s, total_loss: 5.7, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.5, lr: 1.201e-03, size: 768, ETA: 2 days, 8:35:29\u001b[0m\n",
            "\u001b[32m2021-10-22 03:00:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 460/777, mem: 9741Mb, iter_time: 1.108s, data_time: 0.007s, total_loss: 5.8, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.7, cls_loss: 1.3, lr: 1.201e-03, size: 512, ETA: 2 days, 8:36:53\u001b[0m\n",
            "\u001b[32m2021-10-22 03:00:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 470/777, mem: 9741Mb, iter_time: 0.925s, data_time: 0.007s, total_loss: 5.0, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.2, lr: 1.201e-03, size: 800, ETA: 2 days, 8:35:13\u001b[0m\n",
            "\u001b[32m2021-10-22 03:00:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 480/777, mem: 9741Mb, iter_time: 1.229s, data_time: 0.009s, total_loss: 4.7, iou_loss: 1.4, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.3, lr: 1.201e-03, size: 672, ETA: 2 days, 8:38:35\u001b[0m\n",
            "\u001b[32m2021-10-22 03:00:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 490/777, mem: 9741Mb, iter_time: 1.094s, data_time: 0.006s, total_loss: 5.3, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.2, lr: 1.201e-03, size: 768, ETA: 2 days, 8:39:42\u001b[0m\n",
            "\u001b[32m2021-10-22 03:01:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 500/777, mem: 9741Mb, iter_time: 1.128s, data_time: 0.005s, total_loss: 6.0, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.9, cls_loss: 1.6, lr: 1.201e-03, size: 736, ETA: 2 days, 8:41:21\u001b[0m\n",
            "\u001b[32m2021-10-22 03:01:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 510/777, mem: 9741Mb, iter_time: 1.114s, data_time: 0.007s, total_loss: 5.3, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.4, lr: 1.200e-03, size: 704, ETA: 2 days, 8:42:45\u001b[0m\n",
            "\u001b[32m2021-10-22 03:01:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 520/777, mem: 9741Mb, iter_time: 1.158s, data_time: 0.006s, total_loss: 5.7, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.5, cls_loss: 1.6, lr: 1.200e-03, size: 800, ETA: 2 days, 8:44:51\u001b[0m\n",
            "\u001b[32m2021-10-22 03:01:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 530/777, mem: 9741Mb, iter_time: 1.161s, data_time: 0.006s, total_loss: 5.2, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.3, lr: 1.200e-03, size: 480, ETA: 2 days, 8:46:59\u001b[0m\n",
            "\u001b[32m2021-10-22 03:01:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 540/777, mem: 9741Mb, iter_time: 0.787s, data_time: 0.008s, total_loss: 4.8, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 0.9, lr: 1.200e-03, size: 448, ETA: 2 days, 8:43:07\u001b[0m\n",
            "\u001b[32m2021-10-22 03:01:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 550/777, mem: 9741Mb, iter_time: 0.841s, data_time: 0.008s, total_loss: 5.7, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.6, cls_loss: 1.4, lr: 1.200e-03, size: 736, ETA: 2 days, 8:40:09\u001b[0m\n",
            "\u001b[32m2021-10-22 03:02:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 560/777, mem: 9741Mb, iter_time: 1.132s, data_time: 0.011s, total_loss: 4.6, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.0, lr: 1.200e-03, size: 672, ETA: 2 days, 8:41:49\u001b[0m\n",
            "\u001b[32m2021-10-22 03:02:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 570/777, mem: 9741Mb, iter_time: 1.132s, data_time: 0.007s, total_loss: 5.4, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 2.5, cls_loss: 1.4, lr: 1.200e-03, size: 800, ETA: 2 days, 8:43:27\u001b[0m\n",
            "\u001b[32m2021-10-22 03:02:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 580/777, mem: 9741Mb, iter_time: 1.220s, data_time: 0.006s, total_loss: 5.7, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.5, cls_loss: 1.4, lr: 1.200e-03, size: 640, ETA: 2 days, 8:46:27\u001b[0m\n",
            "\u001b[32m2021-10-22 03:02:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 590/777, mem: 9741Mb, iter_time: 1.040s, data_time: 0.008s, total_loss: 4.2, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 0.8, lr: 1.200e-03, size: 736, ETA: 2 days, 8:46:37\u001b[0m\n",
            "\u001b[32m2021-10-22 03:02:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 600/777, mem: 9741Mb, iter_time: 1.140s, data_time: 0.009s, total_loss: 5.8, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.7, cls_loss: 1.4, lr: 1.200e-03, size: 736, ETA: 2 days, 8:48:20\u001b[0m\n",
            "\u001b[32m2021-10-22 03:03:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 610/777, mem: 9741Mb, iter_time: 1.097s, data_time: 0.008s, total_loss: 4.4, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 0.9, lr: 1.200e-03, size: 576, ETA: 2 days, 8:49:22\u001b[0m\n",
            "\u001b[32m2021-10-22 03:03:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 620/777, mem: 9741Mb, iter_time: 0.977s, data_time: 0.007s, total_loss: 5.6, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.5, lr: 1.200e-03, size: 736, ETA: 2 days, 8:48:32\u001b[0m\n",
            "\u001b[32m2021-10-22 03:03:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 630/777, mem: 9741Mb, iter_time: 1.110s, data_time: 0.006s, total_loss: 5.1, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.4, lr: 1.200e-03, size: 544, ETA: 2 days, 8:49:45\u001b[0m\n",
            "\u001b[32m2021-10-22 03:03:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 640/777, mem: 9741Mb, iter_time: 0.962s, data_time: 0.009s, total_loss: 5.3, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.4, lr: 1.200e-03, size: 832, ETA: 2 days, 8:48:43\u001b[0m\n",
            "\u001b[32m2021-10-22 03:03:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 650/777, mem: 9741Mb, iter_time: 1.328s, data_time: 0.011s, total_loss: 7.2, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 3.3, cls_loss: 2.0, lr: 1.200e-03, size: 704, ETA: 2 days, 8:53:13\u001b[0m\n",
            "\u001b[32m2021-10-22 03:03:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 660/777, mem: 9741Mb, iter_time: 1.075s, data_time: 0.005s, total_loss: 4.7, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.1, lr: 1.200e-03, size: 640, ETA: 2 days, 8:53:51\u001b[0m\n",
            "\u001b[32m2021-10-22 03:04:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 670/777, mem: 9741Mb, iter_time: 0.953s, data_time: 0.006s, total_loss: 5.3, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.4, lr: 1.200e-03, size: 640, ETA: 2 days, 8:52:39\u001b[0m\n",
            "\u001b[32m2021-10-22 03:04:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 680/777, mem: 9741Mb, iter_time: 0.899s, data_time: 0.006s, total_loss: 5.8, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.6, cls_loss: 1.3, lr: 1.200e-03, size: 480, ETA: 2 days, 8:50:40\u001b[0m\n",
            "\u001b[32m2021-10-22 03:04:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 690/777, mem: 9741Mb, iter_time: 0.911s, data_time: 0.007s, total_loss: 5.4, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.4, lr: 1.200e-03, size: 800, ETA: 2 days, 8:48:52\u001b[0m\n",
            "\u001b[32m2021-10-22 03:04:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 700/777, mem: 9741Mb, iter_time: 1.238s, data_time: 0.005s, total_loss: 4.5, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.0, lr: 1.200e-03, size: 544, ETA: 2 days, 8:51:55\u001b[0m\n",
            "\u001b[32m2021-10-22 03:04:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 710/777, mem: 9741Mb, iter_time: 0.931s, data_time: 0.006s, total_loss: 4.8, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 0.9, lr: 1.200e-03, size: 768, ETA: 2 days, 8:50:26\u001b[0m\n",
            "\u001b[32m2021-10-22 03:04:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 720/777, mem: 9741Mb, iter_time: 1.140s, data_time: 0.008s, total_loss: 4.8, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.2, lr: 1.200e-03, size: 576, ETA: 2 days, 8:52:01\u001b[0m\n",
            "\u001b[32m2021-10-22 03:05:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 730/777, mem: 9741Mb, iter_time: 1.015s, data_time: 0.009s, total_loss: 5.5, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.5, lr: 1.200e-03, size: 832, ETA: 2 days, 8:51:45\u001b[0m\n",
            "\u001b[32m2021-10-22 03:05:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 740/777, mem: 9741Mb, iter_time: 1.268s, data_time: 0.006s, total_loss: 4.4, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.0, lr: 1.200e-03, size: 576, ETA: 2 days, 8:55:11\u001b[0m\n",
            "\u001b[32m2021-10-22 03:05:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 750/777, mem: 9741Mb, iter_time: 0.969s, data_time: 0.007s, total_loss: 5.3, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.3, lr: 1.200e-03, size: 736, ETA: 2 days, 8:54:15\u001b[0m\n",
            "\u001b[32m2021-10-22 03:05:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 760/777, mem: 9741Mb, iter_time: 1.127s, data_time: 0.012s, total_loss: 5.2, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.2, lr: 1.200e-03, size: 672, ETA: 2 days, 8:55:36\u001b[0m\n",
            "\u001b[32m2021-10-22 03:05:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 42/300, iter: 770/777, mem: 9741Mb, iter_time: 1.016s, data_time: 0.008s, total_loss: 6.3, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 3.0, cls_loss: 1.7, lr: 1.200e-03, size: 544, ETA: 2 days, 8:55:20\u001b[0m\n",
            "\u001b[32m2021-10-22 03:05:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mSave weights to /content/gdrive/MyDrive/Sprints/yolox_voc_s/yolox_voc_s/yolox_voc_s\u001b[0m\n",
            "100%|##########| 44/44 [00:15<00:00,  2.90it/s]\n",
            "\u001b[32m2021-10-22 03:06:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.evaluators.voc_evaluator\u001b[0m:\u001b[36m161\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
            "Writing beans VOC results file\n",
            "Writing cake VOC results file\n",
            "Writing candy VOC results file\n",
            "Writing cereal VOC results file\n",
            "Writing chips VOC results file\n",
            "Writing chocolate VOC results file\n",
            "Writing coffee VOC results file\n",
            "Writing corn VOC results file\n",
            "Writing fish VOC results file\n",
            "Writing flour VOC results file\n",
            "Writing honey VOC results file\n",
            "Writing jam VOC results file\n",
            "Writing juice VOC results file\n",
            "Writing milk VOC results file\n",
            "Writing nuts VOC results file\n",
            "Writing oil VOC results file\n",
            "Writing pasta VOC results file\n",
            "Writing rice VOC results file\n",
            "Writing soda VOC results file\n",
            "Writing spices VOC results file\n",
            "Writing sugar VOC results file\n",
            "Writing tea VOC results file\n",
            "Writing tomato_sauce VOC results file\n",
            "Writing vinegar VOC results file\n",
            "Writing water VOC results file\n",
            "Eval IoU : 0.50\n",
            "AP for beans = 0.9309\n",
            "AP for cake = 0.9249\n",
            "AP for candy = 0.7542\n",
            "AP for cereal = 0.9456\n",
            "AP for chips = 0.9259\n",
            "AP for chocolate = 0.9034\n",
            "AP for coffee = 0.9352\n",
            "AP for corn = 0.9504\n",
            "AP for fish = 0.8828\n",
            "AP for flour = 0.9135\n",
            "AP for honey = 0.9550\n",
            "AP for jam = 0.8976\n",
            "AP for juice = 0.8977\n",
            "AP for milk = 0.7227\n",
            "AP for nuts = 0.8852\n",
            "AP for oil = 0.8276\n",
            "AP for pasta = 0.8599\n",
            "AP for rice = 0.8952\n",
            "AP for soda = 0.8808\n",
            "AP for spices = 0.9063\n",
            "AP for sugar = 0.9097\n",
            "AP for tea = 0.8081\n",
            "AP for tomato_sauce = 0.8819\n",
            "AP for vinegar = 0.9712\n",
            "AP for water = 0.9320\n",
            "Mean AP = 0.8919\n",
            "~~~~~~~~\n",
            "Results:\n",
            "0.931\n",
            "0.925\n",
            "0.754\n",
            "0.946\n",
            "0.926\n",
            "0.903\n",
            "0.935\n",
            "0.950\n",
            "0.883\n",
            "0.914\n",
            "0.955\n",
            "0.898\n",
            "0.898\n",
            "0.723\n",
            "0.885\n",
            "0.828\n",
            "0.860\n",
            "0.895\n",
            "0.881\n",
            "0.906\n",
            "0.910\n",
            "0.808\n",
            "0.882\n",
            "0.971\n",
            "0.932\n",
            "0.892\n",
            "~~~~~~~~\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Results computed with the **unofficial** Python eval code.\n",
            "Results should be very close to the official MATLAB eval code.\n",
            "Recompute with `./tools/reval.py --matlab ...` for your paper.\n",
            "-- Thanks, The Management\n",
            "--------------------------------------------------------------\n",
            "Eval IoU : 0.55\n",
            "Eval IoU : 0.60\n",
            "Eval IoU : 0.65\n",
            "Eval IoU : 0.70\n",
            "Eval IoU : 0.75\n",
            "Eval IoU : 0.80\n",
            "Eval IoU : 0.85\n",
            "Eval IoU : 0.90\n",
            "Eval IoU : 0.95\n",
            "--------------------------------------------------------------\n",
            "map_5095: 0.6947190136561233\n",
            "map_50: 0.8919170467170281\n",
            "--------------------------------------------------------------\n",
            "\u001b[32m2021-10-22 03:06:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m314\u001b[0m - \u001b[1m\n",
            "Average forward time: 23.31 ms, Average NMS time: 6.00 ms, Average inference time: 29.30 ms\n",
            "\u001b[0m\n",
            "\u001b[32m2021-10-22 03:06:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mSave weights to /content/gdrive/MyDrive/Sprints/yolox_voc_s/yolox_voc_s/yolox_voc_s\u001b[0m\n",
            "\u001b[32m2021-10-22 03:06:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m193\u001b[0m - \u001b[1m---> start train epoch43\u001b[0m\n",
            "\u001b[32m2021-10-22 03:06:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 10/777, mem: 9741Mb, iter_time: 1.189s, data_time: 0.008s, total_loss: 4.7, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.0, lr: 1.200e-03, size: 704, ETA: 2 days, 8:56:03\u001b[0m\n",
            "\u001b[32m2021-10-22 03:06:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 20/777, mem: 9741Mb, iter_time: 1.145s, data_time: 0.008s, total_loss: 5.9, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.6, cls_loss: 1.4, lr: 1.199e-03, size: 512, ETA: 2 days, 8:57:38\u001b[0m\n",
            "\u001b[32m2021-10-22 03:06:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 30/777, mem: 9741Mb, iter_time: 0.880s, data_time: 0.006s, total_loss: 5.0, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.3, lr: 1.199e-03, size: 608, ETA: 2 days, 8:55:27\u001b[0m\n",
            "\u001b[32m2021-10-22 03:06:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 40/777, mem: 9741Mb, iter_time: 0.920s, data_time: 0.011s, total_loss: 5.2, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.2, lr: 1.199e-03, size: 480, ETA: 2 days, 8:53:50\u001b[0m\n",
            "\u001b[32m2021-10-22 03:07:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 50/777, mem: 9741Mb, iter_time: 0.856s, data_time: 0.007s, total_loss: 5.1, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.2, lr: 1.199e-03, size: 800, ETA: 2 days, 8:51:20\u001b[0m\n",
            "\u001b[32m2021-10-22 03:07:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 60/777, mem: 9741Mb, iter_time: 1.256s, data_time: 0.009s, total_loss: 6.1, iou_loss: 2.0, l1_loss: 0.0, conf_loss: 2.7, cls_loss: 1.5, lr: 1.199e-03, size: 800, ETA: 2 days, 8:54:26\u001b[0m\n",
            "\u001b[32m2021-10-22 03:07:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 70/777, mem: 9741Mb, iter_time: 1.244s, data_time: 0.005s, total_loss: 5.9, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.5, cls_loss: 1.7, lr: 1.199e-03, size: 512, ETA: 2 days, 8:57:21\u001b[0m\n",
            "\u001b[32m2021-10-22 03:07:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 80/777, mem: 9741Mb, iter_time: 0.951s, data_time: 0.004s, total_loss: 4.8, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.1, lr: 1.199e-03, size: 608, ETA: 2 days, 8:56:10\u001b[0m\n",
            "\u001b[32m2021-10-22 03:07:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 90/777, mem: 9741Mb, iter_time: 0.914s, data_time: 0.008s, total_loss: 4.8, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.2, lr: 1.199e-03, size: 640, ETA: 2 days, 8:54:30\u001b[0m\n",
            "\u001b[32m2021-10-22 03:08:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 100/777, mem: 9741Mb, iter_time: 0.942s, data_time: 0.008s, total_loss: 4.5, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.0, lr: 1.199e-03, size: 608, ETA: 2 days, 8:53:14\u001b[0m\n",
            "\u001b[32m2021-10-22 03:08:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 110/777, mem: 9741Mb, iter_time: 0.949s, data_time: 0.003s, total_loss: 4.5, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.0, lr: 1.199e-03, size: 768, ETA: 2 days, 8:52:03\u001b[0m\n",
            "\u001b[32m2021-10-22 03:08:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.handle\u001b[0m:\u001b[36m140\u001b[0m - \u001b[1mGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\u001b[0m\n",
            "\u001b[32m2021-10-22 03:08:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 120/777, mem: 9741Mb, iter_time: 1.095s, data_time: 0.007s, total_loss: 5.1, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.2, lr: 1.199e-03, size: 544, ETA: 2 days, 8:52:53\u001b[0m\n",
            "\u001b[32m2021-10-22 03:08:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 130/777, mem: 9741Mb, iter_time: 0.933s, data_time: 0.005s, total_loss: 5.1, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.2, lr: 1.199e-03, size: 544, ETA: 2 days, 8:51:30\u001b[0m\n",
            "\u001b[32m2021-10-22 03:08:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 140/777, mem: 9741Mb, iter_time: 0.836s, data_time: 0.010s, total_loss: 5.3, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.2, lr: 1.199e-03, size: 640, ETA: 2 days, 8:48:49\u001b[0m\n",
            "\u001b[32m2021-10-22 03:08:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 150/777, mem: 9741Mb, iter_time: 0.902s, data_time: 0.009s, total_loss: 5.4, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.3, lr: 1.199e-03, size: 576, ETA: 2 days, 8:47:02\u001b[0m\n",
            "\u001b[32m2021-10-22 03:08:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 160/777, mem: 9741Mb, iter_time: 0.921s, data_time: 0.008s, total_loss: 4.9, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.3, lr: 1.199e-03, size: 736, ETA: 2 days, 8:45:32\u001b[0m\n",
            "\u001b[32m2021-10-22 03:09:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 170/777, mem: 9741Mb, iter_time: 1.054s, data_time: 0.009s, total_loss: 5.6, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 2.7, cls_loss: 1.4, lr: 1.199e-03, size: 544, ETA: 2 days, 8:45:49\u001b[0m\n",
            "\u001b[32m2021-10-22 03:09:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 180/777, mem: 9741Mb, iter_time: 0.926s, data_time: 0.005s, total_loss: 5.4, iou_loss: 2.0, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.4, lr: 1.199e-03, size: 768, ETA: 2 days, 8:44:24\u001b[0m\n",
            "\u001b[32m2021-10-22 03:09:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 190/777, mem: 9741Mb, iter_time: 1.150s, data_time: 0.007s, total_loss: 5.8, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.7, cls_loss: 1.5, lr: 1.199e-03, size: 704, ETA: 2 days, 8:45:57\u001b[0m\n",
            "\u001b[32m2021-10-22 03:09:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 200/777, mem: 9741Mb, iter_time: 1.109s, data_time: 0.010s, total_loss: 4.7, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.0, lr: 1.199e-03, size: 768, ETA: 2 days, 8:46:57\u001b[0m\n",
            "\u001b[32m2021-10-22 03:09:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 210/777, mem: 9741Mb, iter_time: 1.103s, data_time: 0.006s, total_loss: 5.2, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.3, lr: 1.199e-03, size: 544, ETA: 2 days, 8:47:51\u001b[0m\n",
            "\u001b[32m2021-10-22 03:10:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 220/777, mem: 9741Mb, iter_time: 0.928s, data_time: 0.006s, total_loss: 4.4, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.7, cls_loss: 1.1, lr: 1.199e-03, size: 480, ETA: 2 days, 8:46:28\u001b[0m\n",
            "\u001b[32m2021-10-22 03:10:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 230/777, mem: 9741Mb, iter_time: 0.779s, data_time: 0.006s, total_loss: 4.6, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.0, lr: 1.199e-03, size: 608, ETA: 2 days, 8:43:09\u001b[0m\n",
            "\u001b[32m2021-10-22 03:10:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 240/777, mem: 9741Mb, iter_time: 0.889s, data_time: 0.009s, total_loss: 4.8, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.3, lr: 1.199e-03, size: 768, ETA: 2 days, 8:41:17\u001b[0m\n",
            "\u001b[32m2021-10-22 03:10:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 250/777, mem: 9741Mb, iter_time: 1.171s, data_time: 0.008s, total_loss: 4.5, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.0, lr: 1.199e-03, size: 704, ETA: 2 days, 8:43:04\u001b[0m\n",
            "\u001b[32m2021-10-22 03:10:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 260/777, mem: 9741Mb, iter_time: 1.135s, data_time: 0.008s, total_loss: 5.7, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.5, lr: 1.199e-03, size: 800, ETA: 2 days, 8:44:23\u001b[0m\n",
            "\u001b[32m2021-10-22 03:10:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 270/777, mem: 9741Mb, iter_time: 1.173s, data_time: 0.007s, total_loss: 5.5, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.5, lr: 1.199e-03, size: 512, ETA: 2 days, 8:46:10\u001b[0m\n",
            "\u001b[32m2021-10-22 03:11:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 280/777, mem: 9741Mb, iter_time: 0.911s, data_time: 0.006s, total_loss: 5.0, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.2, lr: 1.199e-03, size: 512, ETA: 2 days, 8:44:36\u001b[0m\n",
            "\u001b[32m2021-10-22 03:11:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 290/777, mem: 9741Mb, iter_time: 0.778s, data_time: 0.006s, total_loss: 4.5, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 1.7, cls_loss: 1.1, lr: 1.199e-03, size: 480, ETA: 2 days, 8:41:20\u001b[0m\n",
            "\u001b[32m2021-10-22 03:11:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 300/777, mem: 9741Mb, iter_time: 0.805s, data_time: 0.006s, total_loss: 4.7, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.0, lr: 1.199e-03, size: 672, ETA: 2 days, 8:38:26\u001b[0m\n",
            "\u001b[32m2021-10-22 03:11:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 310/777, mem: 9741Mb, iter_time: 1.021s, data_time: 0.009s, total_loss: 5.1, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.1, lr: 1.198e-03, size: 832, ETA: 2 days, 8:38:18\u001b[0m\n",
            "\u001b[32m2021-10-22 03:11:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 320/777, mem: 9741Mb, iter_time: 1.244s, data_time: 0.008s, total_loss: 5.5, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.5, lr: 1.198e-03, size: 512, ETA: 2 days, 8:40:58\u001b[0m\n",
            "\u001b[32m2021-10-22 03:11:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 330/777, mem: 9741Mb, iter_time: 0.997s, data_time: 0.006s, total_loss: 4.9, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.0, lr: 1.198e-03, size: 832, ETA: 2 days, 8:40:31\u001b[0m\n",
            "\u001b[32m2021-10-22 03:12:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 340/777, mem: 9741Mb, iter_time: 1.234s, data_time: 0.010s, total_loss: 5.1, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.4, lr: 1.198e-03, size: 448, ETA: 2 days, 8:43:02\u001b[0m\n",
            "\u001b[32m2021-10-22 03:12:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 350/777, mem: 9741Mb, iter_time: 0.962s, data_time: 0.006s, total_loss: 5.2, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.2, lr: 1.198e-03, size: 832, ETA: 2 days, 8:42:08\u001b[0m\n",
            "\u001b[32m2021-10-22 03:12:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 360/777, mem: 9741Mb, iter_time: 1.304s, data_time: 0.011s, total_loss: 4.8, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.1, lr: 1.198e-03, size: 736, ETA: 2 days, 8:45:30\u001b[0m\n",
            "\u001b[32m2021-10-22 03:12:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 370/777, mem: 9741Mb, iter_time: 1.193s, data_time: 0.009s, total_loss: 4.2, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 0.9, lr: 1.198e-03, size: 576, ETA: 2 days, 8:47:27\u001b[0m\n",
            "\u001b[32m2021-10-22 03:12:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 380/777, mem: 9741Mb, iter_time: 0.981s, data_time: 0.005s, total_loss: 5.2, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.3, lr: 1.198e-03, size: 736, ETA: 2 days, 8:46:47\u001b[0m\n",
            "\u001b[32m2021-10-22 03:12:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 390/777, mem: 9741Mb, iter_time: 1.068s, data_time: 0.008s, total_loss: 6.2, iou_loss: 2.0, l1_loss: 0.0, conf_loss: 2.7, cls_loss: 1.5, lr: 1.198e-03, size: 480, ETA: 2 days, 8:47:10\u001b[0m\n",
            "\u001b[32m2021-10-22 03:13:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 400/777, mem: 9741Mb, iter_time: 0.914s, data_time: 0.005s, total_loss: 5.5, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.6, lr: 1.198e-03, size: 704, ETA: 2 days, 8:45:41\u001b[0m\n",
            "\u001b[32m2021-10-22 03:13:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 410/777, mem: 9741Mb, iter_time: 1.004s, data_time: 0.009s, total_loss: 5.8, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.5, cls_loss: 1.5, lr: 1.198e-03, size: 544, ETA: 2 days, 8:45:18\u001b[0m\n",
            "\u001b[32m2021-10-22 03:13:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 420/777, mem: 9741Mb, iter_time: 0.919s, data_time: 0.007s, total_loss: 5.4, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.6, lr: 1.198e-03, size: 704, ETA: 2 days, 8:43:53\u001b[0m\n",
            "\u001b[32m2021-10-22 03:13:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 430/777, mem: 9741Mb, iter_time: 1.100s, data_time: 0.010s, total_loss: 6.2, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.7, cls_loss: 1.7, lr: 1.198e-03, size: 800, ETA: 2 days, 8:44:40\u001b[0m\n",
            "\u001b[32m2021-10-22 03:13:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 440/777, mem: 9741Mb, iter_time: 1.190s, data_time: 0.007s, total_loss: 5.3, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.1, lr: 1.198e-03, size: 512, ETA: 2 days, 8:46:32\u001b[0m\n",
            "\u001b[32m2021-10-22 03:13:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 450/777, mem: 9741Mb, iter_time: 0.926s, data_time: 0.004s, total_loss: 4.8, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.3, lr: 1.198e-03, size: 608, ETA: 2 days, 8:45:12\u001b[0m\n",
            "\u001b[32m2021-10-22 03:14:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 460/777, mem: 9741Mb, iter_time: 0.908s, data_time: 0.008s, total_loss: 5.8, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.8, lr: 1.198e-03, size: 640, ETA: 2 days, 8:43:41\u001b[0m\n",
            "\u001b[32m2021-10-22 03:14:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 470/777, mem: 9741Mb, iter_time: 0.953s, data_time: 0.013s, total_loss: 5.9, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.8, cls_loss: 1.5, lr: 1.198e-03, size: 704, ETA: 2 days, 8:42:42\u001b[0m\n",
            "\u001b[32m2021-10-22 03:14:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 480/777, mem: 9741Mb, iter_time: 1.050s, data_time: 0.007s, total_loss: 5.3, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.2, lr: 1.198e-03, size: 640, ETA: 2 days, 8:42:52\u001b[0m\n",
            "\u001b[32m2021-10-22 03:14:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 490/777, mem: 9741Mb, iter_time: 0.993s, data_time: 0.008s, total_loss: 4.9, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.0, lr: 1.198e-03, size: 672, ETA: 2 days, 8:42:22\u001b[0m\n",
            "\u001b[32m2021-10-22 03:14:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 500/777, mem: 9741Mb, iter_time: 1.020s, data_time: 0.007s, total_loss: 6.0, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.7, cls_loss: 1.5, lr: 1.198e-03, size: 800, ETA: 2 days, 8:42:12\u001b[0m\n",
            "\u001b[32m2021-10-22 03:14:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 510/777, mem: 9741Mb, iter_time: 1.205s, data_time: 0.012s, total_loss: 5.0, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.2, lr: 1.198e-03, size: 512, ETA: 2 days, 8:44:11\u001b[0m\n",
            "\u001b[32m2021-10-22 03:15:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 520/777, mem: 9741Mb, iter_time: 0.949s, data_time: 0.006s, total_loss: 5.1, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.3, lr: 1.198e-03, size: 672, ETA: 2 days, 8:43:10\u001b[0m\n",
            "\u001b[32m2021-10-22 03:15:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 530/777, mem: 9741Mb, iter_time: 0.972s, data_time: 0.011s, total_loss: 5.1, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.2, lr: 1.198e-03, size: 480, ETA: 2 days, 8:42:26\u001b[0m\n",
            "\u001b[32m2021-10-22 03:15:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 540/777, mem: 9741Mb, iter_time: 0.851s, data_time: 0.009s, total_loss: 5.5, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.4, lr: 1.198e-03, size: 704, ETA: 2 days, 8:40:17\u001b[0m\n",
            "\u001b[32m2021-10-22 03:15:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 550/777, mem: 9741Mb, iter_time: 1.035s, data_time: 0.008s, total_loss: 5.7, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.5, cls_loss: 1.5, lr: 1.198e-03, size: 672, ETA: 2 days, 8:40:17\u001b[0m\n",
            "\u001b[32m2021-10-22 03:15:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 560/777, mem: 9741Mb, iter_time: 1.023s, data_time: 0.009s, total_loss: 5.0, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.0, lr: 1.198e-03, size: 512, ETA: 2 days, 8:40:09\u001b[0m\n",
            "\u001b[32m2021-10-22 03:15:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 570/777, mem: 9741Mb, iter_time: 0.897s, data_time: 0.005s, total_loss: 5.7, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.5, cls_loss: 1.5, lr: 1.198e-03, size: 768, ETA: 2 days, 8:38:33\u001b[0m\n",
            "\u001b[32m2021-10-22 03:16:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 580/777, mem: 9741Mb, iter_time: 1.103s, data_time: 0.009s, total_loss: 5.6, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.5, lr: 1.198e-03, size: 576, ETA: 2 days, 8:39:20\u001b[0m\n",
            "\u001b[32m2021-10-22 03:16:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 590/777, mem: 9741Mb, iter_time: 0.922s, data_time: 0.009s, total_loss: 5.0, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.2, lr: 1.198e-03, size: 576, ETA: 2 days, 8:38:02\u001b[0m\n",
            "\u001b[32m2021-10-22 03:16:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 600/777, mem: 9741Mb, iter_time: 0.886s, data_time: 0.006s, total_loss: 4.1, iou_loss: 1.4, l1_loss: 0.0, conf_loss: 1.7, cls_loss: 1.0, lr: 1.197e-03, size: 608, ETA: 2 days, 8:36:21\u001b[0m\n",
            "\u001b[32m2021-10-22 03:16:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 610/777, mem: 9741Mb, iter_time: 0.940s, data_time: 0.008s, total_loss: 4.4, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 0.9, lr: 1.197e-03, size: 768, ETA: 2 days, 8:35:16\u001b[0m\n",
            "\u001b[32m2021-10-22 03:16:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 620/777, mem: 9741Mb, iter_time: 1.117s, data_time: 0.008s, total_loss: 5.3, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.3, lr: 1.197e-03, size: 608, ETA: 2 days, 8:36:12\u001b[0m\n",
            "\u001b[32m2021-10-22 03:16:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 630/777, mem: 9741Mb, iter_time: 0.968s, data_time: 0.006s, total_loss: 5.1, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.3, lr: 1.197e-03, size: 480, ETA: 2 days, 8:35:27\u001b[0m\n",
            "\u001b[32m2021-10-22 03:17:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 640/777, mem: 9741Mb, iter_time: 0.831s, data_time: 0.008s, total_loss: 4.5, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.7, cls_loss: 1.2, lr: 1.197e-03, size: 800, ETA: 2 days, 8:33:10\u001b[0m\n",
            "\u001b[32m2021-10-22 03:17:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 650/777, mem: 9741Mb, iter_time: 1.206s, data_time: 0.008s, total_loss: 5.6, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.5, cls_loss: 1.4, lr: 1.197e-03, size: 704, ETA: 2 days, 8:35:05\u001b[0m\n",
            "\u001b[32m2021-10-22 03:17:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 660/777, mem: 9741Mb, iter_time: 1.114s, data_time: 0.007s, total_loss: 6.1, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.9, cls_loss: 1.6, lr: 1.197e-03, size: 672, ETA: 2 days, 8:35:58\u001b[0m\n",
            "\u001b[32m2021-10-22 03:17:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 670/777, mem: 9741Mb, iter_time: 1.023s, data_time: 0.008s, total_loss: 5.5, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.3, lr: 1.197e-03, size: 448, ETA: 2 days, 8:35:51\u001b[0m\n",
            "\u001b[32m2021-10-22 03:17:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 680/777, mem: 9741Mb, iter_time: 0.802s, data_time: 0.007s, total_loss: 5.2, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.2, lr: 1.197e-03, size: 480, ETA: 2 days, 8:33:16\u001b[0m\n",
            "\u001b[32m2021-10-22 03:17:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 690/777, mem: 9741Mb, iter_time: 0.806s, data_time: 0.008s, total_loss: 5.1, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.2, lr: 1.197e-03, size: 704, ETA: 2 days, 8:30:44\u001b[0m\n",
            "\u001b[32m2021-10-22 03:18:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 700/777, mem: 9741Mb, iter_time: 0.984s, data_time: 0.010s, total_loss: 4.5, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.0, lr: 1.197e-03, size: 544, ETA: 2 days, 8:30:12\u001b[0m\n",
            "\u001b[32m2021-10-22 03:18:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 710/777, mem: 9741Mb, iter_time: 0.937s, data_time: 0.005s, total_loss: 5.3, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.4, lr: 1.197e-03, size: 736, ETA: 2 days, 8:29:08\u001b[0m\n",
            "\u001b[32m2021-10-22 03:18:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 720/777, mem: 9741Mb, iter_time: 1.099s, data_time: 0.011s, total_loss: 5.2, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.3, lr: 1.197e-03, size: 768, ETA: 2 days, 8:29:51\u001b[0m\n",
            "\u001b[32m2021-10-22 03:18:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 730/777, mem: 9741Mb, iter_time: 1.123s, data_time: 0.007s, total_loss: 5.7, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.5, cls_loss: 1.4, lr: 1.197e-03, size: 512, ETA: 2 days, 8:30:49\u001b[0m\n",
            "\u001b[32m2021-10-22 03:18:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 740/777, mem: 9741Mb, iter_time: 0.905s, data_time: 0.005s, total_loss: 4.5, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.1, lr: 1.197e-03, size: 704, ETA: 2 days, 8:29:25\u001b[0m\n",
            "\u001b[32m2021-10-22 03:18:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 750/777, mem: 9741Mb, iter_time: 1.031s, data_time: 0.008s, total_loss: 5.3, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.2, lr: 1.197e-03, size: 768, ETA: 2 days, 8:29:23\u001b[0m\n",
            "\u001b[32m2021-10-22 03:19:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 760/777, mem: 9741Mb, iter_time: 1.099s, data_time: 0.011s, total_loss: 5.4, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.4, lr: 1.197e-03, size: 448, ETA: 2 days, 8:30:05\u001b[0m\n",
            "\u001b[32m2021-10-22 03:19:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 43/300, iter: 770/777, mem: 9741Mb, iter_time: 0.885s, data_time: 0.007s, total_loss: 4.9, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.2, lr: 1.197e-03, size: 736, ETA: 2 days, 8:28:29\u001b[0m\n",
            "\u001b[32m2021-10-22 03:19:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mSave weights to /content/gdrive/MyDrive/Sprints/yolox_voc_s/yolox_voc_s/yolox_voc_s\u001b[0m\n",
            "100%|##########| 44/44 [00:14<00:00,  3.02it/s]\n",
            "\u001b[32m2021-10-22 03:19:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.evaluators.voc_evaluator\u001b[0m:\u001b[36m161\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
            "Writing beans VOC results file\n",
            "Writing cake VOC results file\n",
            "Writing candy VOC results file\n",
            "Writing cereal VOC results file\n",
            "Writing chips VOC results file\n",
            "Writing chocolate VOC results file\n",
            "Writing coffee VOC results file\n",
            "Writing corn VOC results file\n",
            "Writing fish VOC results file\n",
            "Writing flour VOC results file\n",
            "Writing honey VOC results file\n",
            "Writing jam VOC results file\n",
            "Writing juice VOC results file\n",
            "Writing milk VOC results file\n",
            "Writing nuts VOC results file\n",
            "Writing oil VOC results file\n",
            "Writing pasta VOC results file\n",
            "Writing rice VOC results file\n",
            "Writing soda VOC results file\n",
            "Writing spices VOC results file\n",
            "Writing sugar VOC results file\n",
            "Writing tea VOC results file\n",
            "Writing tomato_sauce VOC results file\n",
            "Writing vinegar VOC results file\n",
            "Writing water VOC results file\n",
            "Eval IoU : 0.50\n",
            "AP for beans = 0.9292\n",
            "AP for cake = 0.9216\n",
            "AP for candy = 0.7441\n",
            "AP for cereal = 0.9450\n",
            "AP for chips = 0.9205\n",
            "AP for chocolate = 0.9028\n",
            "AP for coffee = 0.9281\n",
            "AP for corn = 0.9504\n",
            "AP for fish = 0.8828\n",
            "AP for flour = 0.8988\n",
            "AP for honey = 0.9550\n",
            "AP for jam = 0.8976\n",
            "AP for juice = 0.8992\n",
            "AP for milk = 0.7227\n",
            "AP for nuts = 0.8834\n",
            "AP for oil = 0.8385\n",
            "AP for pasta = 0.8570\n",
            "AP for rice = 0.8828\n",
            "AP for soda = 0.8846\n",
            "AP for spices = 0.9063\n",
            "AP for sugar = 0.9063\n",
            "AP for tea = 0.8090\n",
            "AP for tomato_sauce = 0.9038\n",
            "AP for vinegar = 0.9758\n",
            "AP for water = 0.9254\n",
            "Mean AP = 0.8908\n",
            "~~~~~~~~\n",
            "Results:\n",
            "0.929\n",
            "0.922\n",
            "0.744\n",
            "0.945\n",
            "0.920\n",
            "0.903\n",
            "0.928\n",
            "0.950\n",
            "0.883\n",
            "0.899\n",
            "0.955\n",
            "0.898\n",
            "0.899\n",
            "0.723\n",
            "0.883\n",
            "0.839\n",
            "0.857\n",
            "0.883\n",
            "0.885\n",
            "0.906\n",
            "0.906\n",
            "0.809\n",
            "0.904\n",
            "0.976\n",
            "0.925\n",
            "0.891\n",
            "~~~~~~~~\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Results computed with the **unofficial** Python eval code.\n",
            "Results should be very close to the official MATLAB eval code.\n",
            "Recompute with `./tools/reval.py --matlab ...` for your paper.\n",
            "-- Thanks, The Management\n",
            "--------------------------------------------------------------\n",
            "Eval IoU : 0.55\n",
            "Eval IoU : 0.60\n",
            "Eval IoU : 0.65\n",
            "Eval IoU : 0.70\n",
            "Eval IoU : 0.75\n",
            "Eval IoU : 0.80\n",
            "Eval IoU : 0.85\n",
            "Eval IoU : 0.90\n",
            "Eval IoU : 0.95\n",
            "--------------------------------------------------------------\n",
            "map_5095: 0.6933476477532714\n",
            "map_50: 0.8908273311888444\n",
            "--------------------------------------------------------------\n",
            "\u001b[32m2021-10-22 03:19:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m314\u001b[0m - \u001b[1m\n",
            "Average forward time: 22.43 ms, Average NMS time: 6.04 ms, Average inference time: 28.47 ms\n",
            "\u001b[0m\n",
            "\u001b[32m2021-10-22 03:19:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mSave weights to /content/gdrive/MyDrive/Sprints/yolox_voc_s/yolox_voc_s/yolox_voc_s\u001b[0m\n",
            "\u001b[32m2021-10-22 03:19:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m193\u001b[0m - \u001b[1m---> start train epoch44\u001b[0m\n",
            "\u001b[32m2021-10-22 03:19:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 10/777, mem: 9741Mb, iter_time: 1.107s, data_time: 0.006s, total_loss: 5.9, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.6, cls_loss: 1.5, lr: 1.197e-03, size: 512, ETA: 2 days, 8:29:51\u001b[0m\n",
            "\u001b[32m2021-10-22 03:20:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 20/777, mem: 9741Mb, iter_time: 0.928s, data_time: 0.007s, total_loss: 4.4, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 0.9, lr: 1.197e-03, size: 480, ETA: 2 days, 8:28:43\u001b[0m\n",
            "\u001b[32m2021-10-22 03:20:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 30/777, mem: 9741Mb, iter_time: 0.749s, data_time: 0.010s, total_loss: 5.3, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.3, lr: 1.197e-03, size: 448, ETA: 2 days, 8:25:42\u001b[0m\n",
            "\u001b[32m2021-10-22 03:20:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 40/777, mem: 9741Mb, iter_time: 0.731s, data_time: 0.011s, total_loss: 4.7, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.3, lr: 1.197e-03, size: 480, ETA: 2 days, 8:22:30\u001b[0m\n",
            "\u001b[32m2021-10-22 03:20:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 50/777, mem: 9741Mb, iter_time: 0.744s, data_time: 0.009s, total_loss: 4.7, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.1, lr: 1.197e-03, size: 512, ETA: 2 days, 8:19:27\u001b[0m\n",
            "\u001b[32m2021-10-22 03:20:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 60/777, mem: 9741Mb, iter_time: 0.820s, data_time: 0.009s, total_loss: 3.9, iou_loss: 1.4, l1_loss: 0.0, conf_loss: 1.6, cls_loss: 0.8, lr: 1.197e-03, size: 832, ETA: 2 days, 8:17:14\u001b[0m\n",
            "\u001b[32m2021-10-22 03:20:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 70/777, mem: 9741Mb, iter_time: 1.112s, data_time: 0.009s, total_loss: 6.0, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.7, cls_loss: 1.5, lr: 1.197e-03, size: 704, ETA: 2 days, 8:18:05\u001b[0m\n",
            "\u001b[32m2021-10-22 03:20:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 80/777, mem: 9741Mb, iter_time: 1.248s, data_time: 0.007s, total_loss: 5.8, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.6, cls_loss: 1.3, lr: 1.197e-03, size: 544, ETA: 2 days, 8:20:20\u001b[0m\n",
            "\u001b[32m2021-10-22 03:21:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 90/777, mem: 9741Mb, iter_time: 0.934s, data_time: 0.007s, total_loss: 4.9, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.1, lr: 1.197e-03, size: 480, ETA: 2 days, 8:19:19\u001b[0m\n",
            "\u001b[32m2021-10-22 03:21:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 100/777, mem: 9741Mb, iter_time: 0.769s, data_time: 0.006s, total_loss: 5.0, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.3, lr: 1.196e-03, size: 448, ETA: 2 days, 8:16:35\u001b[0m\n",
            "\u001b[32m2021-10-22 03:21:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 110/777, mem: 9741Mb, iter_time: 0.732s, data_time: 0.008s, total_loss: 4.4, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.0, lr: 1.196e-03, size: 768, ETA: 2 days, 8:13:29\u001b[0m\n",
            "\u001b[32m2021-10-22 03:21:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 120/777, mem: 9741Mb, iter_time: 1.051s, data_time: 0.010s, total_loss: 5.3, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.3, lr: 1.196e-03, size: 576, ETA: 2 days, 8:13:42\u001b[0m\n",
            "\u001b[32m2021-10-22 03:21:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 130/777, mem: 9741Mb, iter_time: 1.041s, data_time: 0.005s, total_loss: 4.9, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.2, lr: 1.196e-03, size: 672, ETA: 2 days, 8:13:48\u001b[0m\n",
            "\u001b[32m2021-10-22 03:21:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 140/777, mem: 9741Mb, iter_time: 0.948s, data_time: 0.008s, total_loss: 5.7, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.5, lr: 1.196e-03, size: 448, ETA: 2 days, 8:12:57\u001b[0m\n",
            "\u001b[32m2021-10-22 03:22:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 150/777, mem: 9741Mb, iter_time: 0.874s, data_time: 0.004s, total_loss: 4.8, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.2, lr: 1.196e-03, size: 800, ETA: 2 days, 8:11:21\u001b[0m\n",
            "\u001b[32m2021-10-22 03:22:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 160/777, mem: 9741Mb, iter_time: 1.048s, data_time: 0.008s, total_loss: 5.4, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.6, cls_loss: 1.1, lr: 1.196e-03, size: 576, ETA: 2 days, 8:11:32\u001b[0m\n",
            "\u001b[32m2021-10-22 03:22:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 170/777, mem: 9741Mb, iter_time: 1.098s, data_time: 0.006s, total_loss: 4.4, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.0, lr: 1.196e-03, size: 768, ETA: 2 days, 8:12:13\u001b[0m\n",
            "\u001b[32m2021-10-22 03:22:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 180/777, mem: 9741Mb, iter_time: 1.036s, data_time: 0.007s, total_loss: 6.4, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 3.0, cls_loss: 1.8, lr: 1.196e-03, size: 544, ETA: 2 days, 8:12:16\u001b[0m\n",
            "\u001b[32m2021-10-22 03:22:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 190/777, mem: 9741Mb, iter_time: 1.018s, data_time: 0.007s, total_loss: 4.7, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 1.7, cls_loss: 1.2, lr: 1.196e-03, size: 448, ETA: 2 days, 8:12:08\u001b[0m\n",
            "\u001b[32m2021-10-22 03:22:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 200/777, mem: 9741Mb, iter_time: 0.752s, data_time: 0.005s, total_loss: 5.1, iou_loss: 2.0, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.0, lr: 1.196e-03, size: 512, ETA: 2 days, 8:09:19\u001b[0m\n",
            "\u001b[32m2021-10-22 03:22:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 210/777, mem: 9741Mb, iter_time: 0.770s, data_time: 0.010s, total_loss: 5.2, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.3, lr: 1.196e-03, size: 704, ETA: 2 days, 8:06:43\u001b[0m\n",
            "\u001b[32m2021-10-22 03:23:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 220/777, mem: 9741Mb, iter_time: 0.979s, data_time: 0.010s, total_loss: 6.1, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.7, cls_loss: 1.7, lr: 1.196e-03, size: 736, ETA: 2 days, 8:06:13\u001b[0m\n",
            "\u001b[32m2021-10-22 03:23:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 230/777, mem: 9741Mb, iter_time: 1.114s, data_time: 0.007s, total_loss: 5.0, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.2, lr: 1.196e-03, size: 736, ETA: 2 days, 8:07:03\u001b[0m\n",
            "\u001b[32m2021-10-22 03:23:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 240/777, mem: 9741Mb, iter_time: 1.131s, data_time: 0.007s, total_loss: 5.7, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.7, cls_loss: 1.4, lr: 1.196e-03, size: 512, ETA: 2 days, 8:08:04\u001b[0m\n",
            "\u001b[32m2021-10-22 03:23:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 250/777, mem: 9741Mb, iter_time: 0.948s, data_time: 0.004s, total_loss: 4.2, iou_loss: 1.4, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.0, lr: 1.196e-03, size: 832, ETA: 2 days, 8:07:14\u001b[0m\n",
            "\u001b[32m2021-10-22 03:23:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 260/777, mem: 9741Mb, iter_time: 1.159s, data_time: 0.008s, total_loss: 5.9, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.7, cls_loss: 1.4, lr: 1.196e-03, size: 448, ETA: 2 days, 8:08:30\u001b[0m\n",
            "\u001b[32m2021-10-22 03:24:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 270/777, mem: 9741Mb, iter_time: 1.062s, data_time: 0.003s, total_loss: 5.2, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.5, lr: 1.196e-03, size: 480, ETA: 2 days, 8:08:49\u001b[0m\n",
            "\u001b[32m2021-10-22 03:24:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 280/777, mem: 9741Mb, iter_time: 0.709s, data_time: 0.007s, total_loss: 5.2, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.4, lr: 1.196e-03, size: 768, ETA: 2 days, 8:05:40\u001b[0m\n",
            "\u001b[32m2021-10-22 03:24:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 290/777, mem: 9741Mb, iter_time: 1.039s, data_time: 0.010s, total_loss: 6.0, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.7, cls_loss: 1.4, lr: 1.196e-03, size: 480, ETA: 2 days, 8:05:45\u001b[0m\n",
            "\u001b[32m2021-10-22 03:24:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 300/777, mem: 9741Mb, iter_time: 0.983s, data_time: 0.004s, total_loss: 5.1, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.1, lr: 1.196e-03, size: 672, ETA: 2 days, 8:05:17\u001b[0m\n",
            "\u001b[32m2021-10-22 03:24:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 310/777, mem: 9741Mb, iter_time: 0.943s, data_time: 0.007s, total_loss: 5.8, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.9, cls_loss: 1.1, lr: 1.196e-03, size: 704, ETA: 2 days, 8:04:27\u001b[0m\n",
            "\u001b[32m2021-10-22 03:24:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 320/777, mem: 9741Mb, iter_time: 1.077s, data_time: 0.007s, total_loss: 4.9, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.2, lr: 1.196e-03, size: 512, ETA: 2 days, 8:04:54\u001b[0m\n",
            "\u001b[32m2021-10-22 03:24:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 330/777, mem: 9741Mb, iter_time: 0.903s, data_time: 0.007s, total_loss: 4.9, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.3, lr: 1.196e-03, size: 608, ETA: 2 days, 8:03:40\u001b[0m\n",
            "\u001b[32m2021-10-22 03:25:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 340/777, mem: 9741Mb, iter_time: 0.848s, data_time: 0.008s, total_loss: 4.6, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.1, lr: 1.196e-03, size: 480, ETA: 2 days, 8:01:55\u001b[0m\n",
            "\u001b[32m2021-10-22 03:25:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 350/777, mem: 9741Mb, iter_time: 0.825s, data_time: 0.008s, total_loss: 4.5, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.0, lr: 1.196e-03, size: 704, ETA: 2 days, 7:59:57\u001b[0m\n",
            "\u001b[32m2021-10-22 03:25:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 360/777, mem: 9741Mb, iter_time: 0.965s, data_time: 0.008s, total_loss: 4.5, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.1, lr: 1.196e-03, size: 640, ETA: 2 days, 7:59:21\u001b[0m\n",
            "\u001b[32m2021-10-22 03:25:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 370/777, mem: 9741Mb, iter_time: 1.009s, data_time: 0.007s, total_loss: 4.6, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.0, lr: 1.196e-03, size: 512, ETA: 2 days, 7:59:09\u001b[0m\n",
            "\u001b[32m2021-10-22 03:25:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 380/777, mem: 9741Mb, iter_time: 0.867s, data_time: 0.007s, total_loss: 5.3, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.2, lr: 1.195e-03, size: 512, ETA: 2 days, 7:57:37\u001b[0m\n",
            "\u001b[32m2021-10-22 03:25:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 390/777, mem: 9741Mb, iter_time: 0.792s, data_time: 0.006s, total_loss: 4.6, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.0, lr: 1.195e-03, size: 736, ETA: 2 days, 7:55:22\u001b[0m\n",
            "\u001b[32m2021-10-22 03:26:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 400/777, mem: 9741Mb, iter_time: 1.012s, data_time: 0.011s, total_loss: 4.8, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.2, lr: 1.195e-03, size: 608, ETA: 2 days, 7:55:13\u001b[0m\n",
            "\u001b[32m2021-10-22 03:26:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 410/777, mem: 9741Mb, iter_time: 1.048s, data_time: 0.007s, total_loss: 4.9, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.1, lr: 1.195e-03, size: 544, ETA: 2 days, 7:55:25\u001b[0m\n",
            "\u001b[32m2021-10-22 03:26:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 420/777, mem: 9741Mb, iter_time: 0.876s, data_time: 0.006s, total_loss: 5.4, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.3, lr: 1.195e-03, size: 800, ETA: 2 days, 7:53:59\u001b[0m\n",
            "\u001b[32m2021-10-22 03:26:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 430/777, mem: 9741Mb, iter_time: 1.112s, data_time: 0.014s, total_loss: 6.3, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 3.0, cls_loss: 1.5, lr: 1.195e-03, size: 736, ETA: 2 days, 7:54:46\u001b[0m\n",
            "\u001b[32m2021-10-22 03:26:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 440/777, mem: 9741Mb, iter_time: 1.219s, data_time: 0.006s, total_loss: 4.9, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.2, lr: 1.195e-03, size: 800, ETA: 2 days, 7:56:33\u001b[0m\n",
            "\u001b[32m2021-10-22 03:26:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 450/777, mem: 9741Mb, iter_time: 1.198s, data_time: 0.008s, total_loss: 5.0, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.2, lr: 1.195e-03, size: 448, ETA: 2 days, 7:58:08\u001b[0m\n",
            "\u001b[32m2021-10-22 03:27:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 460/777, mem: 9741Mb, iter_time: 1.035s, data_time: 0.003s, total_loss: 5.2, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.2, lr: 1.195e-03, size: 608, ETA: 2 days, 7:58:11\u001b[0m\n",
            "\u001b[32m2021-10-22 03:27:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 470/777, mem: 9741Mb, iter_time: 0.830s, data_time: 0.013s, total_loss: 5.4, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.2, lr: 1.195e-03, size: 448, ETA: 2 days, 7:56:20\u001b[0m\n",
            "\u001b[32m2021-10-22 03:27:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 480/777, mem: 9741Mb, iter_time: 0.836s, data_time: 0.007s, total_loss: 5.3, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.2, lr: 1.195e-03, size: 768, ETA: 2 days, 7:54:33\u001b[0m\n",
            "\u001b[32m2021-10-22 03:27:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 490/777, mem: 9741Mb, iter_time: 1.006s, data_time: 0.013s, total_loss: 4.9, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.2, lr: 1.195e-03, size: 768, ETA: 2 days, 7:54:20\u001b[0m\n",
            "\u001b[32m2021-10-22 03:27:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 500/777, mem: 9741Mb, iter_time: 1.200s, data_time: 0.008s, total_loss: 6.4, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 3.0, cls_loss: 1.8, lr: 1.195e-03, size: 640, ETA: 2 days, 7:55:55\u001b[0m\n",
            "\u001b[32m2021-10-22 03:27:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 510/777, mem: 9741Mb, iter_time: 1.053s, data_time: 0.008s, total_loss: 5.1, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.1, lr: 1.195e-03, size: 480, ETA: 2 days, 7:56:08\u001b[0m\n",
            "\u001b[32m2021-10-22 03:28:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 520/777, mem: 9741Mb, iter_time: 0.824s, data_time: 0.007s, total_loss: 4.6, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.2, lr: 1.195e-03, size: 832, ETA: 2 days, 7:54:15\u001b[0m\n",
            "\u001b[32m2021-10-22 03:28:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 530/777, mem: 9741Mb, iter_time: 1.140s, data_time: 0.009s, total_loss: 7.4, iou_loss: 2.0, l1_loss: 0.0, conf_loss: 3.6, cls_loss: 1.8, lr: 1.195e-03, size: 544, ETA: 2 days, 7:55:16\u001b[0m\n",
            "\u001b[32m2021-10-22 03:28:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 540/777, mem: 9741Mb, iter_time: 1.113s, data_time: 0.004s, total_loss: 4.6, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.0, lr: 1.195e-03, size: 672, ETA: 2 days, 7:56:02\u001b[0m\n",
            "\u001b[32m2021-10-22 03:28:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 550/777, mem: 9741Mb, iter_time: 0.951s, data_time: 0.009s, total_loss: 4.7, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.0, lr: 1.195e-03, size: 480, ETA: 2 days, 7:55:19\u001b[0m\n",
            "\u001b[32m2021-10-22 03:28:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 560/777, mem: 9741Mb, iter_time: 0.883s, data_time: 0.005s, total_loss: 4.9, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.0, lr: 1.195e-03, size: 544, ETA: 2 days, 7:53:59\u001b[0m\n",
            "\u001b[32m2021-10-22 03:28:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 570/777, mem: 9741Mb, iter_time: 0.799s, data_time: 0.011s, total_loss: 4.5, iou_loss: 1.4, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.1, lr: 1.195e-03, size: 512, ETA: 2 days, 7:51:55\u001b[0m\n",
            "\u001b[32m2021-10-22 03:29:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 580/777, mem: 9741Mb, iter_time: 0.775s, data_time: 0.009s, total_loss: 4.8, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.1, lr: 1.195e-03, size: 736, ETA: 2 days, 7:49:38\u001b[0m\n",
            "\u001b[32m2021-10-22 03:29:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 590/777, mem: 9741Mb, iter_time: 0.983s, data_time: 0.009s, total_loss: 5.0, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.3, lr: 1.195e-03, size: 576, ETA: 2 days, 7:49:13\u001b[0m\n",
            "\u001b[32m2021-10-22 03:29:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 600/777, mem: 9741Mb, iter_time: 1.001s, data_time: 0.008s, total_loss: 4.8, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.2, lr: 1.195e-03, size: 640, ETA: 2 days, 7:48:59\u001b[0m\n",
            "\u001b[32m2021-10-22 03:29:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 610/777, mem: 9741Mb, iter_time: 0.900s, data_time: 0.010s, total_loss: 4.6, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.2, lr: 1.195e-03, size: 640, ETA: 2 days, 7:47:50\u001b[0m\n",
            "\u001b[32m2021-10-22 03:29:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 620/777, mem: 9741Mb, iter_time: 0.948s, data_time: 0.010s, total_loss: 5.0, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.3, lr: 1.195e-03, size: 672, ETA: 2 days, 7:47:08\u001b[0m\n",
            "\u001b[32m2021-10-22 03:29:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 630/777, mem: 9741Mb, iter_time: 0.944s, data_time: 0.010s, total_loss: 5.0, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.2, lr: 1.195e-03, size: 448, ETA: 2 days, 7:46:23\u001b[0m\n",
            "\u001b[32m2021-10-22 03:29:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 640/777, mem: 9741Mb, iter_time: 0.850s, data_time: 0.003s, total_loss: 4.7, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.2, lr: 1.195e-03, size: 608, ETA: 2 days, 7:44:49\u001b[0m\n",
            "\u001b[32m2021-10-22 03:30:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 650/777, mem: 9741Mb, iter_time: 0.846s, data_time: 0.007s, total_loss: 5.4, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.2, lr: 1.195e-03, size: 704, ETA: 2 days, 7:43:13\u001b[0m\n",
            "\u001b[32m2021-10-22 03:30:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 660/777, mem: 9741Mb, iter_time: 1.004s, data_time: 0.014s, total_loss: 4.0, iou_loss: 1.4, l1_loss: 0.0, conf_loss: 1.6, cls_loss: 1.0, lr: 1.194e-03, size: 448, ETA: 2 days, 7:43:01\u001b[0m\n",
            "\u001b[32m2021-10-22 03:30:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 670/777, mem: 9741Mb, iter_time: 0.883s, data_time: 0.003s, total_loss: 5.2, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.2, lr: 1.194e-03, size: 736, ETA: 2 days, 7:41:45\u001b[0m\n",
            "\u001b[32m2021-10-22 03:30:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 680/777, mem: 9741Mb, iter_time: 0.949s, data_time: 0.011s, total_loss: 6.3, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.9, cls_loss: 1.8, lr: 1.194e-03, size: 640, ETA: 2 days, 7:41:04\u001b[0m\n",
            "\u001b[32m2021-10-22 03:30:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 690/777, mem: 9741Mb, iter_time: 1.044s, data_time: 0.004s, total_loss: 4.8, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.2, lr: 1.194e-03, size: 544, ETA: 2 days, 7:41:13\u001b[0m\n",
            "\u001b[32m2021-10-22 03:30:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 700/777, mem: 9741Mb, iter_time: 0.868s, data_time: 0.005s, total_loss: 4.9, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.0, lr: 1.194e-03, size: 768, ETA: 2 days, 7:39:50\u001b[0m\n",
            "\u001b[32m2021-10-22 03:31:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 710/777, mem: 9741Mb, iter_time: 1.078s, data_time: 0.013s, total_loss: 5.7, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.7, lr: 1.194e-03, size: 640, ETA: 2 days, 7:40:17\u001b[0m\n",
            "\u001b[32m2021-10-22 03:31:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 720/777, mem: 9741Mb, iter_time: 1.051s, data_time: 0.006s, total_loss: 4.4, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.0, lr: 1.194e-03, size: 544, ETA: 2 days, 7:40:30\u001b[0m\n",
            "\u001b[32m2021-10-22 03:31:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 730/777, mem: 9741Mb, iter_time: 0.883s, data_time: 0.006s, total_loss: 6.1, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.6, cls_loss: 1.7, lr: 1.194e-03, size: 768, ETA: 2 days, 7:39:16\u001b[0m\n",
            "\u001b[32m2021-10-22 03:31:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 740/777, mem: 9741Mb, iter_time: 1.017s, data_time: 0.010s, total_loss: 5.4, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.3, lr: 1.194e-03, size: 544, ETA: 2 days, 7:39:11\u001b[0m\n",
            "\u001b[32m2021-10-22 03:31:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 750/777, mem: 9741Mb, iter_time: 0.983s, data_time: 0.005s, total_loss: 4.3, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.0, lr: 1.194e-03, size: 608, ETA: 2 days, 7:38:49\u001b[0m\n",
            "\u001b[32m2021-10-22 03:31:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 760/777, mem: 9741Mb, iter_time: 0.882s, data_time: 0.006s, total_loss: 5.2, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.4, lr: 1.194e-03, size: 832, ETA: 2 days, 7:37:34\u001b[0m\n",
            "\u001b[32m2021-10-22 03:32:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 44/300, iter: 770/777, mem: 9741Mb, iter_time: 1.167s, data_time: 0.010s, total_loss: 7.0, iou_loss: 2.0, l1_loss: 0.0, conf_loss: 3.0, cls_loss: 2.0, lr: 1.194e-03, size: 736, ETA: 2 days, 7:38:46\u001b[0m\n",
            "\u001b[32m2021-10-22 03:32:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mSave weights to /content/gdrive/MyDrive/Sprints/yolox_voc_s/yolox_voc_s/yolox_voc_s\u001b[0m\n",
            "100%|##########| 44/44 [00:13<00:00,  3.16it/s]\n",
            "\u001b[32m2021-10-22 03:32:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.evaluators.voc_evaluator\u001b[0m:\u001b[36m161\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
            "Writing beans VOC results file\n",
            "Writing cake VOC results file\n",
            "Writing candy VOC results file\n",
            "Writing cereal VOC results file\n",
            "Writing chips VOC results file\n",
            "Writing chocolate VOC results file\n",
            "Writing coffee VOC results file\n",
            "Writing corn VOC results file\n",
            "Writing fish VOC results file\n",
            "Writing flour VOC results file\n",
            "Writing honey VOC results file\n",
            "Writing jam VOC results file\n",
            "Writing juice VOC results file\n",
            "Writing milk VOC results file\n",
            "Writing nuts VOC results file\n",
            "Writing oil VOC results file\n",
            "Writing pasta VOC results file\n",
            "Writing rice VOC results file\n",
            "Writing soda VOC results file\n",
            "Writing spices VOC results file\n",
            "Writing sugar VOC results file\n",
            "Writing tea VOC results file\n",
            "Writing tomato_sauce VOC results file\n",
            "Writing vinegar VOC results file\n",
            "Writing water VOC results file\n",
            "Eval IoU : 0.50\n",
            "AP for beans = 0.9210\n",
            "AP for cake = 0.9140\n",
            "AP for candy = 0.7616\n",
            "AP for cereal = 0.9430\n",
            "AP for chips = 0.9173\n",
            "AP for chocolate = 0.9019\n",
            "AP for coffee = 0.9384\n",
            "AP for corn = 0.9504\n",
            "AP for fish = 0.8853\n",
            "AP for flour = 0.8384\n",
            "AP for honey = 0.9547\n",
            "AP for jam = 0.8976\n",
            "AP for juice = 0.9454\n",
            "AP for milk = 0.7227\n",
            "AP for nuts = 0.8812\n",
            "AP for oil = 0.8278\n",
            "AP for pasta = 0.8487\n",
            "AP for rice = 0.8733\n",
            "AP for soda = 0.8814\n",
            "AP for spices = 0.9076\n",
            "AP for sugar = 0.8923\n",
            "AP for tea = 0.8089\n",
            "AP for tomato_sauce = 0.8797\n",
            "AP for vinegar = 0.9739\n",
            "AP for water = 0.9277\n",
            "Mean AP = 0.8878\n",
            "~~~~~~~~\n",
            "Results:\n",
            "0.921\n",
            "0.914\n",
            "0.762\n",
            "0.943\n",
            "0.917\n",
            "0.902\n",
            "0.938\n",
            "0.950\n",
            "0.885\n",
            "0.838\n",
            "0.955\n",
            "0.898\n",
            "0.945\n",
            "0.723\n",
            "0.881\n",
            "0.828\n",
            "0.849\n",
            "0.873\n",
            "0.881\n",
            "0.908\n",
            "0.892\n",
            "0.809\n",
            "0.880\n",
            "0.974\n",
            "0.928\n",
            "0.888\n",
            "~~~~~~~~\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Results computed with the **unofficial** Python eval code.\n",
            "Results should be very close to the official MATLAB eval code.\n",
            "Recompute with `./tools/reval.py --matlab ...` for your paper.\n",
            "-- Thanks, The Management\n",
            "--------------------------------------------------------------\n",
            "Eval IoU : 0.55\n",
            "Eval IoU : 0.60\n",
            "Eval IoU : 0.65\n",
            "Eval IoU : 0.70\n",
            "Eval IoU : 0.75\n",
            "Eval IoU : 0.80\n",
            "Eval IoU : 0.85\n",
            "Eval IoU : 0.90\n",
            "Eval IoU : 0.95\n",
            "--------------------------------------------------------------\n",
            "map_5095: 0.6911118583209526\n",
            "map_50: 0.8877666062107804\n",
            "--------------------------------------------------------------\n",
            "\u001b[32m2021-10-22 03:32:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m314\u001b[0m - \u001b[1m\n",
            "Average forward time: 22.70 ms, Average NMS time: 5.52 ms, Average inference time: 28.23 ms\n",
            "\u001b[0m\n",
            "\u001b[32m2021-10-22 03:32:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mSave weights to /content/gdrive/MyDrive/Sprints/yolox_voc_s/yolox_voc_s/yolox_voc_s\u001b[0m\n",
            "\u001b[32m2021-10-22 03:32:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m193\u001b[0m - \u001b[1m---> start train epoch45\u001b[0m\n",
            "\u001b[32m2021-10-22 03:32:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 10/777, mem: 9741Mb, iter_time: 1.093s, data_time: 0.006s, total_loss: 4.9, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.2, lr: 1.194e-03, size: 608, ETA: 2 days, 7:40:45\u001b[0m\n",
            "\u001b[32m2021-10-22 03:32:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 20/777, mem: 9741Mb, iter_time: 0.884s, data_time: 0.007s, total_loss: 5.0, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.2, lr: 1.194e-03, size: 448, ETA: 2 days, 7:39:32\u001b[0m\n",
            "\u001b[32m2021-10-22 03:33:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 30/777, mem: 9741Mb, iter_time: 0.847s, data_time: 0.008s, total_loss: 5.3, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.5, lr: 1.194e-03, size: 736, ETA: 2 days, 7:38:00\u001b[0m\n",
            "\u001b[32m2021-10-22 03:33:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 40/777, mem: 9741Mb, iter_time: 1.109s, data_time: 0.009s, total_loss: 4.6, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.2, lr: 1.194e-03, size: 576, ETA: 2 days, 7:38:42\u001b[0m\n",
            "\u001b[32m2021-10-22 03:33:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 50/777, mem: 9741Mb, iter_time: 0.960s, data_time: 0.006s, total_loss: 4.5, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 1.7, cls_loss: 1.0, lr: 1.194e-03, size: 736, ETA: 2 days, 7:38:08\u001b[0m\n",
            "\u001b[32m2021-10-22 03:33:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 60/777, mem: 9741Mb, iter_time: 1.112s, data_time: 0.009s, total_loss: 4.8, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.1, lr: 1.194e-03, size: 672, ETA: 2 days, 7:38:50\u001b[0m\n",
            "\u001b[32m2021-10-22 03:33:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 70/777, mem: 9741Mb, iter_time: 1.020s, data_time: 0.007s, total_loss: 4.8, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.1, lr: 1.194e-03, size: 640, ETA: 2 days, 7:38:47\u001b[0m\n",
            "\u001b[32m2021-10-22 03:33:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 80/777, mem: 9741Mb, iter_time: 1.020s, data_time: 0.009s, total_loss: 5.0, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.2, lr: 1.194e-03, size: 768, ETA: 2 days, 7:38:43\u001b[0m\n",
            "\u001b[32m2021-10-22 03:34:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 90/777, mem: 9741Mb, iter_time: 1.141s, data_time: 0.006s, total_loss: 5.6, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.4, lr: 1.194e-03, size: 608, ETA: 2 days, 7:39:40\u001b[0m\n",
            "\u001b[32m2021-10-22 03:34:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 100/777, mem: 9741Mb, iter_time: 0.902s, data_time: 0.006s, total_loss: 5.0, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.2, lr: 1.194e-03, size: 576, ETA: 2 days, 7:38:37\u001b[0m\n",
            "\u001b[32m2021-10-22 03:34:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 110/777, mem: 9741Mb, iter_time: 0.994s, data_time: 0.008s, total_loss: 4.9, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.2, lr: 1.194e-03, size: 832, ETA: 2 days, 7:38:20\u001b[0m\n",
            "\u001b[32m2021-10-22 03:34:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 120/777, mem: 9741Mb, iter_time: 1.303s, data_time: 0.008s, total_loss: 5.4, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.5, lr: 1.194e-03, size: 736, ETA: 2 days, 7:40:36\u001b[0m\n",
            "\u001b[32m2021-10-22 03:34:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 130/777, mem: 9741Mb, iter_time: 1.097s, data_time: 0.006s, total_loss: 4.4, iou_loss: 1.4, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.2, lr: 1.194e-03, size: 672, ETA: 2 days, 7:41:10\u001b[0m\n",
            "\u001b[32m2021-10-22 03:34:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 140/777, mem: 9741Mb, iter_time: 0.952s, data_time: 0.007s, total_loss: 6.0, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 2.8, cls_loss: 1.7, lr: 1.194e-03, size: 480, ETA: 2 days, 7:40:32\u001b[0m\n",
            "\u001b[32m2021-10-22 03:35:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 150/777, mem: 9741Mb, iter_time: 0.808s, data_time: 0.010s, total_loss: 5.1, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.2, lr: 1.194e-03, size: 576, ETA: 2 days, 7:38:43\u001b[0m\n",
            "\u001b[32m2021-10-22 03:35:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 160/777, mem: 9741Mb, iter_time: 0.863s, data_time: 0.007s, total_loss: 5.4, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.3, lr: 1.193e-03, size: 576, ETA: 2 days, 7:37:22\u001b[0m\n",
            "\u001b[32m2021-10-22 03:35:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 170/777, mem: 9741Mb, iter_time: 0.853s, data_time: 0.008s, total_loss: 4.9, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.1, lr: 1.193e-03, size: 608, ETA: 2 days, 7:35:56\u001b[0m\n",
            "\u001b[32m2021-10-22 03:35:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 180/777, mem: 9741Mb, iter_time: 0.908s, data_time: 0.007s, total_loss: 5.1, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.1, lr: 1.193e-03, size: 544, ETA: 2 days, 7:34:58\u001b[0m\n",
            "\u001b[32m2021-10-22 03:35:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 190/777, mem: 9741Mb, iter_time: 0.910s, data_time: 0.008s, total_loss: 5.7, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.7, cls_loss: 1.2, lr: 1.193e-03, size: 704, ETA: 2 days, 7:34:01\u001b[0m\n",
            "\u001b[32m2021-10-22 03:35:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 200/777, mem: 9741Mb, iter_time: 1.157s, data_time: 0.010s, total_loss: 4.9, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.2, lr: 1.193e-03, size: 832, ETA: 2 days, 7:35:04\u001b[0m\n",
            "\u001b[32m2021-10-22 03:36:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 210/777, mem: 9741Mb, iter_time: 1.220s, data_time: 0.006s, total_loss: 5.1, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.2, lr: 1.193e-03, size: 512, ETA: 2 days, 7:36:37\u001b[0m\n",
            "\u001b[32m2021-10-22 03:36:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 220/777, mem: 9741Mb, iter_time: 0.883s, data_time: 0.007s, total_loss: 5.1, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.3, lr: 1.193e-03, size: 736, ETA: 2 days, 7:35:26\u001b[0m\n",
            "\u001b[32m2021-10-22 03:36:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 230/777, mem: 9741Mb, iter_time: 1.175s, data_time: 0.008s, total_loss: 4.8, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.2, lr: 1.193e-03, size: 800, ETA: 2 days, 7:36:37\u001b[0m\n",
            "\u001b[32m2021-10-22 03:36:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 240/777, mem: 9741Mb, iter_time: 1.246s, data_time: 0.007s, total_loss: 5.8, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.4, lr: 1.193e-03, size: 768, ETA: 2 days, 7:38:22\u001b[0m\n",
            "\u001b[32m2021-10-22 03:36:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 250/777, mem: 9741Mb, iter_time: 1.193s, data_time: 0.007s, total_loss: 6.1, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.8, cls_loss: 1.6, lr: 1.193e-03, size: 800, ETA: 2 days, 7:39:41\u001b[0m\n",
            "\u001b[32m2021-10-22 03:37:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 260/777, mem: 9741Mb, iter_time: 1.192s, data_time: 0.005s, total_loss: 4.5, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.0, lr: 1.193e-03, size: 608, ETA: 2 days, 7:40:59\u001b[0m\n",
            "\u001b[32m2021-10-22 03:37:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 270/777, mem: 9741Mb, iter_time: 1.009s, data_time: 0.006s, total_loss: 5.1, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.4, lr: 1.193e-03, size: 800, ETA: 2 days, 7:40:49\u001b[0m\n",
            "\u001b[32m2021-10-22 03:37:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 280/777, mem: 9741Mb, iter_time: 1.171s, data_time: 0.003s, total_loss: 5.4, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.4, lr: 1.193e-03, size: 512, ETA: 2 days, 7:41:56\u001b[0m\n",
            "\u001b[32m2021-10-22 03:37:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 290/777, mem: 9741Mb, iter_time: 0.811s, data_time: 0.006s, total_loss: 5.0, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.2, lr: 1.193e-03, size: 608, ETA: 2 days, 7:40:11\u001b[0m\n",
            "\u001b[32m2021-10-22 03:37:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 300/777, mem: 9741Mb, iter_time: 0.902s, data_time: 0.011s, total_loss: 4.4, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.0, lr: 1.193e-03, size: 544, ETA: 2 days, 7:39:10\u001b[0m\n",
            "\u001b[32m2021-10-22 03:37:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 310/777, mem: 9741Mb, iter_time: 0.825s, data_time: 0.006s, total_loss: 4.4, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 0.9, lr: 1.193e-03, size: 480, ETA: 2 days, 7:37:33\u001b[0m\n",
            "\u001b[32m2021-10-22 03:37:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 320/777, mem: 9741Mb, iter_time: 0.788s, data_time: 0.008s, total_loss: 4.4, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.1, lr: 1.193e-03, size: 576, ETA: 2 days, 7:35:39\u001b[0m\n",
            "\u001b[32m2021-10-22 03:38:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 330/777, mem: 9741Mb, iter_time: 0.964s, data_time: 0.015s, total_loss: 4.9, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.2, lr: 1.193e-03, size: 736, ETA: 2 days, 7:35:08\u001b[0m\n",
            "\u001b[32m2021-10-22 03:38:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 340/777, mem: 9741Mb, iter_time: 1.185s, data_time: 0.011s, total_loss: 4.9, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.2, lr: 1.193e-03, size: 832, ETA: 2 days, 7:36:22\u001b[0m\n",
            "\u001b[32m2021-10-22 03:38:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 350/777, mem: 9741Mb, iter_time: 1.339s, data_time: 0.008s, total_loss: 5.1, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.1, lr: 1.193e-03, size: 800, ETA: 2 days, 7:38:47\u001b[0m\n",
            "\u001b[32m2021-10-22 03:38:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 360/777, mem: 9741Mb, iter_time: 1.253s, data_time: 0.007s, total_loss: 6.8, iou_loss: 2.0, l1_loss: 0.0, conf_loss: 2.9, cls_loss: 1.8, lr: 1.193e-03, size: 704, ETA: 2 days, 7:40:31\u001b[0m\n",
            "\u001b[32m2021-10-22 03:38:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 370/777, mem: 9741Mb, iter_time: 0.995s, data_time: 0.006s, total_loss: 6.6, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.9, cls_loss: 1.7, lr: 1.193e-03, size: 448, ETA: 2 days, 7:40:14\u001b[0m\n",
            "\u001b[32m2021-10-22 03:39:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 380/777, mem: 9741Mb, iter_time: 0.699s, data_time: 0.011s, total_loss: 4.4, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.0, lr: 1.193e-03, size: 448, ETA: 2 days, 7:37:39\u001b[0m\n",
            "\u001b[32m2021-10-22 03:39:09\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 390/777, mem: 9741Mb, iter_time: 0.728s, data_time: 0.009s, total_loss: 4.6, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.2, lr: 1.193e-03, size: 480, ETA: 2 days, 7:35:19\u001b[0m\n",
            "\u001b[32m2021-10-22 03:39:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 400/777, mem: 9741Mb, iter_time: 0.763s, data_time: 0.010s, total_loss: 5.1, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.2, lr: 1.193e-03, size: 544, ETA: 2 days, 7:33:15\u001b[0m\n",
            "\u001b[32m2021-10-22 03:39:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 410/777, mem: 9741Mb, iter_time: 0.862s, data_time: 0.008s, total_loss: 4.7, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.1, lr: 1.193e-03, size: 672, ETA: 2 days, 7:31:58\u001b[0m\n",
            "\u001b[32m2021-10-22 03:39:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 420/777, mem: 9741Mb, iter_time: 0.973s, data_time: 0.006s, total_loss: 5.5, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.3, lr: 1.193e-03, size: 448, ETA: 2 days, 7:31:32\u001b[0m\n",
            "\u001b[32m2021-10-22 03:39:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 430/777, mem: 9741Mb, iter_time: 0.875s, data_time: 0.006s, total_loss: 5.1, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.1, lr: 1.192e-03, size: 736, ETA: 2 days, 7:30:21\u001b[0m\n",
            "\u001b[32m2021-10-22 03:39:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 440/777, mem: 9741Mb, iter_time: 1.122s, data_time: 0.008s, total_loss: 4.8, iou_loss: 1.4, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.3, lr: 1.192e-03, size: 704, ETA: 2 days, 7:31:04\u001b[0m\n",
            "\u001b[32m2021-10-22 03:40:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 450/777, mem: 9741Mb, iter_time: 1.121s, data_time: 0.011s, total_loss: 4.8, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.1, lr: 1.192e-03, size: 832, ETA: 2 days, 7:31:46\u001b[0m\n",
            "\u001b[32m2021-10-22 03:40:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 460/777, mem: 9741Mb, iter_time: 1.217s, data_time: 0.004s, total_loss: 5.9, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.5, cls_loss: 1.6, lr: 1.192e-03, size: 480, ETA: 2 days, 7:33:12\u001b[0m\n",
            "\u001b[32m2021-10-22 03:40:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 470/777, mem: 9741Mb, iter_time: 0.886s, data_time: 0.007s, total_loss: 4.4, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.0, lr: 1.192e-03, size: 736, ETA: 2 days, 7:32:06\u001b[0m\n",
            "\u001b[32m2021-10-22 03:40:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 480/777, mem: 9741Mb, iter_time: 1.088s, data_time: 0.007s, total_loss: 5.5, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.6, lr: 1.192e-03, size: 576, ETA: 2 days, 7:32:32\u001b[0m\n",
            "\u001b[32m2021-10-22 03:40:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 490/777, mem: 9741Mb, iter_time: 0.931s, data_time: 0.010s, total_loss: 5.0, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.3, lr: 1.192e-03, size: 704, ETA: 2 days, 7:31:48\u001b[0m\n",
            "\u001b[32m2021-10-22 03:40:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 500/777, mem: 9741Mb, iter_time: 1.104s, data_time: 0.010s, total_loss: 5.2, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.3, lr: 1.192e-03, size: 800, ETA: 2 days, 7:32:21\u001b[0m\n",
            "\u001b[32m2021-10-22 03:41:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 510/777, mem: 9741Mb, iter_time: 1.208s, data_time: 0.003s, total_loss: 6.4, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.7, cls_loss: 1.9, lr: 1.192e-03, size: 608, ETA: 2 days, 7:33:41\u001b[0m\n",
            "\u001b[32m2021-10-22 03:41:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 520/777, mem: 9741Mb, iter_time: 0.987s, data_time: 0.008s, total_loss: 4.8, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.0, lr: 1.192e-03, size: 768, ETA: 2 days, 7:33:21\u001b[0m\n",
            "\u001b[32m2021-10-22 03:41:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 530/777, mem: 9741Mb, iter_time: 1.072s, data_time: 0.007s, total_loss: 4.8, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.2, lr: 1.192e-03, size: 480, ETA: 2 days, 7:33:40\u001b[0m\n",
            "\u001b[32m2021-10-22 03:41:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 540/777, mem: 9741Mb, iter_time: 0.804s, data_time: 0.006s, total_loss: 4.6, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 0.9, lr: 1.192e-03, size: 640, ETA: 2 days, 7:31:58\u001b[0m\n",
            "\u001b[32m2021-10-22 03:41:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 550/777, mem: 9741Mb, iter_time: 0.905s, data_time: 0.007s, total_loss: 4.9, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.0, lr: 1.192e-03, size: 480, ETA: 2 days, 7:31:02\u001b[0m\n",
            "\u001b[32m2021-10-22 03:41:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 560/777, mem: 9741Mb, iter_time: 0.735s, data_time: 0.007s, total_loss: 4.0, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 1.7, cls_loss: 0.8, lr: 1.192e-03, size: 448, ETA: 2 days, 7:28:51\u001b[0m\n",
            "\u001b[32m2021-10-22 03:42:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 570/777, mem: 9741Mb, iter_time: 0.848s, data_time: 0.011s, total_loss: 4.9, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.0, lr: 1.192e-03, size: 736, ETA: 2 days, 7:27:30\u001b[0m\n",
            "\u001b[32m2021-10-22 03:42:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 580/777, mem: 9741Mb, iter_time: 1.040s, data_time: 0.004s, total_loss: 5.5, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.5, cls_loss: 1.4, lr: 1.192e-03, size: 480, ETA: 2 days, 7:27:35\u001b[0m\n",
            "\u001b[32m2021-10-22 03:42:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 590/777, mem: 9741Mb, iter_time: 0.768s, data_time: 0.008s, total_loss: 4.7, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.1, lr: 1.192e-03, size: 576, ETA: 2 days, 7:25:39\u001b[0m\n",
            "\u001b[32m2021-10-22 03:42:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.handle\u001b[0m:\u001b[36m140\u001b[0m - \u001b[1mGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\u001b[0m\n",
            "\u001b[32m2021-10-22 03:42:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 600/777, mem: 9741Mb, iter_time: 0.924s, data_time: 0.008s, total_loss: 4.9, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.2, lr: 1.192e-03, size: 736, ETA: 2 days, 7:24:53\u001b[0m\n",
            "\u001b[32m2021-10-22 03:42:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 610/777, mem: 9741Mb, iter_time: 1.101s, data_time: 0.006s, total_loss: 4.5, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.1, lr: 1.192e-03, size: 672, ETA: 2 days, 7:25:25\u001b[0m\n",
            "\u001b[32m2021-10-22 03:42:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 620/777, mem: 9741Mb, iter_time: 0.974s, data_time: 0.006s, total_loss: 5.3, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.2, lr: 1.192e-03, size: 544, ETA: 2 days, 7:25:00\u001b[0m\n",
            "\u001b[32m2021-10-22 03:43:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 630/777, mem: 9741Mb, iter_time: 0.858s, data_time: 0.008s, total_loss: 5.0, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.3, lr: 1.192e-03, size: 640, ETA: 2 days, 7:23:45\u001b[0m\n",
            "\u001b[32m2021-10-22 03:43:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 640/777, mem: 9741Mb, iter_time: 1.000s, data_time: 0.009s, total_loss: 4.9, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.2, lr: 1.192e-03, size: 768, ETA: 2 days, 7:23:33\u001b[0m\n",
            "\u001b[32m2021-10-22 03:43:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 650/777, mem: 9741Mb, iter_time: 1.070s, data_time: 0.006s, total_loss: 4.6, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.1, lr: 1.192e-03, size: 512, ETA: 2 days, 7:23:51\u001b[0m\n",
            "\u001b[32m2021-10-22 03:43:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 660/777, mem: 9741Mb, iter_time: 0.915s, data_time: 0.008s, total_loss: 4.7, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.3, lr: 1.192e-03, size: 832, ETA: 2 days, 7:23:01\u001b[0m\n",
            "\u001b[32m2021-10-22 03:43:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 670/777, mem: 9741Mb, iter_time: 1.321s, data_time: 0.010s, total_loss: 5.7, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.5, cls_loss: 1.6, lr: 1.192e-03, size: 768, ETA: 2 days, 7:25:08\u001b[0m\n",
            "\u001b[32m2021-10-22 03:43:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 680/777, mem: 9741Mb, iter_time: 1.082s, data_time: 0.008s, total_loss: 4.8, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.1, lr: 1.192e-03, size: 608, ETA: 2 days, 7:25:31\u001b[0m\n",
            "\u001b[32m2021-10-22 03:44:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 690/777, mem: 9741Mb, iter_time: 0.852s, data_time: 0.006s, total_loss: 4.7, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.4, lr: 1.192e-03, size: 448, ETA: 2 days, 7:24:14\u001b[0m\n",
            "\u001b[32m2021-10-22 03:44:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 700/777, mem: 9741Mb, iter_time: 0.735s, data_time: 0.007s, total_loss: 5.1, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.3, lr: 1.191e-03, size: 544, ETA: 2 days, 7:22:06\u001b[0m\n",
            "\u001b[32m2021-10-22 03:44:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 710/777, mem: 9741Mb, iter_time: 0.751s, data_time: 0.007s, total_loss: 5.2, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.4, lr: 1.191e-03, size: 448, ETA: 2 days, 7:20:06\u001b[0m\n",
            "\u001b[32m2021-10-22 03:44:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 720/777, mem: 9741Mb, iter_time: 0.800s, data_time: 0.008s, total_loss: 5.0, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.4, lr: 1.191e-03, size: 704, ETA: 2 days, 7:18:28\u001b[0m\n",
            "\u001b[32m2021-10-22 03:44:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 730/777, mem: 9741Mb, iter_time: 1.061s, data_time: 0.007s, total_loss: 6.1, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.5, cls_loss: 1.9, lr: 1.191e-03, size: 608, ETA: 2 days, 7:18:42\u001b[0m\n",
            "\u001b[32m2021-10-22 03:44:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 740/777, mem: 9741Mb, iter_time: 1.018s, data_time: 0.011s, total_loss: 4.5, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.1, lr: 1.191e-03, size: 800, ETA: 2 days, 7:18:38\u001b[0m\n",
            "\u001b[32m2021-10-22 03:45:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 750/777, mem: 9741Mb, iter_time: 1.249s, data_time: 0.008s, total_loss: 6.6, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 3.1, cls_loss: 1.6, lr: 1.191e-03, size: 800, ETA: 2 days, 7:20:13\u001b[0m\n",
            "\u001b[32m2021-10-22 03:45:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 760/777, mem: 9741Mb, iter_time: 1.151s, data_time: 0.004s, total_loss: 4.5, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 0.9, lr: 1.191e-03, size: 512, ETA: 2 days, 7:21:05\u001b[0m\n",
            "\u001b[32m2021-10-22 03:45:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 45/300, iter: 770/777, mem: 9741Mb, iter_time: 0.759s, data_time: 0.007s, total_loss: 4.9, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.2, lr: 1.191e-03, size: 448, ETA: 2 days, 7:19:10\u001b[0m\n",
            "\u001b[32m2021-10-22 03:45:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mSave weights to /content/gdrive/MyDrive/Sprints/yolox_voc_s/yolox_voc_s/yolox_voc_s\u001b[0m\n",
            "100%|##########| 44/44 [00:13<00:00,  3.20it/s]\n",
            "\u001b[32m2021-10-22 03:45:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.evaluators.voc_evaluator\u001b[0m:\u001b[36m161\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
            "Writing beans VOC results file\n",
            "Writing cake VOC results file\n",
            "Writing candy VOC results file\n",
            "Writing cereal VOC results file\n",
            "Writing chips VOC results file\n",
            "Writing chocolate VOC results file\n",
            "Writing coffee VOC results file\n",
            "Writing corn VOC results file\n",
            "Writing fish VOC results file\n",
            "Writing flour VOC results file\n",
            "Writing honey VOC results file\n",
            "Writing jam VOC results file\n",
            "Writing juice VOC results file\n",
            "Writing milk VOC results file\n",
            "Writing nuts VOC results file\n",
            "Writing oil VOC results file\n",
            "Writing pasta VOC results file\n",
            "Writing rice VOC results file\n",
            "Writing soda VOC results file\n",
            "Writing spices VOC results file\n",
            "Writing sugar VOC results file\n",
            "Writing tea VOC results file\n",
            "Writing tomato_sauce VOC results file\n",
            "Writing vinegar VOC results file\n",
            "Writing water VOC results file\n",
            "Eval IoU : 0.50\n",
            "AP for beans = 0.9295\n",
            "AP for cake = 0.9077\n",
            "AP for candy = 0.7642\n",
            "AP for cereal = 0.9412\n",
            "AP for chips = 0.9141\n",
            "AP for chocolate = 0.9030\n",
            "AP for coffee = 0.9341\n",
            "AP for corn = 0.9504\n",
            "AP for fish = 0.8828\n",
            "AP for flour = 0.8294\n",
            "AP for honey = 0.9513\n",
            "AP for jam = 0.8976\n",
            "AP for juice = 0.9409\n",
            "AP for milk = 0.7227\n",
            "AP for nuts = 0.8879\n",
            "AP for oil = 0.8343\n",
            "AP for pasta = 0.8409\n",
            "AP for rice = 0.8688\n",
            "AP for soda = 0.8840\n",
            "AP for spices = 0.9076\n",
            "AP for sugar = 0.8849\n",
            "AP for tea = 0.8076\n",
            "AP for tomato_sauce = 0.8833\n",
            "AP for vinegar = 0.9753\n",
            "AP for water = 0.9269\n",
            "Mean AP = 0.8868\n",
            "~~~~~~~~\n",
            "Results:\n",
            "0.929\n",
            "0.908\n",
            "0.764\n",
            "0.941\n",
            "0.914\n",
            "0.903\n",
            "0.934\n",
            "0.950\n",
            "0.883\n",
            "0.829\n",
            "0.951\n",
            "0.898\n",
            "0.941\n",
            "0.723\n",
            "0.888\n",
            "0.834\n",
            "0.841\n",
            "0.869\n",
            "0.884\n",
            "0.908\n",
            "0.885\n",
            "0.808\n",
            "0.883\n",
            "0.975\n",
            "0.927\n",
            "0.887\n",
            "~~~~~~~~\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Results computed with the **unofficial** Python eval code.\n",
            "Results should be very close to the official MATLAB eval code.\n",
            "Recompute with `./tools/reval.py --matlab ...` for your paper.\n",
            "-- Thanks, The Management\n",
            "--------------------------------------------------------------\n",
            "Eval IoU : 0.55\n",
            "Eval IoU : 0.60\n",
            "Eval IoU : 0.65\n",
            "Eval IoU : 0.70\n",
            "Eval IoU : 0.75\n",
            "Eval IoU : 0.80\n",
            "Eval IoU : 0.85\n",
            "Eval IoU : 0.90\n",
            "Eval IoU : 0.95\n",
            "--------------------------------------------------------------\n",
            "map_5095: 0.688334417042386\n",
            "map_50: 0.88681784061384\n",
            "--------------------------------------------------------------\n",
            "\u001b[32m2021-10-22 03:45:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m314\u001b[0m - \u001b[1m\n",
            "Average forward time: 22.63 ms, Average NMS time: 5.72 ms, Average inference time: 28.34 ms\n",
            "\u001b[0m\n",
            "\u001b[32m2021-10-22 03:45:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mSave weights to /content/gdrive/MyDrive/Sprints/yolox_voc_s/yolox_voc_s/yolox_voc_s\u001b[0m\n",
            "\u001b[32m2021-10-22 03:45:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m193\u001b[0m - \u001b[1m---> start train epoch46\u001b[0m\n",
            "\u001b[32m2021-10-22 03:45:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 10/777, mem: 9741Mb, iter_time: 0.792s, data_time: 0.009s, total_loss: 5.0, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.1, lr: 1.191e-03, size: 576, ETA: 2 days, 7:15:48\u001b[0m\n",
            "\u001b[32m2021-10-22 03:46:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 20/777, mem: 9741Mb, iter_time: 0.833s, data_time: 0.007s, total_loss: 5.0, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.2, lr: 1.191e-03, size: 704, ETA: 2 days, 7:14:26\u001b[0m\n",
            "\u001b[32m2021-10-22 03:46:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 30/777, mem: 9741Mb, iter_time: 0.995s, data_time: 0.007s, total_loss: 4.5, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.0, lr: 1.191e-03, size: 448, ETA: 2 days, 7:14:12\u001b[0m\n",
            "\u001b[32m2021-10-22 03:46:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 40/777, mem: 9741Mb, iter_time: 0.759s, data_time: 0.006s, total_loss: 5.8, iou_loss: 2.1, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.6, lr: 1.191e-03, size: 448, ETA: 2 days, 7:12:19\u001b[0m\n",
            "\u001b[32m2021-10-22 03:46:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 50/777, mem: 9741Mb, iter_time: 0.684s, data_time: 0.009s, total_loss: 4.5, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.0, lr: 1.191e-03, size: 480, ETA: 2 days, 7:09:54\u001b[0m\n",
            "\u001b[32m2021-10-22 03:46:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 60/777, mem: 9741Mb, iter_time: 0.736s, data_time: 0.008s, total_loss: 4.6, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.0, lr: 1.191e-03, size: 608, ETA: 2 days, 7:07:52\u001b[0m\n",
            "\u001b[32m2021-10-22 03:46:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 70/777, mem: 9741Mb, iter_time: 0.912s, data_time: 0.008s, total_loss: 5.4, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.3, lr: 1.191e-03, size: 800, ETA: 2 days, 7:07:05\u001b[0m\n",
            "\u001b[32m2021-10-22 03:46:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 80/777, mem: 9741Mb, iter_time: 1.226s, data_time: 0.006s, total_loss: 6.4, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.9, cls_loss: 1.8, lr: 1.191e-03, size: 736, ETA: 2 days, 7:08:28\u001b[0m\n",
            "\u001b[32m2021-10-22 03:47:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 90/777, mem: 9741Mb, iter_time: 1.144s, data_time: 0.008s, total_loss: 6.4, iou_loss: 2.0, l1_loss: 0.0, conf_loss: 2.9, cls_loss: 1.5, lr: 1.191e-03, size: 704, ETA: 2 days, 7:09:17\u001b[0m\n",
            "\u001b[32m2021-10-22 03:47:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 100/777, mem: 9741Mb, iter_time: 1.039s, data_time: 0.006s, total_loss: 4.8, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.0, lr: 1.191e-03, size: 480, ETA: 2 days, 7:09:22\u001b[0m\n",
            "\u001b[32m2021-10-22 03:47:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 110/777, mem: 9741Mb, iter_time: 0.874s, data_time: 0.003s, total_loss: 5.7, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.6, cls_loss: 1.3, lr: 1.191e-03, size: 800, ETA: 2 days, 7:08:19\u001b[0m\n",
            "\u001b[32m2021-10-22 03:47:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 120/777, mem: 9741Mb, iter_time: 1.183s, data_time: 0.007s, total_loss: 6.1, iou_loss: 2.1, l1_loss: 0.0, conf_loss: 2.5, cls_loss: 1.5, lr: 1.191e-03, size: 576, ETA: 2 days, 7:09:24\u001b[0m\n",
            "\u001b[32m2021-10-22 03:47:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 130/777, mem: 9741Mb, iter_time: 0.957s, data_time: 0.006s, total_loss: 5.1, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.4, lr: 1.191e-03, size: 608, ETA: 2 days, 7:08:55\u001b[0m\n",
            "\u001b[32m2021-10-22 03:47:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 140/777, mem: 9741Mb, iter_time: 0.916s, data_time: 0.008s, total_loss: 5.0, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.4, lr: 1.191e-03, size: 672, ETA: 2 days, 7:08:09\u001b[0m\n",
            "\u001b[32m2021-10-22 03:48:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 150/777, mem: 9741Mb, iter_time: 0.968s, data_time: 0.006s, total_loss: 5.1, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.1, lr: 1.191e-03, size: 608, ETA: 2 days, 7:07:45\u001b[0m\n",
            "\u001b[32m2021-10-22 03:48:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 160/777, mem: 9741Mb, iter_time: 0.986s, data_time: 0.010s, total_loss: 5.3, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.4, lr: 1.191e-03, size: 832, ETA: 2 days, 7:07:28\u001b[0m\n",
            "\u001b[32m2021-10-22 03:48:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 170/777, mem: 9741Mb, iter_time: 1.228s, data_time: 0.012s, total_loss: 6.6, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 3.0, cls_loss: 1.7, lr: 1.191e-03, size: 704, ETA: 2 days, 7:08:50\u001b[0m\n",
            "\u001b[32m2021-10-22 03:48:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 180/777, mem: 9741Mb, iter_time: 1.108s, data_time: 0.006s, total_loss: 6.4, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.9, cls_loss: 1.6, lr: 1.191e-03, size: 704, ETA: 2 days, 7:09:23\u001b[0m\n",
            "\u001b[32m2021-10-22 03:48:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 190/777, mem: 9741Mb, iter_time: 1.049s, data_time: 0.006s, total_loss: 5.5, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.6, cls_loss: 1.2, lr: 1.190e-03, size: 672, ETA: 2 days, 7:09:32\u001b[0m\n",
            "\u001b[32m2021-10-22 03:48:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 200/777, mem: 9741Mb, iter_time: 1.017s, data_time: 0.006s, total_loss: 4.1, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 0.9, lr: 1.190e-03, size: 640, ETA: 2 days, 7:09:28\u001b[0m\n",
            "\u001b[32m2021-10-22 03:49:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 210/777, mem: 9741Mb, iter_time: 0.982s, data_time: 0.009s, total_loss: 5.4, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.4, lr: 1.190e-03, size: 736, ETA: 2 days, 7:09:09\u001b[0m\n",
            "\u001b[32m2021-10-22 03:49:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 220/777, mem: 9741Mb, iter_time: 1.022s, data_time: 0.010s, total_loss: 6.1, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.6, cls_loss: 1.6, lr: 1.190e-03, size: 480, ETA: 2 days, 7:09:07\u001b[0m\n",
            "\u001b[32m2021-10-22 03:49:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 230/777, mem: 9741Mb, iter_time: 0.834s, data_time: 0.007s, total_loss: 4.8, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.1, lr: 1.190e-03, size: 576, ETA: 2 days, 7:07:48\u001b[0m\n",
            "\u001b[32m2021-10-22 03:49:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 240/777, mem: 9741Mb, iter_time: 0.914s, data_time: 0.010s, total_loss: 4.2, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.7, cls_loss: 0.9, lr: 1.190e-03, size: 800, ETA: 2 days, 7:07:02\u001b[0m\n",
            "\u001b[32m2021-10-22 03:49:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 250/777, mem: 9741Mb, iter_time: 1.163s, data_time: 0.007s, total_loss: 5.6, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.5, cls_loss: 1.4, lr: 1.190e-03, size: 448, ETA: 2 days, 7:07:57\u001b[0m\n",
            "\u001b[32m2021-10-22 03:49:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 260/777, mem: 9741Mb, iter_time: 0.909s, data_time: 0.006s, total_loss: 5.2, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.2, lr: 1.190e-03, size: 608, ETA: 2 days, 7:07:09\u001b[0m\n",
            "\u001b[32m2021-10-22 03:50:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 270/777, mem: 9741Mb, iter_time: 0.873s, data_time: 0.009s, total_loss: 4.9, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.3, lr: 1.190e-03, size: 448, ETA: 2 days, 7:06:07\u001b[0m\n",
            "\u001b[32m2021-10-22 03:50:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 280/777, mem: 9741Mb, iter_time: 0.784s, data_time: 0.007s, total_loss: 4.9, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.1, lr: 1.190e-03, size: 544, ETA: 2 days, 7:04:29\u001b[0m\n",
            "\u001b[32m2021-10-22 03:50:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 290/777, mem: 9741Mb, iter_time: 0.811s, data_time: 0.011s, total_loss: 4.8, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.1, lr: 1.190e-03, size: 512, ETA: 2 days, 7:03:03\u001b[0m\n",
            "\u001b[32m2021-10-22 03:50:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 300/777, mem: 9741Mb, iter_time: 0.801s, data_time: 0.009s, total_loss: 5.3, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.6, lr: 1.190e-03, size: 704, ETA: 2 days, 7:01:33\u001b[0m\n",
            "\u001b[32m2021-10-22 03:50:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 310/777, mem: 9741Mb, iter_time: 1.043s, data_time: 0.008s, total_loss: 4.2, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 1.7, cls_loss: 1.0, lr: 1.190e-03, size: 640, ETA: 2 days, 7:01:39\u001b[0m\n",
            "\u001b[32m2021-10-22 03:50:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 320/777, mem: 9741Mb, iter_time: 0.955s, data_time: 0.008s, total_loss: 5.1, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.2, lr: 1.190e-03, size: 608, ETA: 2 days, 7:01:11\u001b[0m\n",
            "\u001b[32m2021-10-22 03:50:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 330/777, mem: 9741Mb, iter_time: 0.925s, data_time: 0.007s, total_loss: 5.3, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.1, lr: 1.190e-03, size: 640, ETA: 2 days, 7:00:31\u001b[0m\n",
            "\u001b[32m2021-10-22 03:51:08\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 340/777, mem: 9741Mb, iter_time: 0.927s, data_time: 0.007s, total_loss: 5.3, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.2, lr: 1.190e-03, size: 448, ETA: 2 days, 6:59:51\u001b[0m\n",
            "\u001b[32m2021-10-22 03:51:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 350/777, mem: 9741Mb, iter_time: 0.780s, data_time: 0.011s, total_loss: 4.7, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.1, lr: 1.190e-03, size: 608, ETA: 2 days, 6:58:14\u001b[0m\n",
            "\u001b[32m2021-10-22 03:51:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 360/777, mem: 9741Mb, iter_time: 0.946s, data_time: 0.011s, total_loss: 5.5, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.4, lr: 1.190e-03, size: 800, ETA: 2 days, 6:57:43\u001b[0m\n",
            "\u001b[32m2021-10-22 03:51:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 370/777, mem: 9741Mb, iter_time: 1.201s, data_time: 0.009s, total_loss: 5.4, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.4, lr: 1.190e-03, size: 576, ETA: 2 days, 6:58:51\u001b[0m\n",
            "\u001b[32m2021-10-22 03:51:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 380/777, mem: 9741Mb, iter_time: 0.973s, data_time: 0.003s, total_loss: 4.7, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.3, lr: 1.190e-03, size: 608, ETA: 2 days, 6:58:30\u001b[0m\n",
            "\u001b[32m2021-10-22 03:51:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 390/777, mem: 9741Mb, iter_time: 0.887s, data_time: 0.007s, total_loss: 5.9, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.8, cls_loss: 1.3, lr: 1.190e-03, size: 512, ETA: 2 days, 6:57:36\u001b[0m\n",
            "\u001b[32m2021-10-22 03:52:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 400/777, mem: 9741Mb, iter_time: 0.832s, data_time: 0.004s, total_loss: 4.5, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.7, cls_loss: 1.1, lr: 1.190e-03, size: 608, ETA: 2 days, 6:56:20\u001b[0m\n",
            "\u001b[32m2021-10-22 03:52:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 410/777, mem: 9741Mb, iter_time: 0.916s, data_time: 0.011s, total_loss: 4.6, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.2, lr: 1.190e-03, size: 768, ETA: 2 days, 6:55:37\u001b[0m\n",
            "\u001b[32m2021-10-22 03:52:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 420/777, mem: 9741Mb, iter_time: 1.151s, data_time: 0.007s, total_loss: 5.7, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.5, cls_loss: 1.5, lr: 1.190e-03, size: 736, ETA: 2 days, 6:56:26\u001b[0m\n",
            "\u001b[32m2021-10-22 03:52:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 430/777, mem: 9741Mb, iter_time: 1.096s, data_time: 0.007s, total_loss: 5.1, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.2, lr: 1.190e-03, size: 608, ETA: 2 days, 6:56:53\u001b[0m\n",
            "\u001b[32m2021-10-22 03:52:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 440/777, mem: 9741Mb, iter_time: 0.988s, data_time: 0.008s, total_loss: 4.5, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.1, lr: 1.190e-03, size: 768, ETA: 2 days, 6:56:38\u001b[0m\n",
            "\u001b[32m2021-10-22 03:52:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 450/777, mem: 9741Mb, iter_time: 1.125s, data_time: 0.008s, total_loss: 5.7, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.5, cls_loss: 1.4, lr: 1.190e-03, size: 608, ETA: 2 days, 6:57:17\u001b[0m\n",
            "\u001b[32m2021-10-22 03:53:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 460/777, mem: 9741Mb, iter_time: 0.926s, data_time: 0.009s, total_loss: 5.2, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.4, lr: 1.189e-03, size: 448, ETA: 2 days, 6:56:38\u001b[0m\n",
            "\u001b[32m2021-10-22 03:53:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 470/777, mem: 9741Mb, iter_time: 0.788s, data_time: 0.006s, total_loss: 5.2, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.2, lr: 1.189e-03, size: 544, ETA: 2 days, 6:55:06\u001b[0m\n",
            "\u001b[32m2021-10-22 03:53:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 480/777, mem: 9741Mb, iter_time: 0.841s, data_time: 0.008s, total_loss: 4.2, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.7, cls_loss: 0.9, lr: 1.189e-03, size: 768, ETA: 2 days, 6:53:54\u001b[0m\n",
            "\u001b[32m2021-10-22 03:53:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 490/777, mem: 9741Mb, iter_time: 1.141s, data_time: 0.009s, total_loss: 5.4, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.5, lr: 1.189e-03, size: 672, ETA: 2 days, 6:54:39\u001b[0m\n",
            "\u001b[32m2021-10-22 03:53:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 500/777, mem: 9741Mb, iter_time: 1.083s, data_time: 0.008s, total_loss: 5.8, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.5, cls_loss: 1.5, lr: 1.189e-03, size: 736, ETA: 2 days, 6:55:00\u001b[0m\n",
            "\u001b[32m2021-10-22 03:53:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 510/777, mem: 9741Mb, iter_time: 1.069s, data_time: 0.006s, total_loss: 5.3, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.3, lr: 1.189e-03, size: 672, ETA: 2 days, 6:55:17\u001b[0m\n",
            "\u001b[32m2021-10-22 03:54:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 520/777, mem: 9741Mb, iter_time: 1.059s, data_time: 0.006s, total_loss: 5.7, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.6, lr: 1.189e-03, size: 672, ETA: 2 days, 6:55:29\u001b[0m\n",
            "\u001b[32m2021-10-22 03:54:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 530/777, mem: 9741Mb, iter_time: 1.010s, data_time: 0.008s, total_loss: 5.2, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.3, lr: 1.189e-03, size: 608, ETA: 2 days, 6:55:23\u001b[0m\n",
            "\u001b[32m2021-10-22 03:54:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 540/777, mem: 9741Mb, iter_time: 0.949s, data_time: 0.009s, total_loss: 5.4, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.2, lr: 1.189e-03, size: 704, ETA: 2 days, 6:54:53\u001b[0m\n",
            "\u001b[32m2021-10-22 03:54:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 550/777, mem: 9741Mb, iter_time: 1.033s, data_time: 0.008s, total_loss: 4.1, iou_loss: 1.4, l1_loss: 0.0, conf_loss: 1.7, cls_loss: 0.9, lr: 1.189e-03, size: 608, ETA: 2 days, 6:54:55\u001b[0m\n",
            "\u001b[32m2021-10-22 03:54:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 560/777, mem: 9741Mb, iter_time: 0.992s, data_time: 0.007s, total_loss: 5.0, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.2, lr: 1.189e-03, size: 800, ETA: 2 days, 6:54:42\u001b[0m\n",
            "\u001b[32m2021-10-22 03:54:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 570/777, mem: 9741Mb, iter_time: 1.159s, data_time: 0.008s, total_loss: 5.7, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.6, cls_loss: 1.4, lr: 1.189e-03, size: 512, ETA: 2 days, 6:55:32\u001b[0m\n",
            "\u001b[32m2021-10-22 03:55:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 580/777, mem: 9741Mb, iter_time: 0.943s, data_time: 0.005s, total_loss: 5.1, iou_loss: 2.0, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.2, lr: 1.189e-03, size: 736, ETA: 2 days, 6:55:00\u001b[0m\n",
            "\u001b[32m2021-10-22 03:55:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 590/777, mem: 9741Mb, iter_time: 1.114s, data_time: 0.009s, total_loss: 4.3, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.1, lr: 1.189e-03, size: 768, ETA: 2 days, 6:55:33\u001b[0m\n",
            "\u001b[32m2021-10-22 03:55:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 600/777, mem: 9741Mb, iter_time: 1.112s, data_time: 0.005s, total_loss: 5.6, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.6, cls_loss: 1.1, lr: 1.189e-03, size: 576, ETA: 2 days, 6:56:04\u001b[0m\n",
            "\u001b[32m2021-10-22 03:55:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 610/777, mem: 9741Mb, iter_time: 0.907s, data_time: 0.007s, total_loss: 5.6, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.4, lr: 1.189e-03, size: 512, ETA: 2 days, 6:55:19\u001b[0m\n",
            "\u001b[32m2021-10-22 03:55:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 620/777, mem: 9741Mb, iter_time: 0.825s, data_time: 0.008s, total_loss: 4.4, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.0, lr: 1.189e-03, size: 576, ETA: 2 days, 6:54:03\u001b[0m\n",
            "\u001b[32m2021-10-22 03:55:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 630/777, mem: 9741Mb, iter_time: 0.826s, data_time: 0.009s, total_loss: 4.8, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 1.7, cls_loss: 1.3, lr: 1.189e-03, size: 512, ETA: 2 days, 6:52:48\u001b[0m\n",
            "\u001b[32m2021-10-22 03:56:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 640/777, mem: 9741Mb, iter_time: 0.792s, data_time: 0.009s, total_loss: 5.3, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.5, lr: 1.189e-03, size: 544, ETA: 2 days, 6:51:20\u001b[0m\n",
            "\u001b[32m2021-10-22 03:56:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 650/777, mem: 9741Mb, iter_time: 0.884s, data_time: 0.010s, total_loss: 4.6, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.0, lr: 1.189e-03, size: 768, ETA: 2 days, 6:50:27\u001b[0m\n",
            "\u001b[32m2021-10-22 03:56:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 660/777, mem: 9741Mb, iter_time: 1.164s, data_time: 0.010s, total_loss: 4.7, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.0, lr: 1.189e-03, size: 800, ETA: 2 days, 6:51:18\u001b[0m\n",
            "\u001b[32m2021-10-22 03:56:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 670/777, mem: 9741Mb, iter_time: 1.200s, data_time: 0.006s, total_loss: 6.8, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 3.2, cls_loss: 1.8, lr: 1.189e-03, size: 608, ETA: 2 days, 6:52:22\u001b[0m\n",
            "\u001b[32m2021-10-22 03:56:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 680/777, mem: 9741Mb, iter_time: 1.018s, data_time: 0.007s, total_loss: 4.8, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.2, lr: 1.189e-03, size: 608, ETA: 2 days, 6:52:18\u001b[0m\n",
            "\u001b[32m2021-10-22 03:56:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 690/777, mem: 9741Mb, iter_time: 0.899s, data_time: 0.006s, total_loss: 5.0, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.3, lr: 1.189e-03, size: 576, ETA: 2 days, 6:51:31\u001b[0m\n",
            "\u001b[32m2021-10-22 03:57:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 700/777, mem: 9741Mb, iter_time: 0.862s, data_time: 0.008s, total_loss: 4.9, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.0, lr: 1.189e-03, size: 640, ETA: 2 days, 6:50:30\u001b[0m\n",
            "\u001b[32m2021-10-22 03:57:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 710/777, mem: 9741Mb, iter_time: 0.938s, data_time: 0.009s, total_loss: 4.9, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.1, lr: 1.189e-03, size: 576, ETA: 2 days, 6:49:57\u001b[0m\n",
            "\u001b[32m2021-10-22 03:57:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 720/777, mem: 9741Mb, iter_time: 0.943s, data_time: 0.010s, total_loss: 3.8, iou_loss: 1.4, l1_loss: 0.0, conf_loss: 1.5, cls_loss: 0.9, lr: 1.188e-03, size: 768, ETA: 2 days, 6:49:26\u001b[0m\n",
            "\u001b[32m2021-10-22 03:57:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 730/777, mem: 9741Mb, iter_time: 1.086s, data_time: 0.007s, total_loss: 5.5, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.6, cls_loss: 1.2, lr: 1.188e-03, size: 544, ETA: 2 days, 6:49:48\u001b[0m\n",
            "\u001b[32m2021-10-22 03:57:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 740/777, mem: 9741Mb, iter_time: 0.920s, data_time: 0.007s, total_loss: 4.9, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.1, lr: 1.188e-03, size: 640, ETA: 2 days, 6:49:09\u001b[0m\n",
            "\u001b[32m2021-10-22 03:57:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 750/777, mem: 9741Mb, iter_time: 0.975s, data_time: 0.010s, total_loss: 4.2, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.6, cls_loss: 1.1, lr: 1.188e-03, size: 800, ETA: 2 days, 6:48:50\u001b[0m\n",
            "\u001b[32m2021-10-22 03:58:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 760/777, mem: 9741Mb, iter_time: 1.167s, data_time: 0.006s, total_loss: 5.8, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.6, cls_loss: 1.3, lr: 1.188e-03, size: 480, ETA: 2 days, 6:49:41\u001b[0m\n",
            "\u001b[32m2021-10-22 03:58:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 46/300, iter: 770/777, mem: 9741Mb, iter_time: 0.869s, data_time: 0.005s, total_loss: 4.6, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.2, lr: 1.188e-03, size: 512, ETA: 2 days, 6:48:43\u001b[0m\n",
            "\u001b[32m2021-10-22 03:58:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mSave weights to /content/gdrive/MyDrive/Sprints/yolox_voc_s/yolox_voc_s/yolox_voc_s\u001b[0m\n",
            "100%|##########| 44/44 [00:14<00:00,  3.10it/s]\n",
            "\u001b[32m2021-10-22 03:58:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.evaluators.voc_evaluator\u001b[0m:\u001b[36m161\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
            "Writing beans VOC results file\n",
            "Writing cake VOC results file\n",
            "Writing candy VOC results file\n",
            "Writing cereal VOC results file\n",
            "Writing chips VOC results file\n",
            "Writing chocolate VOC results file\n",
            "Writing coffee VOC results file\n",
            "Writing corn VOC results file\n",
            "Writing fish VOC results file\n",
            "Writing flour VOC results file\n",
            "Writing honey VOC results file\n",
            "Writing jam VOC results file\n",
            "Writing juice VOC results file\n",
            "Writing milk VOC results file\n",
            "Writing nuts VOC results file\n",
            "Writing oil VOC results file\n",
            "Writing pasta VOC results file\n",
            "Writing rice VOC results file\n",
            "Writing soda VOC results file\n",
            "Writing spices VOC results file\n",
            "Writing sugar VOC results file\n",
            "Writing tea VOC results file\n",
            "Writing tomato_sauce VOC results file\n",
            "Writing vinegar VOC results file\n",
            "Writing water VOC results file\n",
            "Eval IoU : 0.50\n",
            "AP for beans = 0.9311\n",
            "AP for cake = 0.9077\n",
            "AP for candy = 0.7591\n",
            "AP for cereal = 0.9437\n",
            "AP for chips = 0.9100\n",
            "AP for chocolate = 0.9029\n",
            "AP for coffee = 0.9308\n",
            "AP for corn = 0.9504\n",
            "AP for fish = 0.8828\n",
            "AP for flour = 0.7989\n",
            "AP for honey = 0.9513\n",
            "AP for jam = 0.8976\n",
            "AP for juice = 0.9407\n",
            "AP for milk = 0.7227\n",
            "AP for nuts = 0.8932\n",
            "AP for oil = 0.8274\n",
            "AP for pasta = 0.8356\n",
            "AP for rice = 0.8757\n",
            "AP for soda = 0.8801\n",
            "AP for spices = 0.9076\n",
            "AP for sugar = 0.8850\n",
            "AP for tea = 0.8040\n",
            "AP for tomato_sauce = 0.8836\n",
            "AP for vinegar = 0.9794\n",
            "AP for water = 0.9350\n",
            "Mean AP = 0.8854\n",
            "~~~~~~~~\n",
            "Results:\n",
            "0.931\n",
            "0.908\n",
            "0.759\n",
            "0.944\n",
            "0.910\n",
            "0.903\n",
            "0.931\n",
            "0.950\n",
            "0.883\n",
            "0.799\n",
            "0.951\n",
            "0.898\n",
            "0.941\n",
            "0.723\n",
            "0.893\n",
            "0.827\n",
            "0.836\n",
            "0.876\n",
            "0.880\n",
            "0.908\n",
            "0.885\n",
            "0.804\n",
            "0.884\n",
            "0.979\n",
            "0.935\n",
            "0.885\n",
            "~~~~~~~~\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Results computed with the **unofficial** Python eval code.\n",
            "Results should be very close to the official MATLAB eval code.\n",
            "Recompute with `./tools/reval.py --matlab ...` for your paper.\n",
            "-- Thanks, The Management\n",
            "--------------------------------------------------------------\n",
            "Eval IoU : 0.55\n",
            "Eval IoU : 0.60\n",
            "Eval IoU : 0.65\n",
            "Eval IoU : 0.70\n",
            "Eval IoU : 0.75\n",
            "Eval IoU : 0.80\n",
            "Eval IoU : 0.85\n",
            "Eval IoU : 0.90\n",
            "Eval IoU : 0.95\n",
            "--------------------------------------------------------------\n",
            "map_5095: 0.6880427968331055\n",
            "map_50: 0.8854470032961409\n",
            "--------------------------------------------------------------\n",
            "\u001b[32m2021-10-22 03:58:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m314\u001b[0m - \u001b[1m\n",
            "Average forward time: 22.97 ms, Average NMS time: 5.13 ms, Average inference time: 28.10 ms\n",
            "\u001b[0m\n",
            "\u001b[32m2021-10-22 03:58:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mSave weights to /content/gdrive/MyDrive/Sprints/yolox_voc_s/yolox_voc_s/yolox_voc_s\u001b[0m\n",
            "\u001b[32m2021-10-22 03:58:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m193\u001b[0m - \u001b[1m---> start train epoch47\u001b[0m\n",
            "\u001b[32m2021-10-22 03:58:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 10/777, mem: 9741Mb, iter_time: 0.830s, data_time: 0.008s, total_loss: 5.3, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.5, lr: 1.188e-03, size: 800, ETA: 2 days, 6:46:21\u001b[0m\n",
            "\u001b[32m2021-10-22 03:58:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 20/777, mem: 9741Mb, iter_time: 1.125s, data_time: 0.007s, total_loss: 5.4, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.6, lr: 1.188e-03, size: 448, ETA: 2 days, 6:46:57\u001b[0m\n",
            "\u001b[32m2021-10-22 03:59:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 30/777, mem: 9741Mb, iter_time: 0.972s, data_time: 0.002s, total_loss: 4.3, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.7, cls_loss: 1.0, lr: 1.188e-03, size: 480, ETA: 2 days, 6:46:37\u001b[0m\n",
            "\u001b[32m2021-10-22 03:59:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 40/777, mem: 9741Mb, iter_time: 0.710s, data_time: 0.009s, total_loss: 4.3, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 1.6, cls_loss: 1.0, lr: 1.188e-03, size: 544, ETA: 2 days, 6:44:43\u001b[0m\n",
            "\u001b[32m2021-10-22 03:59:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 50/777, mem: 9741Mb, iter_time: 0.804s, data_time: 0.008s, total_loss: 5.0, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.1, lr: 1.188e-03, size: 608, ETA: 2 days, 6:43:22\u001b[0m\n",
            "\u001b[32m2021-10-22 03:59:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 60/777, mem: 9741Mb, iter_time: 0.869s, data_time: 0.010s, total_loss: 5.0, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.2, lr: 1.188e-03, size: 832, ETA: 2 days, 6:42:26\u001b[0m\n",
            "\u001b[32m2021-10-22 03:59:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 70/777, mem: 9741Mb, iter_time: 1.206s, data_time: 0.011s, total_loss: 6.4, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 3.0, cls_loss: 1.6, lr: 1.188e-03, size: 800, ETA: 2 days, 6:43:30\u001b[0m\n",
            "\u001b[32m2021-10-22 03:59:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 80/777, mem: 9741Mb, iter_time: 1.284s, data_time: 0.008s, total_loss: 6.1, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.8, cls_loss: 1.5, lr: 1.188e-03, size: 448, ETA: 2 days, 6:45:02\u001b[0m\n",
            "\u001b[32m2021-10-22 04:00:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 90/777, mem: 9741Mb, iter_time: 0.971s, data_time: 0.003s, total_loss: 5.5, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.4, lr: 1.188e-03, size: 800, ETA: 2 days, 6:44:42\u001b[0m\n",
            "\u001b[32m2021-10-22 04:00:17\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 100/777, mem: 9741Mb, iter_time: 1.112s, data_time: 0.013s, total_loss: 5.8, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.6, lr: 1.188e-03, size: 736, ETA: 2 days, 6:45:12\u001b[0m\n",
            "\u001b[32m2021-10-22 04:00:28\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 110/777, mem: 9741Mb, iter_time: 1.164s, data_time: 0.006s, total_loss: 5.8, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.7, cls_loss: 1.5, lr: 1.188e-03, size: 480, ETA: 2 days, 6:46:01\u001b[0m\n",
            "\u001b[32m2021-10-22 04:00:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 120/777, mem: 9741Mb, iter_time: 0.882s, data_time: 0.003s, total_loss: 4.7, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.1, lr: 1.188e-03, size: 736, ETA: 2 days, 6:45:09\u001b[0m\n",
            "\u001b[32m2021-10-22 04:00:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 130/777, mem: 9741Mb, iter_time: 0.997s, data_time: 0.010s, total_loss: 6.7, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.9, cls_loss: 2.0, lr: 1.188e-03, size: 480, ETA: 2 days, 6:44:59\u001b[0m\n",
            "\u001b[32m2021-10-22 04:00:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 140/777, mem: 9741Mb, iter_time: 0.888s, data_time: 0.004s, total_loss: 4.3, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 0.9, lr: 1.188e-03, size: 768, ETA: 2 days, 6:44:09\u001b[0m\n",
            "\u001b[32m2021-10-22 04:01:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 150/777, mem: 9741Mb, iter_time: 1.070s, data_time: 0.011s, total_loss: 5.5, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.5, cls_loss: 1.2, lr: 1.188e-03, size: 800, ETA: 2 days, 6:44:24\u001b[0m\n",
            "\u001b[32m2021-10-22 04:01:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 160/777, mem: 9741Mb, iter_time: 1.175s, data_time: 0.008s, total_loss: 4.9, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.1, lr: 1.188e-03, size: 544, ETA: 2 days, 6:45:16\u001b[0m\n",
            "\u001b[32m2021-10-22 04:01:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 170/777, mem: 9741Mb, iter_time: 1.021s, data_time: 0.002s, total_loss: 5.8, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.7, cls_loss: 1.4, lr: 1.188e-03, size: 704, ETA: 2 days, 6:45:14\u001b[0m\n",
            "\u001b[32m2021-10-22 04:01:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 180/777, mem: 9741Mb, iter_time: 1.009s, data_time: 0.011s, total_loss: 5.0, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.1, lr: 1.188e-03, size: 672, ETA: 2 days, 6:45:07\u001b[0m\n",
            "\u001b[32m2021-10-22 04:01:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 190/777, mem: 9741Mb, iter_time: 1.020s, data_time: 0.005s, total_loss: 5.4, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.5, lr: 1.188e-03, size: 544, ETA: 2 days, 6:45:04\u001b[0m\n",
            "\u001b[32m2021-10-22 04:01:58\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 200/777, mem: 9741Mb, iter_time: 0.920s, data_time: 0.008s, total_loss: 4.8, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.1, lr: 1.188e-03, size: 832, ETA: 2 days, 6:44:27\u001b[0m\n",
            "\u001b[32m2021-10-22 04:02:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 210/777, mem: 9741Mb, iter_time: 1.191s, data_time: 0.008s, total_loss: 5.1, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.2, lr: 1.187e-03, size: 608, ETA: 2 days, 6:45:23\u001b[0m\n",
            "\u001b[32m2021-10-22 04:02:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 220/777, mem: 9741Mb, iter_time: 1.087s, data_time: 0.003s, total_loss: 5.3, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.2, lr: 1.187e-03, size: 576, ETA: 2 days, 6:45:44\u001b[0m\n",
            "\u001b[32m2021-10-22 04:02:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 230/777, mem: 9741Mb, iter_time: 0.884s, data_time: 0.007s, total_loss: 4.4, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.7, cls_loss: 1.0, lr: 1.187e-03, size: 800, ETA: 2 days, 6:44:53\u001b[0m\n",
            "\u001b[32m2021-10-22 04:02:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 240/777, mem: 9741Mb, iter_time: 1.123s, data_time: 0.010s, total_loss: 5.2, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.2, lr: 1.187e-03, size: 544, ETA: 2 days, 6:45:26\u001b[0m\n",
            "\u001b[32m2021-10-22 04:02:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 250/777, mem: 9741Mb, iter_time: 1.031s, data_time: 0.002s, total_loss: 4.6, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 1.6, cls_loss: 1.2, lr: 1.187e-03, size: 736, ETA: 2 days, 6:45:27\u001b[0m\n",
            "\u001b[32m2021-10-22 04:03:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 260/777, mem: 9741Mb, iter_time: 1.036s, data_time: 0.010s, total_loss: 5.0, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.1, lr: 1.187e-03, size: 576, ETA: 2 days, 6:45:29\u001b[0m\n",
            "\u001b[32m2021-10-22 04:03:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 270/777, mem: 9741Mb, iter_time: 0.973s, data_time: 0.005s, total_loss: 5.1, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.1, lr: 1.187e-03, size: 576, ETA: 2 days, 6:45:10\u001b[0m\n",
            "\u001b[32m2021-10-22 04:03:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 280/777, mem: 9741Mb, iter_time: 0.848s, data_time: 0.009s, total_loss: 3.9, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 1.7, cls_loss: 0.7, lr: 1.187e-03, size: 672, ETA: 2 days, 6:44:07\u001b[0m\n",
            "\u001b[32m2021-10-22 04:03:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 290/777, mem: 9741Mb, iter_time: 0.969s, data_time: 0.011s, total_loss: 4.5, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.0, lr: 1.187e-03, size: 640, ETA: 2 days, 6:43:47\u001b[0m\n",
            "\u001b[32m2021-10-22 04:03:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 300/777, mem: 9741Mb, iter_time: 0.972s, data_time: 0.006s, total_loss: 5.3, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.1, lr: 1.187e-03, size: 640, ETA: 2 days, 6:43:27\u001b[0m\n",
            "\u001b[32m2021-10-22 04:03:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 310/777, mem: 9741Mb, iter_time: 0.935s, data_time: 0.009s, total_loss: 4.3, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.0, lr: 1.187e-03, size: 800, ETA: 2 days, 6:42:55\u001b[0m\n",
            "\u001b[32m2021-10-22 04:04:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 320/777, mem: 9741Mb, iter_time: 1.149s, data_time: 0.006s, total_loss: 4.8, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.1, lr: 1.187e-03, size: 544, ETA: 2 days, 6:43:36\u001b[0m\n",
            "\u001b[32m2021-10-22 04:04:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 330/777, mem: 9741Mb, iter_time: 1.003s, data_time: 0.002s, total_loss: 4.3, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 0.9, lr: 1.187e-03, size: 448, ETA: 2 days, 6:43:27\u001b[0m\n",
            "\u001b[32m2021-10-22 04:04:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 340/777, mem: 9741Mb, iter_time: 0.747s, data_time: 0.005s, total_loss: 4.4, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 1.6, cls_loss: 1.0, lr: 1.187e-03, size: 640, ETA: 2 days, 6:41:51\u001b[0m\n",
            "\u001b[32m2021-10-22 04:04:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 350/777, mem: 9741Mb, iter_time: 0.888s, data_time: 0.007s, total_loss: 4.8, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.1, lr: 1.187e-03, size: 608, ETA: 2 days, 6:41:03\u001b[0m\n",
            "\u001b[32m2021-10-22 04:04:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 360/777, mem: 9741Mb, iter_time: 0.915s, data_time: 0.007s, total_loss: 5.1, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.3, lr: 1.187e-03, size: 480, ETA: 2 days, 6:40:24\u001b[0m\n",
            "\u001b[32m2021-10-22 04:04:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 370/777, mem: 9741Mb, iter_time: 0.793s, data_time: 0.008s, total_loss: 4.8, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.0, lr: 1.187e-03, size: 512, ETA: 2 days, 6:39:04\u001b[0m\n",
            "\u001b[32m2021-10-22 04:04:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 380/777, mem: 9741Mb, iter_time: 0.738s, data_time: 0.009s, total_loss: 4.4, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 1.7, cls_loss: 0.9, lr: 1.187e-03, size: 768, ETA: 2 days, 6:37:26\u001b[0m\n",
            "\u001b[32m2021-10-22 04:05:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 390/777, mem: 9741Mb, iter_time: 1.100s, data_time: 0.011s, total_loss: 5.0, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.4, lr: 1.187e-03, size: 640, ETA: 2 days, 6:37:50\u001b[0m\n",
            "\u001b[32m2021-10-22 04:05:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 400/777, mem: 9741Mb, iter_time: 1.052s, data_time: 0.007s, total_loss: 5.2, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.4, lr: 1.187e-03, size: 832, ETA: 2 days, 6:37:59\u001b[0m\n",
            "\u001b[32m2021-10-22 04:05:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 410/777, mem: 9741Mb, iter_time: 1.191s, data_time: 0.011s, total_loss: 6.3, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.9, cls_loss: 1.5, lr: 1.187e-03, size: 800, ETA: 2 days, 6:38:54\u001b[0m\n",
            "\u001b[32m2021-10-22 04:05:38\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 420/777, mem: 9741Mb, iter_time: 1.303s, data_time: 0.009s, total_loss: 5.5, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.3, lr: 1.187e-03, size: 640, ETA: 2 days, 6:40:26\u001b[0m\n",
            "\u001b[32m2021-10-22 04:05:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 430/777, mem: 9741Mb, iter_time: 1.112s, data_time: 0.004s, total_loss: 5.1, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.3, lr: 1.187e-03, size: 832, ETA: 2 days, 6:40:53\u001b[0m\n",
            "\u001b[32m2021-10-22 04:06:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 440/777, mem: 9741Mb, iter_time: 1.198s, data_time: 0.007s, total_loss: 5.5, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.5, cls_loss: 1.4, lr: 1.187e-03, size: 736, ETA: 2 days, 6:41:50\u001b[0m\n",
            "\u001b[32m2021-10-22 04:06:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 450/777, mem: 9741Mb, iter_time: 1.240s, data_time: 0.007s, total_loss: 4.7, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.0, lr: 1.187e-03, size: 704, ETA: 2 days, 6:43:00\u001b[0m\n",
            "\u001b[32m2021-10-22 04:06:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 460/777, mem: 9741Mb, iter_time: 1.086s, data_time: 0.010s, total_loss: 5.7, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.6, lr: 1.187e-03, size: 768, ETA: 2 days, 6:43:19\u001b[0m\n",
            "\u001b[32m2021-10-22 04:06:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 470/777, mem: 9741Mb, iter_time: 1.124s, data_time: 0.007s, total_loss: 5.3, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.3, lr: 1.186e-03, size: 448, ETA: 2 days, 6:43:50\u001b[0m\n",
            "\u001b[32m2021-10-22 04:06:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 480/777, mem: 9741Mb, iter_time: 0.881s, data_time: 0.004s, total_loss: 5.1, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.4, lr: 1.186e-03, size: 480, ETA: 2 days, 6:43:00\u001b[0m\n",
            "\u001b[32m2021-10-22 04:06:52\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 490/777, mem: 9741Mb, iter_time: 0.757s, data_time: 0.011s, total_loss: 4.3, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.6, cls_loss: 1.1, lr: 1.186e-03, size: 640, ETA: 2 days, 6:41:29\u001b[0m\n",
            "\u001b[32m2021-10-22 04:07:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 500/777, mem: 9741Mb, iter_time: 0.888s, data_time: 0.010s, total_loss: 4.8, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.1, lr: 1.186e-03, size: 704, ETA: 2 days, 6:40:42\u001b[0m\n",
            "\u001b[32m2021-10-22 04:07:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 510/777, mem: 9741Mb, iter_time: 1.064s, data_time: 0.006s, total_loss: 5.0, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.3, lr: 1.186e-03, size: 576, ETA: 2 days, 6:40:53\u001b[0m\n",
            "\u001b[32m2021-10-22 04:07:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 520/777, mem: 9741Mb, iter_time: 0.952s, data_time: 0.009s, total_loss: 4.7, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.1, lr: 1.186e-03, size: 800, ETA: 2 days, 6:40:27\u001b[0m\n",
            "\u001b[32m2021-10-22 04:07:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 530/777, mem: 9741Mb, iter_time: 1.133s, data_time: 0.009s, total_loss: 6.0, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.8, cls_loss: 1.5, lr: 1.186e-03, size: 736, ETA: 2 days, 6:41:01\u001b[0m\n",
            "\u001b[32m2021-10-22 04:07:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 540/777, mem: 9741Mb, iter_time: 1.196s, data_time: 0.006s, total_loss: 5.4, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.4, lr: 1.186e-03, size: 736, ETA: 2 days, 6:41:56\u001b[0m\n",
            "\u001b[32m2021-10-22 04:07:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 550/777, mem: 9741Mb, iter_time: 1.109s, data_time: 0.004s, total_loss: 6.0, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.9, cls_loss: 1.4, lr: 1.186e-03, size: 736, ETA: 2 days, 6:42:21\u001b[0m\n",
            "\u001b[32m2021-10-22 04:08:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 560/777, mem: 9741Mb, iter_time: 1.108s, data_time: 0.006s, total_loss: 5.0, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.2, lr: 1.186e-03, size: 832, ETA: 2 days, 6:42:47\u001b[0m\n",
            "\u001b[32m2021-10-22 04:08:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 570/777, mem: 9741Mb, iter_time: 1.257s, data_time: 0.011s, total_loss: 5.3, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.4, lr: 1.186e-03, size: 544, ETA: 2 days, 6:44:01\u001b[0m\n",
            "\u001b[32m2021-10-22 04:08:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 580/777, mem: 9741Mb, iter_time: 1.040s, data_time: 0.004s, total_loss: 4.6, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.1, lr: 1.186e-03, size: 704, ETA: 2 days, 6:44:03\u001b[0m\n",
            "\u001b[32m2021-10-22 04:08:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 590/777, mem: 9741Mb, iter_time: 0.961s, data_time: 0.010s, total_loss: 4.3, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 0.8, lr: 1.186e-03, size: 448, ETA: 2 days, 6:43:40\u001b[0m\n",
            "\u001b[32m2021-10-22 04:08:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 600/777, mem: 9741Mb, iter_time: 0.827s, data_time: 0.003s, total_loss: 4.6, iou_loss: 2.0, l1_loss: 0.0, conf_loss: 1.7, cls_loss: 0.9, lr: 1.186e-03, size: 512, ETA: 2 days, 6:42:33\u001b[0m\n",
            "\u001b[32m2021-10-22 04:08:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 610/777, mem: 9741Mb, iter_time: 0.742s, data_time: 0.008s, total_loss: 4.7, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.0, lr: 1.186e-03, size: 640, ETA: 2 days, 6:40:59\u001b[0m\n",
            "\u001b[32m2021-10-22 04:09:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 620/777, mem: 9741Mb, iter_time: 0.868s, data_time: 0.006s, total_loss: 4.3, iou_loss: 1.4, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.1, lr: 1.186e-03, size: 480, ETA: 2 days, 6:40:06\u001b[0m\n",
            "\u001b[32m2021-10-22 04:09:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 630/777, mem: 9741Mb, iter_time: 0.806s, data_time: 0.007s, total_loss: 5.0, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.3, lr: 1.186e-03, size: 800, ETA: 2 days, 6:38:53\u001b[0m\n",
            "\u001b[32m2021-10-22 04:09:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 640/777, mem: 9741Mb, iter_time: 1.155s, data_time: 0.010s, total_loss: 4.8, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.1, lr: 1.186e-03, size: 704, ETA: 2 days, 6:39:33\u001b[0m\n",
            "\u001b[32m2021-10-22 04:09:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 650/777, mem: 9741Mb, iter_time: 1.130s, data_time: 0.008s, total_loss: 5.6, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.6, cls_loss: 1.2, lr: 1.186e-03, size: 640, ETA: 2 days, 6:40:05\u001b[0m\n",
            "\u001b[32m2021-10-22 04:09:45\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 660/777, mem: 9741Mb, iter_time: 0.991s, data_time: 0.004s, total_loss: 5.4, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.3, lr: 1.186e-03, size: 672, ETA: 2 days, 6:39:52\u001b[0m\n",
            "\u001b[32m2021-10-22 04:09:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 670/777, mem: 9741Mb, iter_time: 0.974s, data_time: 0.006s, total_loss: 5.2, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.2, lr: 1.186e-03, size: 608, ETA: 2 days, 6:39:33\u001b[0m\n",
            "\u001b[32m2021-10-22 04:10:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 680/777, mem: 9741Mb, iter_time: 0.964s, data_time: 0.011s, total_loss: 4.2, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.6, cls_loss: 1.1, lr: 1.186e-03, size: 608, ETA: 2 days, 6:39:12\u001b[0m\n",
            "\u001b[32m2021-10-22 04:10:13\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 690/777, mem: 9741Mb, iter_time: 0.890s, data_time: 0.006s, total_loss: 4.9, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.4, lr: 1.186e-03, size: 576, ETA: 2 days, 6:38:27\u001b[0m\n",
            "\u001b[32m2021-10-22 04:10:22\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 700/777, mem: 9741Mb, iter_time: 0.874s, data_time: 0.007s, total_loss: 4.2, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.6, cls_loss: 0.9, lr: 1.186e-03, size: 736, ETA: 2 days, 6:37:36\u001b[0m\n",
            "\u001b[32m2021-10-22 04:10:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 710/777, mem: 9741Mb, iter_time: 1.032s, data_time: 0.007s, total_loss: 6.5, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 3.0, cls_loss: 1.7, lr: 1.186e-03, size: 640, ETA: 2 days, 6:37:36\u001b[0m\n",
            "\u001b[32m2021-10-22 04:10:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 720/777, mem: 9741Mb, iter_time: 1.009s, data_time: 0.006s, total_loss: 6.7, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.9, cls_loss: 2.0, lr: 1.186e-03, size: 608, ETA: 2 days, 6:37:29\u001b[0m\n",
            "\u001b[32m2021-10-22 04:10:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 730/777, mem: 9741Mb, iter_time: 0.908s, data_time: 0.009s, total_loss: 5.2, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.2, lr: 1.185e-03, size: 480, ETA: 2 days, 6:36:50\u001b[0m\n",
            "\u001b[32m2021-10-22 04:10:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 740/777, mem: 9741Mb, iter_time: 0.791s, data_time: 0.007s, total_loss: 5.3, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.3, lr: 1.185e-03, size: 800, ETA: 2 days, 6:35:34\u001b[0m\n",
            "\u001b[32m2021-10-22 04:11:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 750/777, mem: 9741Mb, iter_time: 1.111s, data_time: 0.013s, total_loss: 6.0, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.5, cls_loss: 1.7, lr: 1.185e-03, size: 608, ETA: 2 days, 6:35:59\u001b[0m\n",
            "\u001b[32m2021-10-22 04:11:21\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 760/777, mem: 9741Mb, iter_time: 1.089s, data_time: 0.003s, total_loss: 4.7, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.1, lr: 1.185e-03, size: 800, ETA: 2 days, 6:36:17\u001b[0m\n",
            "\u001b[32m2021-10-22 04:11:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 47/300, iter: 770/777, mem: 9741Mb, iter_time: 1.166s, data_time: 0.009s, total_loss: 6.6, iou_loss: 2.0, l1_loss: 0.0, conf_loss: 3.1, cls_loss: 1.5, lr: 1.185e-03, size: 608, ETA: 2 days, 6:37:00\u001b[0m\n",
            "\u001b[32m2021-10-22 04:11:41\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mSave weights to /content/gdrive/MyDrive/Sprints/yolox_voc_s/yolox_voc_s/yolox_voc_s\u001b[0m\n",
            "100%|##########| 44/44 [00:13<00:00,  3.17it/s]\n",
            "\u001b[32m2021-10-22 04:11:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.evaluators.voc_evaluator\u001b[0m:\u001b[36m161\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
            "Writing beans VOC results file\n",
            "Writing cake VOC results file\n",
            "Writing candy VOC results file\n",
            "Writing cereal VOC results file\n",
            "Writing chips VOC results file\n",
            "Writing chocolate VOC results file\n",
            "Writing coffee VOC results file\n",
            "Writing corn VOC results file\n",
            "Writing fish VOC results file\n",
            "Writing flour VOC results file\n",
            "Writing honey VOC results file\n",
            "Writing jam VOC results file\n",
            "Writing juice VOC results file\n",
            "Writing milk VOC results file\n",
            "Writing nuts VOC results file\n",
            "Writing oil VOC results file\n",
            "Writing pasta VOC results file\n",
            "Writing rice VOC results file\n",
            "Writing soda VOC results file\n",
            "Writing spices VOC results file\n",
            "Writing sugar VOC results file\n",
            "Writing tea VOC results file\n",
            "Writing tomato_sauce VOC results file\n",
            "Writing vinegar VOC results file\n",
            "Writing water VOC results file\n",
            "Eval IoU : 0.50\n",
            "AP for beans = 0.9287\n",
            "AP for cake = 0.9094\n",
            "AP for candy = 0.7453\n",
            "AP for cereal = 0.9443\n",
            "AP for chips = 0.9117\n",
            "AP for chocolate = 0.8987\n",
            "AP for coffee = 0.9288\n",
            "AP for corn = 0.9504\n",
            "AP for fish = 0.8766\n",
            "AP for flour = 0.7973\n",
            "AP for honey = 0.9547\n",
            "AP for jam = 0.8976\n",
            "AP for juice = 0.8975\n",
            "AP for milk = 0.7273\n",
            "AP for nuts = 0.8921\n",
            "AP for oil = 0.8142\n",
            "AP for pasta = 0.8290\n",
            "AP for rice = 0.8935\n",
            "AP for soda = 0.8728\n",
            "AP for spices = 0.9076\n",
            "AP for sugar = 0.8871\n",
            "AP for tea = 0.8063\n",
            "AP for tomato_sauce = 0.8805\n",
            "AP for vinegar = 0.9718\n",
            "AP for water = 0.9355\n",
            "Mean AP = 0.8824\n",
            "~~~~~~~~\n",
            "Results:\n",
            "0.929\n",
            "0.909\n",
            "0.745\n",
            "0.944\n",
            "0.912\n",
            "0.899\n",
            "0.929\n",
            "0.950\n",
            "0.877\n",
            "0.797\n",
            "0.955\n",
            "0.898\n",
            "0.897\n",
            "0.727\n",
            "0.892\n",
            "0.814\n",
            "0.829\n",
            "0.894\n",
            "0.873\n",
            "0.908\n",
            "0.887\n",
            "0.806\n",
            "0.881\n",
            "0.972\n",
            "0.936\n",
            "0.882\n",
            "~~~~~~~~\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Results computed with the **unofficial** Python eval code.\n",
            "Results should be very close to the official MATLAB eval code.\n",
            "Recompute with `./tools/reval.py --matlab ...` for your paper.\n",
            "-- Thanks, The Management\n",
            "--------------------------------------------------------------\n",
            "Eval IoU : 0.55\n",
            "Eval IoU : 0.60\n",
            "Eval IoU : 0.65\n",
            "Eval IoU : 0.70\n",
            "Eval IoU : 0.75\n",
            "Eval IoU : 0.80\n",
            "Eval IoU : 0.85\n",
            "Eval IoU : 0.90\n",
            "Eval IoU : 0.95\n",
            "--------------------------------------------------------------\n",
            "map_5095: 0.6889873797853796\n",
            "map_50: 0.8823531717698914\n",
            "--------------------------------------------------------------\n",
            "\u001b[32m2021-10-22 04:12:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m314\u001b[0m - \u001b[1m\n",
            "Average forward time: 22.47 ms, Average NMS time: 6.00 ms, Average inference time: 28.47 ms\n",
            "\u001b[0m\n",
            "\u001b[32m2021-10-22 04:12:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m323\u001b[0m - \u001b[1mSave weights to /content/gdrive/MyDrive/Sprints/yolox_voc_s/yolox_voc_s/yolox_voc_s\u001b[0m\n",
            "\u001b[32m2021-10-22 04:12:00\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m193\u001b[0m - \u001b[1m---> start train epoch48\u001b[0m\n",
            "\u001b[32m2021-10-22 04:12:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 10/777, mem: 9741Mb, iter_time: 1.000s, data_time: 0.009s, total_loss: 4.4, iou_loss: 1.3, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.1, lr: 1.185e-03, size: 704, ETA: 2 days, 6:37:19\u001b[0m\n",
            "\u001b[32m2021-10-22 04:12:20\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 20/777, mem: 9741Mb, iter_time: 0.987s, data_time: 0.005s, total_loss: 5.9, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.6, lr: 1.185e-03, size: 544, ETA: 2 days, 6:37:05\u001b[0m\n",
            "\u001b[32m2021-10-22 04:12:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 30/777, mem: 9741Mb, iter_time: 0.846s, data_time: 0.007s, total_loss: 4.9, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.1, lr: 1.185e-03, size: 640, ETA: 2 days, 6:36:06\u001b[0m\n",
            "\u001b[32m2021-10-22 04:12:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 40/777, mem: 9741Mb, iter_time: 1.008s, data_time: 0.008s, total_loss: 4.6, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.1, lr: 1.185e-03, size: 768, ETA: 2 days, 6:35:59\u001b[0m\n",
            "\u001b[32m2021-10-22 04:12:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 50/777, mem: 9741Mb, iter_time: 1.107s, data_time: 0.010s, total_loss: 5.7, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.6, lr: 1.185e-03, size: 640, ETA: 2 days, 6:36:22\u001b[0m\n",
            "\u001b[32m2021-10-22 04:12:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 60/777, mem: 9741Mb, iter_time: 0.867s, data_time: 0.009s, total_loss: 4.5, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.1, lr: 1.185e-03, size: 512, ETA: 2 days, 6:35:30\u001b[0m\n",
            "\u001b[32m2021-10-22 04:13:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 70/777, mem: 9741Mb, iter_time: 0.714s, data_time: 0.009s, total_loss: 4.9, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.1, lr: 1.185e-03, size: 448, ETA: 2 days, 6:33:51\u001b[0m\n",
            "\u001b[32m2021-10-22 04:13:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 80/777, mem: 9741Mb, iter_time: 0.867s, data_time: 0.009s, total_loss: 4.1, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.7, cls_loss: 0.8, lr: 1.185e-03, size: 768, ETA: 2 days, 6:32:59\u001b[0m\n",
            "\u001b[32m2021-10-22 04:13:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 90/777, mem: 9741Mb, iter_time: 1.209s, data_time: 0.008s, total_loss: 4.4, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.0, lr: 1.185e-03, size: 800, ETA: 2 days, 6:33:55\u001b[0m\n",
            "\u001b[32m2021-10-22 04:13:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 100/777, mem: 9741Mb, iter_time: 1.256s, data_time: 0.009s, total_loss: 4.8, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.2, lr: 1.185e-03, size: 800, ETA: 2 days, 6:35:05\u001b[0m\n",
            "\u001b[32m2021-10-22 04:13:51\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 110/777, mem: 9741Mb, iter_time: 1.192s, data_time: 0.003s, total_loss: 5.5, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.5, cls_loss: 1.4, lr: 1.185e-03, size: 672, ETA: 2 days, 6:35:54\u001b[0m\n",
            "\u001b[32m2021-10-22 04:14:01\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 120/777, mem: 9741Mb, iter_time: 0.998s, data_time: 0.006s, total_loss: 5.1, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.0, lr: 1.185e-03, size: 704, ETA: 2 days, 6:35:43\u001b[0m\n",
            "\u001b[32m2021-10-22 04:14:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 130/777, mem: 9741Mb, iter_time: 1.002s, data_time: 0.003s, total_loss: 4.9, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.3, lr: 1.185e-03, size: 512, ETA: 2 days, 6:35:34\u001b[0m\n",
            "\u001b[32m2021-10-22 04:14:18\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 140/777, mem: 9741Mb, iter_time: 0.710s, data_time: 0.012s, total_loss: 4.5, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 1.7, cls_loss: 1.0, lr: 1.185e-03, size: 480, ETA: 2 days, 6:33:54\u001b[0m\n",
            "\u001b[32m2021-10-22 04:14:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 150/777, mem: 9741Mb, iter_time: 0.720s, data_time: 0.009s, total_loss: 4.4, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 1.7, cls_loss: 1.1, lr: 1.185e-03, size: 512, ETA: 2 days, 6:32:18\u001b[0m\n",
            "\u001b[32m2021-10-22 04:14:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 160/777, mem: 9741Mb, iter_time: 0.945s, data_time: 0.011s, total_loss: 5.1, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.2, lr: 1.185e-03, size: 832, ETA: 2 days, 6:31:51\u001b[0m\n",
            "\u001b[32m2021-10-22 04:14:48\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 170/777, mem: 9741Mb, iter_time: 1.285s, data_time: 0.004s, total_loss: 4.6, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.0, lr: 1.185e-03, size: 608, ETA: 2 days, 6:33:09\u001b[0m\n",
            "\u001b[32m2021-10-22 04:14:56\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 180/777, mem: 9741Mb, iter_time: 0.860s, data_time: 0.005s, total_loss: 4.2, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 1.6, cls_loss: 0.9, lr: 1.185e-03, size: 512, ETA: 2 days, 6:32:16\u001b[0m\n",
            "\u001b[32m2021-10-22 04:15:04\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 190/777, mem: 9741Mb, iter_time: 0.793s, data_time: 0.009s, total_loss: 4.8, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.3, lr: 1.185e-03, size: 608, ETA: 2 days, 6:31:03\u001b[0m\n",
            "\u001b[32m2021-10-22 04:15:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 200/777, mem: 9741Mb, iter_time: 1.008s, data_time: 0.010s, total_loss: 4.3, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.0, lr: 1.185e-03, size: 800, ETA: 2 days, 6:30:55\u001b[0m\n",
            "\u001b[32m2021-10-22 04:15:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 210/777, mem: 9741Mb, iter_time: 1.270s, data_time: 0.005s, total_loss: 4.4, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.0, lr: 1.184e-03, size: 736, ETA: 2 days, 6:32:08\u001b[0m\n",
            "\u001b[32m2021-10-22 04:15:39\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 220/777, mem: 9741Mb, iter_time: 1.154s, data_time: 0.007s, total_loss: 4.8, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.1, lr: 1.184e-03, size: 800, ETA: 2 days, 6:32:45\u001b[0m\n",
            "\u001b[32m2021-10-22 04:15:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 230/777, mem: 9741Mb, iter_time: 1.150s, data_time: 0.004s, total_loss: 5.4, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.5, lr: 1.184e-03, size: 448, ETA: 2 days, 6:33:21\u001b[0m\n",
            "\u001b[32m2021-10-22 04:15:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 240/777, mem: 9741Mb, iter_time: 0.679s, data_time: 0.008s, total_loss: 5.3, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.3, lr: 1.184e-03, size: 448, ETA: 2 days, 6:31:33\u001b[0m\n",
            "\u001b[32m2021-10-22 04:16:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 250/777, mem: 9741Mb, iter_time: 0.761s, data_time: 0.010s, total_loss: 4.6, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.1, lr: 1.184e-03, size: 640, ETA: 2 days, 6:30:11\u001b[0m\n",
            "\u001b[32m2021-10-22 04:16:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 260/777, mem: 9741Mb, iter_time: 0.971s, data_time: 0.007s, total_loss: 5.1, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.2, lr: 1.184e-03, size: 672, ETA: 2 days, 6:29:52\u001b[0m\n",
            "\u001b[32m2021-10-22 04:16:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 270/777, mem: 9741Mb, iter_time: 0.977s, data_time: 0.007s, total_loss: 5.4, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.2, lr: 1.184e-03, size: 544, ETA: 2 days, 6:29:36\u001b[0m\n",
            "\u001b[32m2021-10-22 04:16:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 280/777, mem: 9741Mb, iter_time: 0.777s, data_time: 0.006s, total_loss: 5.0, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.1, lr: 1.184e-03, size: 480, ETA: 2 days, 6:28:19\u001b[0m\n",
            "\u001b[32m2021-10-22 04:16:40\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 290/777, mem: 9741Mb, iter_time: 0.774s, data_time: 0.010s, total_loss: 4.0, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 1.6, cls_loss: 0.7, lr: 1.184e-03, size: 544, ETA: 2 days, 6:27:01\u001b[0m\n",
            "\u001b[32m2021-10-22 04:16:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 300/777, mem: 9741Mb, iter_time: 0.977s, data_time: 0.008s, total_loss: 4.5, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 0.9, lr: 1.184e-03, size: 832, ETA: 2 days, 6:26:44\u001b[0m\n",
            "\u001b[32m2021-10-22 04:17:02\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 310/777, mem: 9741Mb, iter_time: 1.275s, data_time: 0.003s, total_loss: 5.4, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.3, lr: 1.184e-03, size: 544, ETA: 2 days, 6:27:57\u001b[0m\n",
            "\u001b[32m2021-10-22 04:17:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mapex.amp.handle\u001b[0m:\u001b[36m140\u001b[0m - \u001b[1mGradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\u001b[0m\n",
            "\u001b[32m2021-10-22 04:17:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 320/777, mem: 9741Mb, iter_time: 0.877s, data_time: 0.008s, total_loss: 5.1, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.2, lr: 1.184e-03, size: 704, ETA: 2 days, 6:27:11\u001b[0m\n",
            "\u001b[32m2021-10-22 04:17:23\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 330/777, mem: 9741Mb, iter_time: 1.166s, data_time: 0.008s, total_loss: 5.0, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.5, lr: 1.184e-03, size: 832, ETA: 2 days, 6:27:51\u001b[0m\n",
            "\u001b[32m2021-10-22 04:17:36\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 340/777, mem: 9741Mb, iter_time: 1.281s, data_time: 0.007s, total_loss: 5.5, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.5, cls_loss: 1.3, lr: 1.184e-03, size: 736, ETA: 2 days, 6:29:05\u001b[0m\n",
            "\u001b[32m2021-10-22 04:17:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 350/777, mem: 9741Mb, iter_time: 1.107s, data_time: 0.004s, total_loss: 5.2, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.2, lr: 1.184e-03, size: 736, ETA: 2 days, 6:29:27\u001b[0m\n",
            "\u001b[32m2021-10-22 04:17:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 360/777, mem: 9741Mb, iter_time: 1.059s, data_time: 0.009s, total_loss: 4.0, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 1.5, cls_loss: 1.0, lr: 1.184e-03, size: 640, ETA: 2 days, 6:29:35\u001b[0m\n",
            "\u001b[32m2021-10-22 04:18:06\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 370/777, mem: 9741Mb, iter_time: 0.876s, data_time: 0.007s, total_loss: 5.3, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.2, lr: 1.184e-03, size: 544, ETA: 2 days, 6:28:48\u001b[0m\n",
            "\u001b[32m2021-10-22 04:18:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 380/777, mem: 9741Mb, iter_time: 0.916s, data_time: 0.008s, total_loss: 5.1, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.2, lr: 1.184e-03, size: 736, ETA: 2 days, 6:28:13\u001b[0m\n",
            "\u001b[32m2021-10-22 04:18:26\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 390/777, mem: 9741Mb, iter_time: 1.097s, data_time: 0.007s, total_loss: 4.8, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.2, lr: 1.184e-03, size: 672, ETA: 2 days, 6:28:32\u001b[0m\n",
            "\u001b[32m2021-10-22 04:18:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 400/777, mem: 9741Mb, iter_time: 1.104s, data_time: 0.013s, total_loss: 4.9, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.1, lr: 1.184e-03, size: 832, ETA: 2 days, 6:28:53\u001b[0m\n",
            "\u001b[32m2021-10-22 04:18:49\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 410/777, mem: 9741Mb, iter_time: 1.209s, data_time: 0.005s, total_loss: 6.0, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.7, cls_loss: 1.4, lr: 1.184e-03, size: 512, ETA: 2 days, 6:29:45\u001b[0m\n",
            "\u001b[32m2021-10-22 04:18:57\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 420/777, mem: 9741Mb, iter_time: 0.797s, data_time: 0.008s, total_loss: 5.1, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.2, cls_loss: 1.2, lr: 1.184e-03, size: 608, ETA: 2 days, 6:28:35\u001b[0m\n",
            "\u001b[32m2021-10-22 04:19:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 430/777, mem: 9741Mb, iter_time: 0.922s, data_time: 0.009s, total_loss: 4.9, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.2, lr: 1.184e-03, size: 672, ETA: 2 days, 6:28:02\u001b[0m\n",
            "\u001b[32m2021-10-22 04:19:16\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 440/777, mem: 9741Mb, iter_time: 0.942s, data_time: 0.004s, total_loss: 4.7, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.0, lr: 1.184e-03, size: 480, ETA: 2 days, 6:27:35\u001b[0m\n",
            "\u001b[32m2021-10-22 04:19:24\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 450/777, mem: 9741Mb, iter_time: 0.744s, data_time: 0.008s, total_loss: 5.6, iou_loss: 2.0, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.2, lr: 1.184e-03, size: 544, ETA: 2 days, 6:26:10\u001b[0m\n",
            "\u001b[32m2021-10-22 04:19:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 460/777, mem: 9741Mb, iter_time: 0.965s, data_time: 0.008s, total_loss: 5.2, iou_loss: 1.9, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.2, lr: 1.183e-03, size: 768, ETA: 2 days, 6:25:50\u001b[0m\n",
            "\u001b[32m2021-10-22 04:19:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 470/777, mem: 9741Mb, iter_time: 1.096s, data_time: 0.006s, total_loss: 4.8, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.1, lr: 1.183e-03, size: 544, ETA: 2 days, 6:26:09\u001b[0m\n",
            "\u001b[32m2021-10-22 04:19:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 480/777, mem: 9741Mb, iter_time: 0.965s, data_time: 0.011s, total_loss: 4.3, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 1.7, cls_loss: 1.1, lr: 1.183e-03, size: 800, ETA: 2 days, 6:25:48\u001b[0m\n",
            "\u001b[32m2021-10-22 04:20:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 490/777, mem: 9741Mb, iter_time: 1.320s, data_time: 0.007s, total_loss: 4.5, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.1, lr: 1.183e-03, size: 832, ETA: 2 days, 6:27:12\u001b[0m\n",
            "\u001b[32m2021-10-22 04:20:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 500/777, mem: 9741Mb, iter_time: 1.203s, data_time: 0.005s, total_loss: 6.1, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.8, cls_loss: 1.5, lr: 1.183e-03, size: 576, ETA: 2 days, 6:28:02\u001b[0m\n",
            "\u001b[32m2021-10-22 04:20:27\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 510/777, mem: 9741Mb, iter_time: 0.827s, data_time: 0.010s, total_loss: 4.7, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.1, lr: 1.183e-03, size: 576, ETA: 2 days, 6:27:01\u001b[0m\n",
            "\u001b[32m2021-10-22 04:20:37\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 520/777, mem: 9741Mb, iter_time: 0.913s, data_time: 0.010s, total_loss: 4.0, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 1.6, cls_loss: 0.9, lr: 1.183e-03, size: 704, ETA: 2 days, 6:26:26\u001b[0m\n",
            "\u001b[32m2021-10-22 04:20:47\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 530/777, mem: 9741Mb, iter_time: 1.044s, data_time: 0.011s, total_loss: 5.3, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.2, lr: 1.183e-03, size: 608, ETA: 2 days, 6:26:29\u001b[0m\n",
            "\u001b[32m2021-10-22 04:20:55\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 540/777, mem: 9741Mb, iter_time: 0.840s, data_time: 0.008s, total_loss: 4.9, iou_loss: 1.3, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.5, lr: 1.183e-03, size: 448, ETA: 2 days, 6:25:32\u001b[0m\n",
            "\u001b[32m2021-10-22 04:21:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 550/777, mem: 9741Mb, iter_time: 0.711s, data_time: 0.010s, total_loss: 5.2, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 1.3, lr: 1.183e-03, size: 544, ETA: 2 days, 6:23:59\u001b[0m\n",
            "\u001b[32m2021-10-22 04:21:11\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 560/777, mem: 9741Mb, iter_time: 0.854s, data_time: 0.009s, total_loss: 4.5, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.0, cls_loss: 0.9, lr: 1.183e-03, size: 576, ETA: 2 days, 6:23:07\u001b[0m\n",
            "\u001b[32m2021-10-22 04:21:19\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 570/777, mem: 9741Mb, iter_time: 0.815s, data_time: 0.005s, total_loss: 4.7, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.1, lr: 1.183e-03, size: 480, ETA: 2 days, 6:22:04\u001b[0m\n",
            "\u001b[32m2021-10-22 04:21:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 580/777, mem: 9741Mb, iter_time: 0.921s, data_time: 0.009s, total_loss: 4.9, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.1, lr: 1.183e-03, size: 832, ETA: 2 days, 6:21:31\u001b[0m\n",
            "\u001b[32m2021-10-22 04:21:42\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 590/777, mem: 9741Mb, iter_time: 1.353s, data_time: 0.010s, total_loss: 5.2, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.2, lr: 1.183e-03, size: 768, ETA: 2 days, 6:23:03\u001b[0m\n",
            "\u001b[32m2021-10-22 04:21:53\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 600/777, mem: 9741Mb, iter_time: 1.058s, data_time: 0.004s, total_loss: 4.6, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.1, lr: 1.183e-03, size: 576, ETA: 2 days, 6:23:10\u001b[0m\n",
            "\u001b[32m2021-10-22 04:22:03\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 610/777, mem: 9741Mb, iter_time: 0.981s, data_time: 0.011s, total_loss: 4.4, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.0, lr: 1.183e-03, size: 800, ETA: 2 days, 6:22:55\u001b[0m\n",
            "\u001b[32m2021-10-22 04:22:15\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 620/777, mem: 9741Mb, iter_time: 1.262s, data_time: 0.006s, total_loss: 4.9, iou_loss: 1.7, l1_loss: 0.0, conf_loss: 2.1, cls_loss: 1.1, lr: 1.183e-03, size: 704, ETA: 2 days, 6:24:01\u001b[0m\n",
            "\u001b[32m2021-10-22 04:22:25\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 630/777, mem: 9741Mb, iter_time: 0.965s, data_time: 0.006s, total_loss: 5.4, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.3, cls_loss: 1.5, lr: 1.183e-03, size: 512, ETA: 2 days, 6:23:41\u001b[0m\n",
            "\u001b[32m2021-10-22 04:22:33\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 640/777, mem: 9741Mb, iter_time: 0.813s, data_time: 0.008s, total_loss: 4.6, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.2, lr: 1.183e-03, size: 672, ETA: 2 days, 6:22:38\u001b[0m\n",
            "\u001b[32m2021-10-22 04:22:44\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 650/777, mem: 9741Mb, iter_time: 1.074s, data_time: 0.007s, total_loss: 4.5, iou_loss: 1.5, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.1, lr: 1.183e-03, size: 672, ETA: 2 days, 6:22:49\u001b[0m\n",
            "\u001b[32m2021-10-22 04:22:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 660/777, mem: 9741Mb, iter_time: 1.053s, data_time: 0.006s, total_loss: 5.1, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 2.4, cls_loss: 1.2, lr: 1.183e-03, size: 736, ETA: 2 days, 6:22:54\u001b[0m\n",
            "\u001b[32m2021-10-22 04:23:05\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 670/777, mem: 9741Mb, iter_time: 1.050s, data_time: 0.004s, total_loss: 4.5, iou_loss: 1.6, l1_loss: 0.0, conf_loss: 1.8, cls_loss: 1.1, lr: 1.183e-03, size: 512, ETA: 2 days, 6:22:59\u001b[0m\n",
            "\u001b[32m2021-10-22 04:23:14\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.core.trainer\u001b[0m:\u001b[36m255\u001b[0m - \u001b[1mepoch: 48/300, iter: 680/777, mem: 9741Mb, iter_time: 0.912s, data_time: 0.007s, total_loss: 4.7, iou_loss: 1.8, l1_loss: 0.0, conf_loss: 1.9, cls_loss: 1.1, lr: 1.183e-03, size: 768, ETA: 2 days, 6:22:24\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UjsuFDICVov"
      },
      "source": [
        "# Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sE5oWuEOICAF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1afdba64-38eb-4d6d-bf32-4aa58922f4c1"
      },
      "source": [
        "!python3 tools/eval.py -n  yolox-s -c /content/gdrive/MyDrive/Sprints/yolox_voc_s/best_ckpt.pth.tar -b 8 -d 1 --conf 0.001 -f exps/example/yolox_voc/yolox_voc_s.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m2021-10-20 05:16:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m129\u001b[0m - \u001b[1mArgs: Namespace(batch_size=8, ckpt='/content/gdrive/MyDrive/Sprints/yolox_voc_s/best_ckpt.pth.tar', conf=0.001, devices=1, dist_backend='nccl', dist_url=None, exp_file='exps/example/yolox_voc/yolox_voc_s.py', experiment_name='yolox_voc_s', fp16=False, fuse=False, local_rank=0, machine_rank=0, name='yolox-s', nms=None, num_machines=1, opts=[], seed=None, speed=False, test=False, trt=False, tsize=None)\u001b[0m\n",
            "\u001b[32m2021-10-20 05:16:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m139\u001b[0m - \u001b[1mModel Summary: Params: 8.95M, Gflops: 26.69\u001b[0m\n",
            "\u001b[32m2021-10-20 05:16:29\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m140\u001b[0m - \u001b[1mModel Structure:\n",
            "YOLOX(\n",
            "  (backbone): YOLOPAFPN(\n",
            "    (backbone): CSPDarknet(\n",
            "      (stem): Focus(\n",
            "        (conv): BaseConv(\n",
            "          (conv): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (dark2): Sequential(\n",
            "        (0): BaseConv(\n",
            "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): CSPLayer(\n",
            "          (conv1): BaseConv(\n",
            "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv2): BaseConv(\n",
            "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv3): BaseConv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (m): Sequential(\n",
            "            (0): Bottleneck(\n",
            "              (conv1): BaseConv(\n",
            "                (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (conv2): BaseConv(\n",
            "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (dark3): Sequential(\n",
            "        (0): BaseConv(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): CSPLayer(\n",
            "          (conv1): BaseConv(\n",
            "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv2): BaseConv(\n",
            "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv3): BaseConv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (m): Sequential(\n",
            "            (0): Bottleneck(\n",
            "              (conv1): BaseConv(\n",
            "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (conv2): BaseConv(\n",
            "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "            (1): Bottleneck(\n",
            "              (conv1): BaseConv(\n",
            "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (conv2): BaseConv(\n",
            "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "            (2): Bottleneck(\n",
            "              (conv1): BaseConv(\n",
            "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (conv2): BaseConv(\n",
            "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (dark4): Sequential(\n",
            "        (0): BaseConv(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): CSPLayer(\n",
            "          (conv1): BaseConv(\n",
            "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv2): BaseConv(\n",
            "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv3): BaseConv(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (m): Sequential(\n",
            "            (0): Bottleneck(\n",
            "              (conv1): BaseConv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (conv2): BaseConv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "            (1): Bottleneck(\n",
            "              (conv1): BaseConv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (conv2): BaseConv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "            (2): Bottleneck(\n",
            "              (conv1): BaseConv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (conv2): BaseConv(\n",
            "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (dark5): Sequential(\n",
            "        (0): BaseConv(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): SPPBottleneck(\n",
            "          (conv1): BaseConv(\n",
            "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (m): ModuleList(\n",
            "            (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
            "            (1): MaxPool2d(kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False)\n",
            "            (2): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)\n",
            "          )\n",
            "          (conv2): BaseConv(\n",
            "            (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (2): CSPLayer(\n",
            "          (conv1): BaseConv(\n",
            "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv2): BaseConv(\n",
            "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv3): BaseConv(\n",
            "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (m): Sequential(\n",
            "            (0): Bottleneck(\n",
            "              (conv1): BaseConv(\n",
            "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "              (conv2): BaseConv(\n",
            "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "                (act): SiLU(inplace=True)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
            "    (lateral_conv0): BaseConv(\n",
            "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (C3_p4): CSPLayer(\n",
            "      (conv1): BaseConv(\n",
            "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (conv2): BaseConv(\n",
            "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (conv3): BaseConv(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): BaseConv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv2): BaseConv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (reduce_conv1): BaseConv(\n",
            "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (C3_p3): CSPLayer(\n",
            "      (conv1): BaseConv(\n",
            "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (conv2): BaseConv(\n",
            "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (conv3): BaseConv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): BaseConv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv2): BaseConv(\n",
            "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (bu_conv2): BaseConv(\n",
            "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (C3_n3): CSPLayer(\n",
            "      (conv1): BaseConv(\n",
            "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (conv2): BaseConv(\n",
            "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (conv3): BaseConv(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): BaseConv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv2): BaseConv(\n",
            "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (bu_conv1): BaseConv(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "      (act): SiLU(inplace=True)\n",
            "    )\n",
            "    (C3_n4): CSPLayer(\n",
            "      (conv1): BaseConv(\n",
            "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (conv2): BaseConv(\n",
            "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (conv3): BaseConv(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (m): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): BaseConv(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "          (conv2): BaseConv(\n",
            "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "            (act): SiLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (head): YOLOXHead(\n",
            "    (cls_convs): ModuleList(\n",
            "      (0): Sequential(\n",
            "        (0): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (reg_convs): ModuleList(\n",
            "      (0): Sequential(\n",
            "        (0): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "        (1): BaseConv(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "          (act): SiLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (cls_preds): ModuleList(\n",
            "      (0): Conv2d(128, 25, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): Conv2d(128, 25, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Conv2d(128, 25, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (reg_preds): ModuleList(\n",
            "      (0): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (obj_preds): ModuleList(\n",
            "      (0): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (2): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (stems): ModuleList(\n",
            "      (0): BaseConv(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (1): BaseConv(\n",
            "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "      (2): BaseConv(\n",
            "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
            "        (act): SiLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (l1_loss): L1Loss()\n",
            "    (bcewithlog_loss): BCEWithLogitsLoss()\n",
            "    (iou_loss): IOUloss()\n",
            "  )\n",
            ")\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\u001b[32m2021-10-20 05:16:31\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mloading checkpoint\u001b[0m\n",
            "\u001b[32m2021-10-20 05:16:32\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mloaded checkpoint done.\u001b[0m\n",
            "100%|##########| 44/44 [00:18<00:00,  2.35it/s]\n",
            "\u001b[32m2021-10-20 05:16:50\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36myolox.evaluators.voc_evaluator\u001b[0m:\u001b[36m161\u001b[0m - \u001b[1mEvaluate in main process...\u001b[0m\n",
            "Writing beans VOC results file\n",
            "Writing cake VOC results file\n",
            "Writing candy VOC results file\n",
            "Writing cereal VOC results file\n",
            "Writing chips VOC results file\n",
            "Writing chocolate VOC results file\n",
            "Writing coffee VOC results file\n",
            "Writing corn VOC results file\n",
            "Writing fish VOC results file\n",
            "Writing flour VOC results file\n",
            "Writing honey VOC results file\n",
            "Writing jam VOC results file\n",
            "Writing juice VOC results file\n",
            "Writing milk VOC results file\n",
            "Writing nuts VOC results file\n",
            "Writing oil VOC results file\n",
            "Writing pasta VOC results file\n",
            "Writing rice VOC results file\n",
            "Writing soda VOC results file\n",
            "Writing spices VOC results file\n",
            "Writing sugar VOC results file\n",
            "Writing tea VOC results file\n",
            "Writing tomato_sauce VOC results file\n",
            "Writing vinegar VOC results file\n",
            "Writing water VOC results file\n",
            "Eval IoU : 0.50\n",
            "AP for beans = 0.9277\n",
            "AP for cake = 0.7583\n",
            "AP for candy = 0.6582\n",
            "AP for cereal = 0.8603\n",
            "AP for chips = 0.8019\n",
            "AP for chocolate = 0.7525\n",
            "AP for coffee = 0.8211\n",
            "AP for corn = 0.9617\n",
            "AP for fish = 0.9388\n",
            "AP for flour = 0.7879\n",
            "AP for honey = 0.8492\n",
            "AP for jam = 0.8906\n",
            "AP for juice = 0.8784\n",
            "AP for milk = 0.7806\n",
            "AP for nuts = 0.8125\n",
            "AP for oil = 0.7701\n",
            "AP for pasta = 0.6856\n",
            "AP for rice = 0.8693\n",
            "AP for soda = 0.7737\n",
            "AP for spices = 0.9599\n",
            "AP for sugar = 0.8140\n",
            "AP for tea = 0.8862\n",
            "AP for tomato_sauce = 0.9569\n",
            "AP for vinegar = 0.8157\n",
            "AP for water = 0.8137\n",
            "Mean AP = 0.8330\n",
            "~~~~~~~~\n",
            "Results:\n",
            "0.928\n",
            "0.758\n",
            "0.658\n",
            "0.860\n",
            "0.802\n",
            "0.752\n",
            "0.821\n",
            "0.962\n",
            "0.939\n",
            "0.788\n",
            "0.849\n",
            "0.891\n",
            "0.878\n",
            "0.781\n",
            "0.813\n",
            "0.770\n",
            "0.686\n",
            "0.869\n",
            "0.774\n",
            "0.960\n",
            "0.814\n",
            "0.886\n",
            "0.957\n",
            "0.816\n",
            "0.814\n",
            "0.833\n",
            "~~~~~~~~\n",
            "\n",
            "--------------------------------------------------------------\n",
            "Results computed with the **unofficial** Python eval code.\n",
            "Results should be very close to the official MATLAB eval code.\n",
            "Recompute with `./tools/reval.py --matlab ...` for your paper.\n",
            "-- Thanks, The Management\n",
            "--------------------------------------------------------------\n",
            "Eval IoU : 0.55\n",
            "Eval IoU : 0.60\n",
            "Eval IoU : 0.65\n",
            "Eval IoU : 0.70\n",
            "Eval IoU : 0.75\n",
            "Eval IoU : 0.80\n",
            "Eval IoU : 0.85\n",
            "Eval IoU : 0.90\n",
            "Eval IoU : 0.95\n",
            "--------------------------------------------------------------\n",
            "map_5095: 0.632036910918931\n",
            "map_50: 0.8329878158741765\n",
            "--------------------------------------------------------------\n",
            "\u001b[32m2021-10-20 05:16:59\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m185\u001b[0m - \u001b[1m\n",
            "Average forward time: 31.37 ms, Average NMS time: 3.44 ms, Average inference time: 34.80 ms\n",
            "\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnFRJEa7CaPe"
      },
      "source": [
        "# Test the Model\n",
        "Make sure you replace the `TEST_IMAGE_PATH` variable with a test image from your dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIXoCCwkMjpK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a851305-f57f-4621-efef-bbcebfb07eb0"
      },
      "source": [
        "!python tools/demo.py image -f /content/YOLOX/exps/example/yolox_voc/yolox_voc_s.py -c /content/best_pth.tar --path /content/tt88.jpg --conf 0.25 --nms 0.45 --tsize 640 --save_result --device gpu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m2021-10-21 17:03:43.911\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m240\u001b[0m - \u001b[1mArgs: Namespace(camid=0, ckpt='/content/gdrive/MyDrive/Sprints/yolox_voc_s/best_ckpt.pth.tar', conf=0.25, demo='image', device='gpu', exp_file='/content/YOLOX/exps/example/yolox_voc/yolox_voc_s.py', experiment_name='yolox_voc_s', fp16=False, fuse=False, name=None, nms=0.45, path='/content/tt88.jpg', save_result=True, trt=False, tsize=640)\u001b[0m\n",
            "\u001b[32m2021-10-21 17:03:44.170\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m250\u001b[0m - \u001b[1mModel Summary: Params: 8.95M, Gflops: 26.68\u001b[0m\n",
            "\u001b[32m2021-10-21 17:03:46.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m261\u001b[0m - \u001b[1mloading checkpoint\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"tools/demo.py\", line 296, in <module>\n",
            "    main(exp, args)\n",
            "  File \"tools/demo.py\", line 264, in main\n",
            "    model.load_state_dict(ckpt[\"model\"])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1224, in load_state_dict\n",
            "    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n",
            "RuntimeError: Error(s) in loading state_dict for YOLOX:\n",
            "\tsize mismatch for head.cls_preds.0.weight: copying a param with shape torch.Size([25, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([20, 128, 1, 1]).\n",
            "\tsize mismatch for head.cls_preds.0.bias: copying a param with shape torch.Size([25]) from checkpoint, the shape in current model is torch.Size([20]).\n",
            "\tsize mismatch for head.cls_preds.1.weight: copying a param with shape torch.Size([25, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([20, 128, 1, 1]).\n",
            "\tsize mismatch for head.cls_preds.1.bias: copying a param with shape torch.Size([25]) from checkpoint, the shape in current model is torch.Size([20]).\n",
            "\tsize mismatch for head.cls_preds.2.weight: copying a param with shape torch.Size([25, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([20, 128, 1, 1]).\n",
            "\tsize mismatch for head.cls_preds.2.bias: copying a param with shape torch.Size([25]) from checkpoint, the shape in current model is torch.Size([20]).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7nX2nwWCper"
      },
      "source": [
        "# Visualize the Predictions\n",
        "Make sure you replace the `OUTPUT_IMAGE_PATH` with the respective path of the image output. This path can be found somewhere in the `YOLOX_outputs` folder\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkeb6ircokya"
      },
      "source": [
        "from PIL import Image\n",
        "OUTPUT_IMAGE_PATH = \"/content/YOLOX/YOLOX_outputs/yolox_voc_s/vis_res/2021_10_17_04_50_50/BEANS0026_png.rf.c494d8b74494eeee413ff1c24554bf3f.jpg\" \n",
        "Image.open(OUTPUT_IMAGE_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQUkGZkLomFA"
      },
      "source": [
        "from PIL import Image\n",
        "OUTPUT_IMAGE_PATH = \"/content/YOLOX/YOLOX_outputs/yolox_voc_s/vis_res/2021_10_17_04_54_00/CAKE0139_png.rf.976176cd4fb119253d0e8e0f2e4a391c.jpg\" \n",
        "Image.open(OUTPUT_IMAGE_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTLVqKZHomi9"
      },
      "source": [
        "from PIL import Image\n",
        "OUTPUT_IMAGE_PATH = \"/content/YOLOX/YOLOX_outputs/yolox_voc_s/vis_res/2021_10_17_04_55_09/CANDY0244_png.rf.3a39488b1526ae3786ff072539812a2b.jpg\" \n",
        "Image.open(OUTPUT_IMAGE_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3_kOK2cZtJK"
      },
      "source": [
        "from PIL import Image\n",
        "OUTPUT_IMAGE_PATH = \"/content/YOLOX/YOLOX_outputs/yolox_voc_s/vis_res/2021_10_17_04_57_24/ttt.jpg\" \n",
        "Image.open(OUTPUT_IMAGE_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFbMKDkxPWoD"
      },
      "source": [
        "# Export Trained Weights for Future Inference\n",
        "\n",
        "Now that you have trained your custom detector, you can export the trained weights you have made here for inference on your device elsewhere"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlZf3KlMPYPS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b260fa89-a1cb-4061-cd1d-303b98ec55e0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRScjyzAwP-A"
      },
      "source": [
        "%cp /content/YOLOX/YOLOX_outputs/yolox_voc_s/best_ckpt.pth.tar /content/gdrive/My\\ Drive"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}